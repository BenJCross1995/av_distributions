{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fecd997",
   "metadata": {},
   "source": [
    "# Get Results and Performance Output\n",
    "\n",
    "Here we grab the results from a directory and run them through the idiolect performance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c01ee21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(idiolect)\n",
    "library(readr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5f82cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_directory = '/Volumes/BCross/datasets/author_verification/test/Wiki/lambdag_results/'\n",
    "\n",
    "aggregated_result_save_loc = paste0(result_directory, \"aggregated_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f65ba4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_rds <- function(directory) {\n",
    "  #' Function to combine all .rds files from within a directory into a single dataframe.\n",
    "  \n",
    "  # List all RDS files\n",
    "  files <- list.files(directory, pattern = \"\\\\.rds\", full.names = TRUE)\n",
    "  \n",
    "  # Read and combine\n",
    "  combined <- files %>%\n",
    "    lapply(readRDS) %>%\n",
    "    bind_rows()\n",
    "  \n",
    "  return(combined)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cdbcf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results <- combine_rds(result_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d6e5b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'problem', 'known_doc', 'unknown_doc',\n",
      "'known_author', 'unknown_author'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 672 × 7\u001b[39m\n",
       "\u001b[38;5;246m# Groups:   problem, known_doc, unknown_doc, known_author, unknown_author [672]\u001b[39m\n",
       "   problem       known_doc unknown_doc known_author unknown_author target  score\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[38;5;246m<lgl>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m HOOTmag vs H… hootmag_… hootmag_te… HOOTmag      HOOTmag        TRUE    -\u001b[31m6\u001b[39m\u001b[31m.\u001b[39m\u001b[31m60\u001b[39m\n",
       "\u001b[38;5;250m 2\u001b[39m HOOTmag vs H… hootmag_… hootmag_te… HOOTmag      HOOTmag        TRUE   -\u001b[31m33\u001b[39m\u001b[31m.\u001b[39m\u001b[31m1\u001b[39m \n",
       "\u001b[38;5;250m 3\u001b[39m HOOTmag vs H… hootmag_… hootmag_te… HOOTmag      HOOTmag        TRUE   525.  \n",
       "\u001b[38;5;250m 4\u001b[39m HOOTmag vs I… hootmag_… iain99_tex… HOOTmag      Iain99         FALSE  -\u001b[31m25\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m \n",
       "\u001b[38;5;250m 5\u001b[39m HOOTmag vs I… hootmag_… iain99_tex… HOOTmag      Iain99         FALSE  -\u001b[31m59\u001b[39m\u001b[31m.\u001b[39m\u001b[31m7\u001b[39m \n",
       "\u001b[38;5;250m 6\u001b[39m HOOTmag vs I… hootmag_… iain99_tex… HOOTmag      Iain99         FALSE  -\u001b[31m41\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m \n",
       "\u001b[38;5;250m 7\u001b[39m Hodja_Nasred… hodja_na… hodja_nasr… Hodja_Nasre… Hodja_Nasredd… TRUE     4.94\n",
       "\u001b[38;5;250m 8\u001b[39m Hodja_Nasred… hodja_na… hodja_nasr… Hodja_Nasre… Hodja_Nasredd… TRUE    22.8 \n",
       "\u001b[38;5;250m 9\u001b[39m Hodja_Nasred… hodja_na… hodja_nasr… Hodja_Nasre… Hodja_Nasredd… TRUE    36.2 \n",
       "\u001b[38;5;250m10\u001b[39m Hodja_Nasred… hodja_na… honestopl_… Hodja_Nasre… HonestopL      FALSE   12.0 \n",
       "\u001b[38;5;246m# ℹ 662 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results |> \n",
    "  mutate(target = known_author == unknown_author) |>\n",
    "  group_by(problem, known_doc, unknown_doc, known_author, unknown_author, target) |>\n",
    "  summarise(score = mean(score, na.rm=TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d69af624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'problem', 'known_author',\n",
      "'unknown_author'. You can override using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "aggregated_results <- combined_results |> \n",
    "  mutate(target = known_author == unknown_author) |>\n",
    "  group_by(problem, known_author, unknown_author, target) |>\n",
    "  summarise(score = mean(score, na.rm=TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "13f80036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 224 × 5\u001b[39m\n",
       "\u001b[38;5;246m# Groups:   problem, known_author, unknown_author [224]\u001b[39m\n",
       "   problem                            known_author  unknown_author target  score\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                              \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[38;5;246m<lgl>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m HOOTmag vs HOOTmag                 HOOTmag       HOOTmag        TRUE   162.  \n",
       "\u001b[38;5;250m 2\u001b[39m HOOTmag vs Iain99                  HOOTmag       Iain99         FALSE  -\u001b[31m42\u001b[39m\u001b[31m.\u001b[39m\u001b[31m1\u001b[39m \n",
       "\u001b[38;5;250m 3\u001b[39m Hodja_Nasreddin vs Hodja_Nasreddin Hodja_Nasred… Hodja_Nasredd… TRUE    21.3 \n",
       "\u001b[38;5;250m 4\u001b[39m Hodja_Nasreddin vs HonestopL       Hodja_Nasred… HonestopL      FALSE    9.26\n",
       "\u001b[38;5;250m 5\u001b[39m HonestopL vs HOOTmag               HonestopL     HOOTmag        FALSE  -\u001b[31m13\u001b[39m\u001b[31m.\u001b[39m\u001b[31m2\u001b[39m \n",
       "\u001b[38;5;250m 6\u001b[39m HonestopL vs HonestopL             HonestopL     HonestopL      TRUE   -\u001b[31m13\u001b[39m\u001b[31m.\u001b[39m\u001b[31m1\u001b[39m \n",
       "\u001b[38;5;250m 7\u001b[39m Iain99 vs Iain99                   Iain99        Iain99         TRUE    46.9 \n",
       "\u001b[38;5;250m 8\u001b[39m Iain99 vs Icarus3                  Iain99        Icarus3        FALSE    8.85\n",
       "\u001b[38;5;250m 9\u001b[39m Icarus3 vs Icarus3                 Icarus3       Icarus3        TRUE   154.  \n",
       "\u001b[38;5;250m10\u001b[39m Icarus3 vs Intangible              Icarus3       Intangible     FALSE  -\u001b[31m18\u001b[39m\u001b[31m.\u001b[39m\u001b[31m8\u001b[39m \n",
       "\u001b[38;5;246m# ℹ 214 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "18c16334",
   "metadata": {},
   "outputs": [],
   "source": [
    "readr::write_csv(aggregated_results, aggregated_result_save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "40ce23a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "\u001b[1m\u001b[22mAdding missing grouping variables: `problem`, `known_author`, `unknown_author`\n",
      "Setting levels: control = FALSE, case = TRUE\n",
      "Setting direction: controls < cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$evaluation\n",
       "       Cllr Cllr_min      EER Mean TRUE LLR Mean FALSE LLR TRUE trials\n",
       "1 0.6476871 0.524302 16.66667      1.092086     -0.7585601         114\n",
       "  FALSE trials      AUC Balanced Accuracy Precision    Recall        F1 TP FN\n",
       "1          114 0.901148         0.8303571 0.8303571 0.8303571 0.8303571 93 19\n",
       "  FP TN\n",
       "1 19 93\n",
       "\n",
       "$roc\n",
       "\n",
       "Call:\n",
       "NULL\n",
       "\n",
       "Data: (unknown) in 0 controls ((unknown) )  0 cases ((unknown) ).\n",
       "Area under the curve not computed.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance(aggregated_results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
