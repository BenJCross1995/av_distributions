{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd79e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f23990a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../src'))\n",
    "\n",
    "from read_and_write_docs import read_xml, read_jsonl\n",
    "from tokenize_and_score import load_model, compute_log_probs_with_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2597c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_text = read_xml(\"/Volumes/BCross/datasets/test_sms/adjusted/SMS_ENG_20110818.0003.conv.xml\")\n",
    "unknown_text = read_xml(\"/Volumes/BCross/datasets/test_sms/adjusted/SMS_ENG_20110901.0001.conv.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "602418b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_text = read_jsonl(\"/Volumes/BCross/datasets/author_verification/training/Wiki/known_corpus_split/classicjupiter2_text_4.jsonl\").loc[0, 'text']\n",
    "unknown_text = read_jsonl(\"/Volumes/BCross/datasets/author_verification/training/Wiki/known_corpus_split/habap_text_3.jsonl\").loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f419ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "{2: {('a', 'note'),\n",
    "  ('drop', 'you'),\n",
    "  ('i', 'just'),\n",
    "  ('i', 'was'),\n",
    "  ('i', 'will'),\n",
    "  ('if', 'you'),\n",
    "  ('in', 'the'),\n",
    "  ('is', 'a'),\n",
    "  ('is', 'also'),\n",
    "  ('is', 'not'),\n",
    "  ('just', 'wanted'),\n",
    "  ('of', 'the'),\n",
    "  ('on', 'the'),\n",
    "  ('talk', 'page'),\n",
    "  ('that', 'there'),\n",
    "  ('the', 'article'),\n",
    "  ('the', 'discussion'),\n",
    "  ('the', 'page'),\n",
    "  ('there', 'is'),\n",
    "  ('to', 'be'),\n",
    "  ('to', 'drop'),\n",
    "  ('to', 'the'),\n",
    "  ('wanted', 'to'),\n",
    "  ('was', 'only'),\n",
    "  ('you', 'a'),\n",
    "  ('you', 'can')},\n",
    " 3: {('drop', 'you', 'a'),\n",
    "  ('just', 'wanted', 'to'),\n",
    "  ('there', 'is', 'a'),\n",
    "  ('to', 'drop', 'you'),\n",
    "  ('wanted', 'to', 'drop'),\n",
    "  ('you', 'a', 'note')},\n",
    " 4: {('drop', 'you', 'a', 'note'),\n",
    "  ('just', 'wanted', 'to', 'drop'),\n",
    "  ('to', 'drop', 'you', 'a'),\n",
    "  ('wanted', 'to', 'drop', 'you')},\n",
    " 5: {('just', 'wanted', 'to', 'drop', 'you'),\n",
    "  ('to', 'drop', 'you', 'a', 'note'),\n",
    "  ('wanted', 'to', 'drop', 'you', 'a')},\n",
    " 6: {('just', 'wanted', 'to', 'drop', 'you', 'a'),\n",
    "  ('wanted', 'to', 'drop', 'you', 'a', 'note')},\n",
    " 7: {('just', 'wanted', 'to', 'drop', 'you', 'a', 'note')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3040f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_phrase = \"bell me wen u\"\n",
    "base_phrase = \"just wanted to drop you a note\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d5b3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_list = [\n",
    "    \"bel me wen u\",\n",
    "    \"bel me wen ya\",\n",
    "    \"bel me wen yu\",\n",
    "    \"bel me whn u\",\n",
    "    \"bell me wen ya\",\n",
    "    \"bell me wen yu\",\n",
    "    \"bell me whn u\",\n",
    "    \"bell me when u\",\n",
    "    \"bell me when you\",\n",
    "    \"ring me wen u\",\n",
    "    \"ring me wen ya\",\n",
    "    \"ring me wen yu\",\n",
    "    \"ring me whn u\",\n",
    "    \"ring me when u\",\n",
    "    \"ring me when you\",\n",
    "    \"call me wen u\",\n",
    "    \"call me wen ya\",\n",
    "    \"call me wen yu\",\n",
    "    \"call me whn u\",\n",
    "    \"call me when u\",\n",
    "    \"call me when you\",\n",
    "    \"buzz me wen u\",\n",
    "    \"buzz me wen ya\",\n",
    "    \"buzz me wen yu\",\n",
    "    \"buzz me whn u\",\n",
    "    \"buzz me when u\",\n",
    "    \"buzz me when you\",\n",
    "    \"give me a bell wen u\",\n",
    "    \"give me a ring wen u\",\n",
    "    \"give me a call wen u\",\n",
    "    \"gimme a bell wen u\",\n",
    "    \"gimme a ring wen u\",\n",
    "    \"gimme a call wen u\",\n",
    "    \"hit me wen u\",\n",
    "    \"hit me wen ya\",\n",
    "    \"hit me wen yu\",\n",
    "    \"hit me whn u\",\n",
    "    \"hit me when u\",\n",
    "    \"hit me when you\",\n",
    "    \"phone me wen u\",\n",
    "    \"phone me wen ya\",\n",
    "    \"phone me wen yu\",\n",
    "    \"phone me whn u\",\n",
    "    \"phone me when u\",\n",
    "    \"phone me when you\",\n",
    "    \"holla wen u\",\n",
    "    \"holla at me wen u\",\n",
    "    \"holla when u\",\n",
    "    \"holler wen u\",\n",
    "    \"holler when u\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74bfef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_list = [\n",
    "    \"just wanted to drop a note to you\",\n",
    "    \"just wanted to drop you a message\",\n",
    "    \"just wanted to drop a message to you\",\n",
    "    \"just wanted to drop you a line\",\n",
    "    \"just wanted to drop a line to you\",\n",
    "    \"just wanted to send you a note\",\n",
    "    \"just wanted to send a note to you\",\n",
    "    \"just wanted to send you a message\",\n",
    "    \"just wanted to send a message to you\",\n",
    "    \"just wanted to send you a line\",\n",
    "    \"just wanted to send a line to you\",\n",
    "    \"just wanted to leave you a note\",\n",
    "    \"just wanted to leave a note for you\",\n",
    "    \"just wanted to leave you a message\",\n",
    "    \"just wanted to leave a message for you\",\n",
    "    \"just wanted to give you a note\",\n",
    "    \"just wanted to give a note to you\",\n",
    "    \"just wanted to give you a message\",\n",
    "    \"just wanted to give a message to you\",\n",
    "    \"just wanted to pass you a note\",\n",
    "    \"just wanted to pass a note to you\",\n",
    "    \"just wanted to pass a message to you\", \n",
    "    \"just wanted to drop ya a note\",\n",
    "    \"just wanted to drop a note to ya\",\n",
    "    \"just wanted to send ya a note\",\n",
    "    \"just wanted to send a note to ya\",\n",
    "    \"just wanted to leave ya a note\",\n",
    "    \"just wanted to leave a note for ya\",\n",
    "    \"just wanted to give ya a note\",\n",
    "    \"just wanted to give a note to ya\",\n",
    "    \"just wanted to pass ya a note\",\n",
    "    \"just wanted to pass a note to ya\",\n",
    "    \"only wanted to drop you a note\",\n",
    "    \"simply wanted to drop you a note\",\n",
    "    \"only wanted to send you a note\",\n",
    "    \"simply wanted to send you a note\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e5b39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_before_phrase(text: str, phrase: str, case_insensitive: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Return everything in `text` before the first occurrence of `phrase`.\n",
    "    If `phrase` isnâ€™t found, returns the entire `text`.\n",
    "\n",
    "    :param text:       The full string you want to trim.\n",
    "    :param phrase:     The substring (phrase) you want to stop at.\n",
    "    :param case_insensitive:  If True, match phrase ignoring case.\n",
    "    :return:           The portion of `text` before `phrase`.\n",
    "    \"\"\"\n",
    "    if case_insensitive:\n",
    "        idx = text.lower().find(phrase.lower())\n",
    "    else:\n",
    "        idx = text.find(phrase)\n",
    "\n",
    "    return text[:idx] if idx != -1 else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af93aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_known_text = keep_before_phrase(known_text, base_phrase)\n",
    "base_unknown_text = keep_before_phrase(unknown_text, base_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0747a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"International Surrealism was only recognized by the public and the historians and scholars between the years, 1924 to 1969.\\nFrom the late 1960's to 2002's SURREALISM DESIRE UNBOUND Retrospective, the public acknowledges that International Surrealism is a retrospective movement in the arts and literature composed of notable figures who came and went, in and out of the International Surrealist Movement, like Aragon, Dali, Ernst, Matta, etc.\\nBetween the years, 2003 to today, there is a surrealist presence online from artists and others that claim to be surrealist, and in fairness to the everyone that claims the surrealist label, its the public that is the final judge.\\nWikipedia is an online encyclopedia, and it should not be used for self-promotion of non-notable groups that claim to be surrealists, just because they say so.\\nThe Internet has literally hundreds of surreal and surrealist related material, art, etc, and we would open the floodgates for misinformation on this encyclopedia.\\nThe information on their online blogs is so vague and misleading, that its just a case of any creative person using a BLOG or MYSPACE to draw attention to themselves, but Wikipedia is not to be used as such, its just not right.\\nThe preceding Jam, thanks so much for contacting me on my discussion page.\\nDaniel, I hope that you can understand this, I was wrong about the validity of the information in the Surrealism article.\\nIf you intend to re-edit the article, I will support your edits.\\nThe article really needs credible reference material\\nThere is the user SUPERTHIKE who is also the same user as HydroSony, Jacques Stenzack, etc, using the Discussion page for flamebait.\\nThey are using the page to start up flamebait and disrupting the discussion, HydroSony in particular keeps asking for personal contact info.\\nThanks for getting back to me on my talk page.\\nCan you please investigate the IP's of the following users, who I believe is one person using sockpuppets, Hello Naconkantari.\\nI\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_known_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0646b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model(\"/Volumes/BCross/models/Qwen 2.5/Qwen2.5-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f561d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def run_over_phrases(\n",
    "    base_known: str,\n",
    "    phrases: List[str],\n",
    "    tokenizer,\n",
    "    model\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    For each phrase in `phrases`, prepend base_known, run compute_log_probs_with_median,\n",
    "    and store tokens, log_probs, median_logprobs, and sum_log_probs.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    total = len(phrases)\n",
    "    for idx, phrase in enumerate(phrases, start=1):\n",
    "        print(f\"Scoring phrase {idx} out of {total}: {phrase}\")\n",
    "        text = base_known + phrase\n",
    "        tokens, log_probs, median_logprobs = compute_log_probs_with_median(text, tokenizer, model)\n",
    "        results[phrase] = {\n",
    "            \"text\": text,\n",
    "            \"tokens\":            tokens,\n",
    "            \"log_probs\":         log_probs,\n",
    "            \"median_logprobs\":   median_logprobs,\n",
    "            \"sum_log_probs\":     sum(log_probs),\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f9ebaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â result = run_over_phrases(base_known_text, paraphrase_list, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2c8a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def score_phrases(\n",
    "    base_text: str,\n",
    "    ref_phrase: str,\n",
    "    paraphrases: List[str],\n",
    "    tokenizer,\n",
    "    model\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Scores base_text alone â†’ base_total and n_base_tokens\n",
    "    - Then scores base_text + ref_phrase and each base_text + paraphrase,\n",
    "      printing:\n",
    "        â€¢ full sequence sum (`sum_before`)\n",
    "        â€¢ phrase-only sum (`phrase_total`)\n",
    "        â€¢ the phrase text\n",
    "        â€¢ `difference`\n",
    "    - Trims off the base_text tokens to isolate phrase-only tokens/log-probs.\n",
    "    - Returns a DataFrame with columns:\n",
    "        phrase_type, phrase, tokens, base_total, sum_before,\n",
    "        log_probs, phrase_total, difference\n",
    "    \"\"\"\n",
    "    # 1) score base_text alone\n",
    "    print(\"Scoring base_text alone...\")\n",
    "    _, log_probs_base, _ = compute_log_probs_with_median(base_text, tokenizer, model)\n",
    "    base_total    = sum(log_probs_base)\n",
    "    n_base_tokens = len(log_probs_base)\n",
    "\n",
    "    # prepare items\n",
    "    all_items = [(\"reference\", ref_phrase)] + [(\"paraphrase\", p) for p in paraphrases]\n",
    "    total = len(all_items)\n",
    "    rows = []\n",
    "\n",
    "    for idx, (ptype, phrase) in enumerate(all_items, start=1):\n",
    "        print(f\"Scoring {ptype} {idx}/{total}â€¦\")\n",
    "        text = base_text + phrase\n",
    "        tokens_all, log_probs_all, _ = compute_log_probs_with_median(text, tokenizer, model)\n",
    "\n",
    "        sum_before       = sum(log_probs_all)\n",
    "        # isolate phrase-only\n",
    "        phrase_tokens    = tokens_all[n_base_tokens:]\n",
    "        phrase_log_probs = log_probs_all[n_base_tokens:]\n",
    "        phrase_total     = sum(phrase_log_probs)\n",
    "        difference       = base_total - sum_before\n",
    "\n",
    "        rows.append({\n",
    "            \"phrase_type\":  ptype,\n",
    "            \"phrase\":       phrase,\n",
    "            \"tokens\":       phrase_tokens,\n",
    "            \"base_total\":   base_total,\n",
    "            \"sum_before\":   sum_before,\n",
    "            \"log_probs\":    phrase_log_probs,\n",
    "            \"phrase_total\": phrase_total,\n",
    "            \"difference\":   difference\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"phrase_type\",\n",
    "        \"phrase\",\n",
    "        \"tokens\",\n",
    "        \"base_total\",\n",
    "        \"sum_before\",\n",
    "        \"log_probs\",\n",
    "        \"phrase_total\",\n",
    "        \"difference\"\n",
    "    ])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c161c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def compute_log_probs_with_median(text: str, tokenizer, model):\n",
    "    \"\"\"\n",
    "    For each token (including the first), returns:\n",
    "      - tokens: list of tokenizer.convert_ids_to_tokens\n",
    "      - log_probs: list of log-probs for each token\n",
    "      - median_logprobs: median log-prob of the distribution at each step\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]         # shape [1, seq_len]\n",
    "    # --- ALIGN TOKENS CORRECTLY HERE ---\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits                 # [1, seq_len, vocab_size]\n",
    "\n",
    "    log_probs = []\n",
    "    median_logprobs = []\n",
    "    # for each position i, look at logits from i-1 (or the BOS for i=0)\n",
    "    for i in range(input_ids.size(1)):\n",
    "        prev_idx = 0 if i == 0 else i - 1\n",
    "        dist = torch.log_softmax(logits[0, prev_idx], dim=-1)\n",
    "        log_prob = dist[input_ids[0, i]].item()\n",
    "        median_lp = float(dist.median().item())\n",
    "        log_probs.append(log_prob)\n",
    "        median_logprobs.append(median_lp)\n",
    "\n",
    "    return tokens, log_probs, median_logprobs\n",
    "\n",
    "def score_phrases(\n",
    "    base_text: str,\n",
    "    ref_phrase: str,\n",
    "    paraphrases: List[str],\n",
    "    tokenizer,\n",
    "    model\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Score base_text alone â†’ base_total\n",
    "    2) For each phrase (reference + paraphrases):\n",
    "         a) Get its token count by scoring phrase alone\n",
    "         b) Score base_text + phrase â†’ full tokens & log_probs\n",
    "         c) sum_before = sum(full log_probs)\n",
    "         d) phrase_tokens    = last n_phrase tokens of full tokens\n",
    "         e) phrase_log_probs = last n_phrase values of full log_probs\n",
    "         f) phrase_total     = sum(phrase_log_probs)\n",
    "         g) difference       = base_total - sum_before\n",
    "         h) APPEND row\n",
    "    3) Return DataFrame with columns:\n",
    "       phrase_type, phrase, tokens, base_total, sum_before,\n",
    "       log_probs, phrase_total, difference\n",
    "    \"\"\"\n",
    "    # 1) score base_text\n",
    "    print(\"â†’ Scoring base_text aloneâ€¦\")\n",
    "    _, log_probs_base, _ = compute_log_probs_with_median(base_text.strip(), tokenizer, model)\n",
    "    base_total = sum(log_probs_base)\n",
    "    print(f\"   base_total = {base_total:.4f}\\n\")\n",
    "\n",
    "    items = [(\"reference\", ref_phrase)] + [(\"paraphrase\", p) for p in paraphrases]\n",
    "    rows = []\n",
    "\n",
    "    for idx, (ptype, phrase) in enumerate(items, start=1):\n",
    "        print(f\"â†’ [{idx}/{len(items)}] Processing {ptype}â€¦\")\n",
    "\n",
    "        # a) phrase alone â†’ get token count\n",
    "        tokens_phrase, log_probs_phrase, _ = compute_log_probs_with_median(phrase, tokenizer, model)\n",
    "        n_phrase_tokens = len(tokens_phrase)\n",
    "        # b) full sequence\n",
    "        full_text = base_text + phrase\n",
    "        tokens_full, log_probs_full, _ = compute_log_probs_with_median(full_text, tokenizer, model)\n",
    "        # c) full sum\n",
    "        sum_before = sum(log_probs_full)\n",
    "        # d/e) slice last n_phrase_tokens\n",
    "        phrase_tokens    = tokens_full[-n_phrase_tokens:]\n",
    "        phrase_log_probs = log_probs_full[-n_phrase_tokens:]\n",
    "        # f/g) compute sums\n",
    "        phrase_total = sum(phrase_log_probs)\n",
    "        difference   = base_total - sum_before\n",
    "        # h) collect\n",
    "        rows.append({\n",
    "            \"phrase_type\":  ptype,\n",
    "            \"phrase\":       phrase,\n",
    "            \"tokens\":       phrase_tokens,\n",
    "            \"sum_log_probs_base\":   base_total,\n",
    "            \"sum_log_probs_inc_phrase\":   sum_before,\n",
    "            \"difference\":   difference,\n",
    "            \"phrase_log_probs\":    phrase_log_probs,\n",
    "            \"sum_log_probs_phrase\": phrase_total,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        \"phrase_type\", \"phrase\", \"tokens\",\n",
    "        \"sum_log_probs_base\", \"sum_log_probs_inc_phrase\",\n",
    "        \"difference\", \"phrase_log_probs\", \"sum_log_probs_phrase\",\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "74753335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pandas as pd\n",
    "# from typing import List\n",
    "\n",
    "# def compute_log_probs_with_median(text: str, tokenizer, model):\n",
    "#     \"\"\"\n",
    "#     For each token (including the first), returns:\n",
    "#       - tokens: list of tokenizer.convert_ids_to_tokens\n",
    "#       - log_probs: list of log-probs for each token\n",
    "#       - median_logprobs: median log-prob of the distribution at each step\n",
    "#     \"\"\"\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "#     input_ids = inputs[\"input_ids\"]         # shape [1, seq_len]\n",
    "#     # --- ALIGN TOKENS CORRECTLY HERE ---\n",
    "#     tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids)\n",
    "#     logits = outputs.logits                 # [1, seq_len, vocab_size]\n",
    "\n",
    "#     log_probs = []\n",
    "#     median_logprobs = []\n",
    "#     # for each position i, look at logits from i-1 (or the BOS for i=0)\n",
    "#     for i in range(input_ids.size(1)):\n",
    "#         prev_idx = 0 if i == 0 else i - 1\n",
    "#         dist = torch.log_softmax(logits[0, prev_idx], dim=-1)\n",
    "#         log_prob = dist[input_ids[0, i]].item()\n",
    "#         median_lp = float(dist.median().item())\n",
    "#         log_probs.append(log_prob)\n",
    "#         median_logprobs.append(median_lp)\n",
    "\n",
    "#     return tokens, log_probs, median_logprobs\n",
    "\n",
    "\n",
    "# def score_phrases(\n",
    "#     base_text: str,\n",
    "#     ref_phrase: str,\n",
    "#     paraphrases: List[str],\n",
    "#     tokenizer,\n",
    "#     model\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     1) Score base_text â†’ base_total & n_base_tokens\n",
    "#     2) For ref_phrase + each paraphrase:\n",
    "#         â€¢ Score base_text+phrase â†’ tokens_all, log_probs_all\n",
    "#         â€¢ sum_before = sum(log_probs_all)\n",
    "#         â€¢ phrase_tokens = tokens_all[n_base_tokens:]\n",
    "#         â€¢ phrase_log_probs = log_probs_all[n_base_tokens:]\n",
    "#         â€¢ phrase_total = sum(phrase_log_probs)\n",
    "#         â€¢ difference   = base_total - sum_before\n",
    "#         â€¢ PRINT sum_before, phrase_total, phrase, difference\n",
    "#         â€¢ APPEND to rows\n",
    "#     3) Return DataFrame with columns:\n",
    "#        phrase_type, phrase, tokens, base_total, sum_before,\n",
    "#        log_probs, phrase_total, difference\n",
    "#     \"\"\"\n",
    "#     # 1) score base_text alone\n",
    "#     print(\"â†’ Scoring base_text aloneâ€¦\")\n",
    "#     tokens_base, log_probs_base, _ = compute_log_probs_with_median(base_text, tokenizer, model)\n",
    "#     base_total    = sum(log_probs_base)\n",
    "#     n_base_tokens = len(tokens_base)\n",
    "#     print(f\"   base_total = {base_total:.4f} over {n_base_tokens} tokens\\n\")\n",
    "\n",
    "#     all_items = [(\"reference\", ref_phrase)] + [(\"paraphrase\", p) for p in paraphrases]\n",
    "#     rows = []\n",
    "#     total = len(all_items)\n",
    "\n",
    "#     for idx, (ptype, phrase) in enumerate(all_items, start=1):\n",
    "#         print(f\"â†’ [{idx}/{total}] Scoring {ptype}â€¦\")\n",
    "#         text = base_text + phrase\n",
    "#         tokens_all, log_probs_all, _ = compute_log_probs_with_median(text, tokenizer, model)\n",
    "\n",
    "#         sum_before       = sum(log_probs_all)\n",
    "#         # **NOW** this slice actually lines up\n",
    "#         phrase_tokens    = tokens_all[n_base_tokens-1:]\n",
    "#         phrase_log_probs = log_probs_all[n_base_tokens-1:]\n",
    "#         phrase_total     = sum(phrase_log_probs)\n",
    "#         difference       = base_total - sum_before\n",
    "\n",
    "#         rows.append({\n",
    "#             \"phrase_type\":  ptype,\n",
    "#             \"phrase\":       phrase,\n",
    "#             \"tokens\":       phrase_tokens,\n",
    "#             \"base_total\":   base_total,\n",
    "#             \"sum_before\":   sum_before,\n",
    "#             \"log_probs\":    phrase_log_probs,\n",
    "#             \"phrase_total\": phrase_total,\n",
    "#             \"difference\":   difference\n",
    "#         })\n",
    "\n",
    "#     df = pd.DataFrame(rows, columns=[\n",
    "#         \"phrase_type\", \"phrase\", \"tokens\",\n",
    "#         \"base_total\", \"sum_before\", \"log_probs\",\n",
    "#         \"phrase_total\", \"difference\"\n",
    "#     ])\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c56433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Scoring base_text aloneâ€¦\n",
      "   base_total = -1583.6236\n",
      "\n",
      "â†’ [1/37] Processing referenceâ€¦\n",
      "â†’ [2/37] Processing paraphraseâ€¦\n",
      "â†’ [3/37] Processing paraphraseâ€¦\n",
      "â†’ [4/37] Processing paraphraseâ€¦\n",
      "â†’ [5/37] Processing paraphraseâ€¦\n",
      "â†’ [6/37] Processing paraphraseâ€¦\n",
      "â†’ [7/37] Processing paraphraseâ€¦\n",
      "â†’ [8/37] Processing paraphraseâ€¦\n",
      "â†’ [9/37] Processing paraphraseâ€¦\n",
      "â†’ [10/37] Processing paraphraseâ€¦\n",
      "â†’ [11/37] Processing paraphraseâ€¦\n",
      "â†’ [12/37] Processing paraphraseâ€¦\n",
      "â†’ [13/37] Processing paraphraseâ€¦\n",
      "â†’ [14/37] Processing paraphraseâ€¦\n",
      "â†’ [15/37] Processing paraphraseâ€¦\n",
      "â†’ [16/37] Processing paraphraseâ€¦\n",
      "â†’ [17/37] Processing paraphraseâ€¦\n",
      "â†’ [18/37] Processing paraphraseâ€¦\n",
      "â†’ [19/37] Processing paraphraseâ€¦\n",
      "â†’ [20/37] Processing paraphraseâ€¦\n",
      "â†’ [21/37] Processing paraphraseâ€¦\n",
      "â†’ [22/37] Processing paraphraseâ€¦\n",
      "â†’ [23/37] Processing paraphraseâ€¦\n",
      "â†’ [24/37] Processing paraphraseâ€¦\n",
      "â†’ [25/37] Processing paraphraseâ€¦\n",
      "â†’ [26/37] Processing paraphraseâ€¦\n",
      "â†’ [27/37] Processing paraphraseâ€¦\n",
      "â†’ [28/37] Processing paraphraseâ€¦\n",
      "â†’ [29/37] Processing paraphraseâ€¦\n",
      "â†’ [30/37] Processing paraphraseâ€¦\n",
      "â†’ [31/37] Processing paraphraseâ€¦\n",
      "â†’ [32/37] Processing paraphraseâ€¦\n",
      "â†’ [33/37] Processing paraphraseâ€¦\n",
      "â†’ [34/37] Processing paraphraseâ€¦\n",
      "â†’ [35/37] Processing paraphraseâ€¦\n",
      "â†’ [36/37] Processing paraphraseâ€¦\n",
      "â†’ [37/37] Processing paraphraseâ€¦\n"
     ]
    }
   ],
   "source": [
    "results_known = score_phrases(base_known_text, base_phrase, paraphrase_list, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "28d724d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sum_log_probs_base</th>\n",
       "      <th>sum_log_probs_inc_phrase</th>\n",
       "      <th>difference</th>\n",
       "      <th>phrase_log_probs</th>\n",
       "      <th>sum_log_probs_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send you a message</td>\n",
       "      <td>[Ä just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä message]</td>\n",
       "      <td>-1583.623627</td>\n",
       "      <td>-1600.023247</td>\n",
       "      <td>16.399620</td>\n",
       "      <td>[-5.656452178955078, -2.6228346824645996, -0.0...</td>\n",
       "      <td>-16.399620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop you a line</td>\n",
       "      <td>[Ä just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä line]</td>\n",
       "      <td>-1583.623627</td>\n",
       "      <td>-1601.297384</td>\n",
       "      <td>17.673757</td>\n",
       "      <td>[-5.656452178955078, -2.6228346824645996, -0.0...</td>\n",
       "      <td>-17.673757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phrase_type                             phrase  \\\n",
       "8  paraphrase  just wanted to send you a message   \n",
       "4  paraphrase     just wanted to drop you a line   \n",
       "\n",
       "                                             tokens  sum_log_probs_base  \\\n",
       "8  [Ä just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä message]        -1583.623627   \n",
       "4     [Ä just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä line]        -1583.623627   \n",
       "\n",
       "   sum_log_probs_inc_phrase  difference  \\\n",
       "8              -1600.023247   16.399620   \n",
       "4              -1601.297384   17.673757   \n",
       "\n",
       "                                    phrase_log_probs  sum_log_probs_phrase  \n",
       "8  [-5.656452178955078, -2.6228346824645996, -0.0...            -16.399620  \n",
       "4  [-5.656452178955078, -2.6228346824645996, -0.0...            -17.673757  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_known.sort_values(by='difference', inplace=True)\n",
    "results_known.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "63b766ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "results_known.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b1eb1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logsumexp(xs):\n",
    "    m = max(xs)\n",
    "    return m + math.log(sum(math.exp(x - m) for x in xs))\n",
    "\n",
    "def p_ref_among_options(logprob_lists, priors=None, ref_index=0):\n",
    "    L = [sum(lp) for lp in logprob_lists]\n",
    "    if priors is not None:\n",
    "        L = [Li + math.log(pi) for Li, pi in zip(L, priors)]\n",
    "    return math.exp(L[ref_index] - logsumexp(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "31b81bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logsumexp(xs):\n",
    "    m = max(xs)\n",
    "    return m + math.log(sum(math.exp(x - m) for x in xs))\n",
    "\n",
    "def ref_metrics(token_logprob_lists, priors=None, ref_index=0):\n",
    "    # sequence log-likelihoods\n",
    "    L = [sum(lst) for lst in token_logprob_lists]\n",
    "    if priors is not None:\n",
    "        L = [Li + math.log(pi) for Li, pi in zip(L, priors)]\n",
    "\n",
    "    logZ = logsumexp(L)\n",
    "    p_ref = math.exp(L[ref_index] - logZ)\n",
    "\n",
    "    others = [L[i] for i in range(len(L)) if i != ref_index]\n",
    "    log_den_others = logsumexp(others)\n",
    "    llr_ref_vs_rest = L[ref_index] - log_den_others     # = logit(p_ref)\n",
    "    odds_ref = math.exp(llr_ref_vs_rest)\n",
    "\n",
    "    pmf = [math.exp(Li - logZ) for Li in L]            # full normalized PMF\n",
    "\n",
    "    return {\n",
    "        \"p_ref\": p_ref,\n",
    "        \"pmf\": pmf,\n",
    "        \"log_den\": logZ,            # numerically stable\n",
    "        \"den\": math.exp(logZ),      # may overflow/underflow\n",
    "        \"llr_ref_vs_rest\": llr_ref_vs_rest,\n",
    "        \"odds_ref\": odds_ref\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "52272141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12267416407896513"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_known.sort_values(by='phrase_type', ascending=False, inplace=True)\n",
    "\n",
    "p_ref_among_options(results_known['phrase_log_probs'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d5f5a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_ref': 0.12267416407896513,\n",
       " 'pmf': [0.12267416407896513,\n",
       "  0.0017798566555540494,\n",
       "  0.0125798948455079,\n",
       "  0.12657870523569342,\n",
       "  0.06738147396391961,\n",
       "  0.018400070914360057,\n",
       "  0.014097329110571225,\n",
       "  0.013937170982132843,\n",
       "  0.012674830969522089,\n",
       "  0.006810618166642372,\n",
       "  0.0017889109618277436,\n",
       "  0.0062875900431353824,\n",
       "  0.0007158860450894309,\n",
       "  0.004117177263267585,\n",
       "  0.000434469539497419,\n",
       "  0.0028527199424338507,\n",
       "  0.0026874769234762367,\n",
       "  0.12691055836512496,\n",
       "  0.000895849705025534,\n",
       "  0.4537831787918548,\n",
       "  7.693809488150951e-07,\n",
       "  2.992009824435929e-05,\n",
       "  0.000626254290402676,\n",
       "  0.00029521942142091335,\n",
       "  0.00023608819831597998,\n",
       "  0.00015680944972811312,\n",
       "  0.00012433316791233835,\n",
       "  0.00010197514528528433,\n",
       "  3.969938516975028e-05,\n",
       "  2.8915014733866484e-05,\n",
       "  0.0009289088465866804,\n",
       "  2.6158133359340097e-05,\n",
       "  8.432866211287504e-06,\n",
       "  3.666536183207843e-06,\n",
       "  3.538822827199206e-06,\n",
       "  1.1761084605139176e-06,\n",
       "  2.0263060763071356e-07],\n",
       " 'log_den': -15.609484244127495,\n",
       " 'den': 1.6629803877247642e-07,\n",
       " 'llr_ref_vs_rest': -1.9673466902158605,\n",
       " 'odds_ref': 0.13982736978237878}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_metrics(results_known['phrase_log_probs'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1df89ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-849.7581649534404"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results_known['sum_log_probs_phrase'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7caa2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Scoring base_text aloneâ€¦\n",
      "   base_total = -2347.6514\n",
      "\n",
      "â†’ [1/37] Processing referenceâ€¦\n",
      "â†’ [2/37] Processing paraphraseâ€¦\n",
      "â†’ [3/37] Processing paraphraseâ€¦\n",
      "â†’ [4/37] Processing paraphraseâ€¦\n",
      "â†’ [5/37] Processing paraphraseâ€¦\n",
      "â†’ [6/37] Processing paraphraseâ€¦\n",
      "â†’ [7/37] Processing paraphraseâ€¦\n",
      "â†’ [8/37] Processing paraphraseâ€¦\n",
      "â†’ [9/37] Processing paraphraseâ€¦\n",
      "â†’ [10/37] Processing paraphraseâ€¦\n",
      "â†’ [11/37] Processing paraphraseâ€¦\n",
      "â†’ [12/37] Processing paraphraseâ€¦\n",
      "â†’ [13/37] Processing paraphraseâ€¦\n",
      "â†’ [14/37] Processing paraphraseâ€¦\n",
      "â†’ [15/37] Processing paraphraseâ€¦\n",
      "â†’ [16/37] Processing paraphraseâ€¦\n",
      "â†’ [17/37] Processing paraphraseâ€¦\n",
      "â†’ [18/37] Processing paraphraseâ€¦\n",
      "â†’ [19/37] Processing paraphraseâ€¦\n",
      "â†’ [20/37] Processing paraphraseâ€¦\n",
      "â†’ [21/37] Processing paraphraseâ€¦\n",
      "â†’ [22/37] Processing paraphraseâ€¦\n",
      "â†’ [23/37] Processing paraphraseâ€¦\n",
      "â†’ [24/37] Processing paraphraseâ€¦\n",
      "â†’ [25/37] Processing paraphraseâ€¦\n",
      "â†’ [26/37] Processing paraphraseâ€¦\n",
      "â†’ [27/37] Processing paraphraseâ€¦\n",
      "â†’ [28/37] Processing paraphraseâ€¦\n",
      "â†’ [29/37] Processing paraphraseâ€¦\n",
      "â†’ [30/37] Processing paraphraseâ€¦\n",
      "â†’ [31/37] Processing paraphraseâ€¦\n",
      "â†’ [32/37] Processing paraphraseâ€¦\n",
      "â†’ [33/37] Processing paraphraseâ€¦\n",
      "â†’ [34/37] Processing paraphraseâ€¦\n",
      "â†’ [35/37] Processing paraphraseâ€¦\n",
      "â†’ [36/37] Processing paraphraseâ€¦\n",
      "â†’ [37/37] Processing paraphraseâ€¦\n"
     ]
    }
   ],
   "source": [
    "results_unknown = score_phrases(base_unknown_text, base_phrase, paraphrase_list, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3e5fee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sum_log_probs_base</th>\n",
       "      <th>sum_log_probs_inc_phrase</th>\n",
       "      <th>difference</th>\n",
       "      <th>phrase_log_probs</th>\n",
       "      <th>sum_log_probs_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>just wanted to drop you a note</td>\n",
       "      <td>[.just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]</td>\n",
       "      <td>-2347.651417</td>\n",
       "      <td>-2366.505260</td>\n",
       "      <td>18.853843</td>\n",
       "      <td>[-18.542102813720703, -1.2133077383041382, -0....</td>\n",
       "      <td>-21.993745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send you a note</td>\n",
       "      <td>[.just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]</td>\n",
       "      <td>-2347.651417</td>\n",
       "      <td>-2370.240882</td>\n",
       "      <td>22.589465</td>\n",
       "      <td>[-18.542102813720703, -1.2133077383041382, -0....</td>\n",
       "      <td>-25.729366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>only wanted to drop you a note</td>\n",
       "      <td>[.only, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]</td>\n",
       "      <td>-2347.651417</td>\n",
       "      <td>-2370.678002</td>\n",
       "      <td>23.026585</td>\n",
       "      <td>[-20.74664306640625, -2.797487258911133, -0.02...</td>\n",
       "      <td>-26.166487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>simply wanted to drop you a note</td>\n",
       "      <td>[.sim, ply, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]</td>\n",
       "      <td>-2347.651417</td>\n",
       "      <td>-2370.883709</td>\n",
       "      <td>23.232292</td>\n",
       "      <td>[-19.088476181030273, -0.2531338334083557, -3....</td>\n",
       "      <td>-26.372194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop you a message</td>\n",
       "      <td>[.just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä message]</td>\n",
       "      <td>-2347.651417</td>\n",
       "      <td>-2371.118758</td>\n",
       "      <td>23.467341</td>\n",
       "      <td>[-18.542102813720703, -1.2133077383041382, -0....</td>\n",
       "      <td>-26.607242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_type                             phrase  \\\n",
       "0    reference     just wanted to drop you a note   \n",
       "6   paraphrase     just wanted to send you a note   \n",
       "33  paraphrase     only wanted to drop you a note   \n",
       "34  paraphrase   simply wanted to drop you a note   \n",
       "2   paraphrase  just wanted to drop you a message   \n",
       "\n",
       "                                               tokens  sum_log_probs_base  \\\n",
       "0       [.just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]        -2347.651417   \n",
       "6       [.just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]        -2347.651417   \n",
       "33      [.only, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]        -2347.651417   \n",
       "34  [.sim, ply, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]        -2347.651417   \n",
       "2    [.just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä message]        -2347.651417   \n",
       "\n",
       "    sum_log_probs_inc_phrase  difference  \\\n",
       "0               -2366.505260   18.853843   \n",
       "6               -2370.240882   22.589465   \n",
       "33              -2370.678002   23.026585   \n",
       "34              -2370.883709   23.232292   \n",
       "2               -2371.118758   23.467341   \n",
       "\n",
       "                                     phrase_log_probs  sum_log_probs_phrase  \n",
       "0   [-18.542102813720703, -1.2133077383041382, -0....            -21.993745  \n",
       "6   [-18.542102813720703, -1.2133077383041382, -0....            -25.729366  \n",
       "33  [-20.74664306640625, -2.797487258911133, -0.02...            -26.166487  \n",
       "34  [-19.088476181030273, -0.2531338334083557, -3....            -26.372194  \n",
       "2   [-18.542102813720703, -1.2133077383041382, -0....            -26.607242  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_unknown.sort_values(by='difference', inplace=True)\n",
    "results_unknown.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ebf213ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "results_unknown.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c35076cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140128938128587"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_unknown.sort_values(by='phrase_type', ascending=False, inplace=True)\n",
    "\n",
    "p_ref_among_options(results_unknown['phrase_log_probs'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "501ac05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_metrics = ref_metrics(results_unknown['phrase_log_probs'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "677e3f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_ref': 0.9140128938128587,\n",
       " 'pmf': [0.9140128938128587,\n",
       "  0.00016217135470962,\n",
       "  4.784973369683106e-05,\n",
       "  3.571054297152586e-05,\n",
       "  2.1443270550867535e-05,\n",
       "  1.2708328473742358e-05,\n",
       "  7.457871773571731e-06,\n",
       "  5.912474607660524e-06,\n",
       "  3.987683067853873e-06,\n",
       "  2.4226698073304474e-06,\n",
       "  1.8995599646531103e-06,\n",
       "  1.8479749160098645e-06,\n",
       "  1.020550925898058e-06,\n",
       "  7.595025255933304e-07,\n",
       "  3.6509056688697477e-07,\n",
       "  3.408860488113954e-07,\n",
       "  6.500583407921985e-08,\n",
       "  0.0001244046886345057,\n",
       "  0.00017975772915759886,\n",
       "  0.02180682103856921,\n",
       "  0.00018677745182850718,\n",
       "  0.014084886187533164,\n",
       "  0.011466106350459549,\n",
       "  0.009064328332442115,\n",
       "  0.00669993353248597,\n",
       "  0.00638473242985564,\n",
       "  0.005240339306690617,\n",
       "  0.0032569309362411336,\n",
       "  0.0019164574733504629,\n",
       "  0.0014093162653898397,\n",
       "  0.001211408831988399,\n",
       "  0.0006841709377676138,\n",
       "  0.0006740666049030073,\n",
       "  0.0005588811416520615,\n",
       "  0.000384417909883419,\n",
       "  0.0003473590114705051,\n",
       "  4.7526398237230654e-08],\n",
       " 'log_den': -21.903833932897783,\n",
       " 'den': 3.0710422436889723e-10,\n",
       " 'llr_ref_vs_rest': 2.363647321414213,\n",
       " 'odds_ref': 10.629650587654375}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "80c332f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.806970898748768e-10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(-21.993745)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1aaf3714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0710422436889754e-10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(math.exp(lp) for lp in results_unknown['sum_log_probs_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "83d3ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.806970898748768e-10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(-21.993745)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7d4faf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140124674341824"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.806970898748768e-10 / 3.0710422436889754e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fd5dd6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.008312444037906"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.12267416407896513) - math.log(0.9140124674341824)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ccb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['just', 'Ä wanted', 'Ä to', 'Ä drop', 'Ä you', 'Ä a', 'Ä note'],\n",
       " [-13.547368049621582,\n",
       "  -11.230600357055664,\n",
       "  -0.07694364339113235,\n",
       "  -5.435577392578125,\n",
       "  -3.012918472290039,\n",
       "  -0.5511003136634827,\n",
       "  -2.96950101852417],\n",
       " [-16.516681671142578,\n",
       "  -16.516681671142578,\n",
       "  -22.0695858001709,\n",
       "  -21.389036178588867,\n",
       "  -20.315900802612305,\n",
       "  -20.781362533569336,\n",
       "  -21.7308349609375])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = compute_log_probs_with_median(base_phrase, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "39260d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_phrases_no_context(\n",
    "    ref_phrase: str,\n",
    "    paraphrases: List[str],\n",
    "    tokenizer,\n",
    "    model\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Score base_text alone â†’ base_total\n",
    "    2) For each phrase (reference + paraphrases):\n",
    "         a) Get its token count by scoring phrase alone\n",
    "         b) Score base_text + phrase â†’ full tokens & log_probs\n",
    "         c) sum_before = sum(full log_probs)\n",
    "         d) phrase_tokens    = last n_phrase tokens of full tokens\n",
    "         e) phrase_log_probs = last n_phrase values of full log_probs\n",
    "         f) phrase_total     = sum(phrase_log_probs)\n",
    "         g) difference       = base_total - sum_before\n",
    "         h) APPEND row\n",
    "    3) Return DataFrame with columns:\n",
    "       phrase_type, phrase, tokens, base_total, sum_before,\n",
    "       log_probs, phrase_total, difference\n",
    "    \"\"\"\n",
    "    # 1) score base_text\n",
    "    items = [(\"reference\", ref_phrase)] + [(\"paraphrase\", p) for p in paraphrases]\n",
    "    rows = []\n",
    "\n",
    "    for idx, (ptype, phrase) in enumerate(items, start=1):\n",
    "        print(f\"â†’ [{idx}/{len(items)}] Processing {ptype}â€¦\")\n",
    "\n",
    "        # a) phrase alone â†’ get token count\n",
    "        tokens_phrase, log_probs_phrase, _ = compute_log_probs_with_median(phrase, tokenizer, model)\n",
    "        # b) compute sum\n",
    "        phrase_total = sum(log_probs_phrase)\n",
    "        # h) collect\n",
    "        rows.append({\n",
    "            \"phrase_type\":  ptype,\n",
    "            \"phrase\":       phrase,\n",
    "            \"tokens\":       tokens_phrase,\n",
    "            \"log_probs\":    log_probs_phrase,\n",
    "            \"sum_log_probs\": phrase_total,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        \"phrase_type\", \"phrase\", \"tokens\",\n",
    "        \"log_probs\", \"sum_log_probs\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "71e2307f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ [1/37] Processing referenceâ€¦\n",
      "â†’ [2/37] Processing paraphraseâ€¦\n",
      "â†’ [3/37] Processing paraphraseâ€¦\n",
      "â†’ [4/37] Processing paraphraseâ€¦\n",
      "â†’ [5/37] Processing paraphraseâ€¦\n",
      "â†’ [6/37] Processing paraphraseâ€¦\n",
      "â†’ [7/37] Processing paraphraseâ€¦\n",
      "â†’ [8/37] Processing paraphraseâ€¦\n",
      "â†’ [9/37] Processing paraphraseâ€¦\n",
      "â†’ [10/37] Processing paraphraseâ€¦\n",
      "â†’ [11/37] Processing paraphraseâ€¦\n",
      "â†’ [12/37] Processing paraphraseâ€¦\n",
      "â†’ [13/37] Processing paraphraseâ€¦\n",
      "â†’ [14/37] Processing paraphraseâ€¦\n",
      "â†’ [15/37] Processing paraphraseâ€¦\n",
      "â†’ [16/37] Processing paraphraseâ€¦\n",
      "â†’ [17/37] Processing paraphraseâ€¦\n",
      "â†’ [18/37] Processing paraphraseâ€¦\n",
      "â†’ [19/37] Processing paraphraseâ€¦\n",
      "â†’ [20/37] Processing paraphraseâ€¦\n",
      "â†’ [21/37] Processing paraphraseâ€¦\n",
      "â†’ [22/37] Processing paraphraseâ€¦\n",
      "â†’ [23/37] Processing paraphraseâ€¦\n",
      "â†’ [24/37] Processing paraphraseâ€¦\n",
      "â†’ [25/37] Processing paraphraseâ€¦\n",
      "â†’ [26/37] Processing paraphraseâ€¦\n",
      "â†’ [27/37] Processing paraphraseâ€¦\n",
      "â†’ [28/37] Processing paraphraseâ€¦\n",
      "â†’ [29/37] Processing paraphraseâ€¦\n",
      "â†’ [30/37] Processing paraphraseâ€¦\n",
      "â†’ [31/37] Processing paraphraseâ€¦\n",
      "â†’ [32/37] Processing paraphraseâ€¦\n",
      "â†’ [33/37] Processing paraphraseâ€¦\n",
      "â†’ [34/37] Processing paraphraseâ€¦\n",
      "â†’ [35/37] Processing paraphraseâ€¦\n",
      "â†’ [36/37] Processing paraphraseâ€¦\n",
      "â†’ [37/37] Processing paraphraseâ€¦\n"
     ]
    }
   ],
   "source": [
    "phrase_no_context_results = score_phrases_no_context(base_phrase, paraphrase_list, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "de720cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>sum_log_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>just wanted to drop you a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-36.824009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop a note to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä a, Ä note, Ä to, Ä you]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-35.761074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop you a message</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä message]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-39.778634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop a message to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä a, Ä message, Ä to,...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-37.104399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop you a line</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä line]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-34.001307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop a line to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä a, Ä line, Ä to, Ä you]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-38.315746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send you a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-36.229169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send a note to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä a, Ä note, Ä to, Ä you]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-38.441291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send you a message</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä message]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-34.957332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send a message to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä a, Ä message, Ä to,...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-36.873977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send you a line</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä line]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-41.211228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send a line to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä a, Ä line, Ä to, Ä you]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-47.928334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to leave you a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä leave, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-37.398837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to leave a note for you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä leave, Ä a, Ä note, Ä for, ...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-37.701949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to leave you a message</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä leave, Ä you, Ä a, Ä message]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-37.468703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to leave a message for you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä leave, Ä a, Ä message, Ä fo...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-37.449453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to give you a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä give, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-37.434040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to give a note to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä give, Ä a, Ä note, Ä to, Ä you]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-39.546929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to give you a message</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä give, Ä you, Ä a, Ä message]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-39.499083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to give a message to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä give, Ä a, Ä message, Ä to,...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-41.382180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to pass you a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä pass, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-40.869490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to pass a note to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä pass, Ä a, Ä note, Ä to, Ä you]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-40.457631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to pass a message to you</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä pass, Ä a, Ä message, Ä to,...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-41.917173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop ya a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä ya, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-42.407314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to drop a note to ya</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä drop, Ä a, Ä note, Ä to, Ä ya]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-42.006555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send ya a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä ya, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-43.879005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to send a note to ya</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä send, Ä a, Ä note, Ä to, Ä ya]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-44.622148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to leave ya a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä leave, Ä ya, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-43.533917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to leave a note for ya</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä leave, Ä a, Ä note, Ä for, ...</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-43.273208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to give ya a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä give, Ä ya, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-44.844115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to give a note to ya</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä give, Ä a, Ä note, Ä to, Ä ya]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-44.735384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to pass ya a note</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä pass, Ä ya, Ä a, Ä note]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-49.065433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>just wanted to pass a note to ya</td>\n",
       "      <td>[just, Ä wanted, Ä to, Ä pass, Ä a, Ä note, Ä to, Ä ya]</td>\n",
       "      <td>[-13.547368049621582, -11.230600357055664, -0....</td>\n",
       "      <td>-46.829541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>only wanted to drop you a note</td>\n",
       "      <td>[only, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-15.629056930541992, -13.394790649414062, -0....</td>\n",
       "      <td>-56.300932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>simply wanted to drop you a note</td>\n",
       "      <td>[sim, ply, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-14.350906372070312, -14.789237976074219, -8....</td>\n",
       "      <td>-63.827073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>only wanted to send you a note</td>\n",
       "      <td>[only, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-15.629056930541992, -13.394790649414062, -0....</td>\n",
       "      <td>-46.332183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>simply wanted to send you a note</td>\n",
       "      <td>[sim, ply, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]</td>\n",
       "      <td>[-14.350906372070312, -14.789237976074219, -8....</td>\n",
       "      <td>-51.408504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_type                                  phrase  \\\n",
       "0    reference          just wanted to drop you a note   \n",
       "1   paraphrase       just wanted to drop a note to you   \n",
       "2   paraphrase       just wanted to drop you a message   \n",
       "3   paraphrase    just wanted to drop a message to you   \n",
       "4   paraphrase          just wanted to drop you a line   \n",
       "5   paraphrase       just wanted to drop a line to you   \n",
       "6   paraphrase          just wanted to send you a note   \n",
       "7   paraphrase       just wanted to send a note to you   \n",
       "8   paraphrase       just wanted to send you a message   \n",
       "9   paraphrase    just wanted to send a message to you   \n",
       "10  paraphrase          just wanted to send you a line   \n",
       "11  paraphrase       just wanted to send a line to you   \n",
       "12  paraphrase         just wanted to leave you a note   \n",
       "13  paraphrase     just wanted to leave a note for you   \n",
       "14  paraphrase      just wanted to leave you a message   \n",
       "15  paraphrase  just wanted to leave a message for you   \n",
       "16  paraphrase          just wanted to give you a note   \n",
       "17  paraphrase       just wanted to give a note to you   \n",
       "18  paraphrase       just wanted to give you a message   \n",
       "19  paraphrase    just wanted to give a message to you   \n",
       "20  paraphrase          just wanted to pass you a note   \n",
       "21  paraphrase       just wanted to pass a note to you   \n",
       "22  paraphrase    just wanted to pass a message to you   \n",
       "23  paraphrase           just wanted to drop ya a note   \n",
       "24  paraphrase        just wanted to drop a note to ya   \n",
       "25  paraphrase           just wanted to send ya a note   \n",
       "26  paraphrase        just wanted to send a note to ya   \n",
       "27  paraphrase          just wanted to leave ya a note   \n",
       "28  paraphrase      just wanted to leave a note for ya   \n",
       "29  paraphrase           just wanted to give ya a note   \n",
       "30  paraphrase        just wanted to give a note to ya   \n",
       "31  paraphrase           just wanted to pass ya a note   \n",
       "32  paraphrase        just wanted to pass a note to ya   \n",
       "33  paraphrase          only wanted to drop you a note   \n",
       "34  paraphrase        simply wanted to drop you a note   \n",
       "35  paraphrase          only wanted to send you a note   \n",
       "36  paraphrase        simply wanted to send you a note   \n",
       "\n",
       "                                               tokens  \\\n",
       "0        [just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]   \n",
       "1   [just, Ä wanted, Ä to, Ä drop, Ä a, Ä note, Ä to, Ä you]   \n",
       "2     [just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä message]   \n",
       "3   [just, Ä wanted, Ä to, Ä drop, Ä a, Ä message, Ä to,...   \n",
       "4        [just, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä line]   \n",
       "5   [just, Ä wanted, Ä to, Ä drop, Ä a, Ä line, Ä to, Ä you]   \n",
       "6        [just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]   \n",
       "7   [just, Ä wanted, Ä to, Ä send, Ä a, Ä note, Ä to, Ä you]   \n",
       "8     [just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä message]   \n",
       "9   [just, Ä wanted, Ä to, Ä send, Ä a, Ä message, Ä to,...   \n",
       "10       [just, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä line]   \n",
       "11  [just, Ä wanted, Ä to, Ä send, Ä a, Ä line, Ä to, Ä you]   \n",
       "12      [just, Ä wanted, Ä to, Ä leave, Ä you, Ä a, Ä note]   \n",
       "13  [just, Ä wanted, Ä to, Ä leave, Ä a, Ä note, Ä for, ...   \n",
       "14   [just, Ä wanted, Ä to, Ä leave, Ä you, Ä a, Ä message]   \n",
       "15  [just, Ä wanted, Ä to, Ä leave, Ä a, Ä message, Ä fo...   \n",
       "16       [just, Ä wanted, Ä to, Ä give, Ä you, Ä a, Ä note]   \n",
       "17  [just, Ä wanted, Ä to, Ä give, Ä a, Ä note, Ä to, Ä you]   \n",
       "18    [just, Ä wanted, Ä to, Ä give, Ä you, Ä a, Ä message]   \n",
       "19  [just, Ä wanted, Ä to, Ä give, Ä a, Ä message, Ä to,...   \n",
       "20       [just, Ä wanted, Ä to, Ä pass, Ä you, Ä a, Ä note]   \n",
       "21  [just, Ä wanted, Ä to, Ä pass, Ä a, Ä note, Ä to, Ä you]   \n",
       "22  [just, Ä wanted, Ä to, Ä pass, Ä a, Ä message, Ä to,...   \n",
       "23        [just, Ä wanted, Ä to, Ä drop, Ä ya, Ä a, Ä note]   \n",
       "24   [just, Ä wanted, Ä to, Ä drop, Ä a, Ä note, Ä to, Ä ya]   \n",
       "25        [just, Ä wanted, Ä to, Ä send, Ä ya, Ä a, Ä note]   \n",
       "26   [just, Ä wanted, Ä to, Ä send, Ä a, Ä note, Ä to, Ä ya]   \n",
       "27       [just, Ä wanted, Ä to, Ä leave, Ä ya, Ä a, Ä note]   \n",
       "28  [just, Ä wanted, Ä to, Ä leave, Ä a, Ä note, Ä for, ...   \n",
       "29        [just, Ä wanted, Ä to, Ä give, Ä ya, Ä a, Ä note]   \n",
       "30   [just, Ä wanted, Ä to, Ä give, Ä a, Ä note, Ä to, Ä ya]   \n",
       "31        [just, Ä wanted, Ä to, Ä pass, Ä ya, Ä a, Ä note]   \n",
       "32   [just, Ä wanted, Ä to, Ä pass, Ä a, Ä note, Ä to, Ä ya]   \n",
       "33       [only, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]   \n",
       "34   [sim, ply, Ä wanted, Ä to, Ä drop, Ä you, Ä a, Ä note]   \n",
       "35       [only, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]   \n",
       "36   [sim, ply, Ä wanted, Ä to, Ä send, Ä you, Ä a, Ä note]   \n",
       "\n",
       "                                            log_probs  sum_log_probs  \n",
       "0   [-13.547368049621582, -11.230600357055664, -0....     -36.824009  \n",
       "1   [-13.547368049621582, -11.230600357055664, -0....     -35.761074  \n",
       "2   [-13.547368049621582, -11.230600357055664, -0....     -39.778634  \n",
       "3   [-13.547368049621582, -11.230600357055664, -0....     -37.104399  \n",
       "4   [-13.547368049621582, -11.230600357055664, -0....     -34.001307  \n",
       "5   [-13.547368049621582, -11.230600357055664, -0....     -38.315746  \n",
       "6   [-13.547368049621582, -11.230600357055664, -0....     -36.229169  \n",
       "7   [-13.547368049621582, -11.230600357055664, -0....     -38.441291  \n",
       "8   [-13.547368049621582, -11.230600357055664, -0....     -34.957332  \n",
       "9   [-13.547368049621582, -11.230600357055664, -0....     -36.873977  \n",
       "10  [-13.547368049621582, -11.230600357055664, -0....     -41.211228  \n",
       "11  [-13.547368049621582, -11.230600357055664, -0....     -47.928334  \n",
       "12  [-13.547368049621582, -11.230600357055664, -0....     -37.398837  \n",
       "13  [-13.547368049621582, -11.230600357055664, -0....     -37.701949  \n",
       "14  [-13.547368049621582, -11.230600357055664, -0....     -37.468703  \n",
       "15  [-13.547368049621582, -11.230600357055664, -0....     -37.449453  \n",
       "16  [-13.547368049621582, -11.230600357055664, -0....     -37.434040  \n",
       "17  [-13.547368049621582, -11.230600357055664, -0....     -39.546929  \n",
       "18  [-13.547368049621582, -11.230600357055664, -0....     -39.499083  \n",
       "19  [-13.547368049621582, -11.230600357055664, -0....     -41.382180  \n",
       "20  [-13.547368049621582, -11.230600357055664, -0....     -40.869490  \n",
       "21  [-13.547368049621582, -11.230600357055664, -0....     -40.457631  \n",
       "22  [-13.547368049621582, -11.230600357055664, -0....     -41.917173  \n",
       "23  [-13.547368049621582, -11.230600357055664, -0....     -42.407314  \n",
       "24  [-13.547368049621582, -11.230600357055664, -0....     -42.006555  \n",
       "25  [-13.547368049621582, -11.230600357055664, -0....     -43.879005  \n",
       "26  [-13.547368049621582, -11.230600357055664, -0....     -44.622148  \n",
       "27  [-13.547368049621582, -11.230600357055664, -0....     -43.533917  \n",
       "28  [-13.547368049621582, -11.230600357055664, -0....     -43.273208  \n",
       "29  [-13.547368049621582, -11.230600357055664, -0....     -44.844115  \n",
       "30  [-13.547368049621582, -11.230600357055664, -0....     -44.735384  \n",
       "31  [-13.547368049621582, -11.230600357055664, -0....     -49.065433  \n",
       "32  [-13.547368049621582, -11.230600357055664, -0....     -46.829541  \n",
       "33  [-15.629056930541992, -13.394790649414062, -0....     -56.300932  \n",
       "34  [-14.350906372070312, -14.789237976074219, -8....     -63.827073  \n",
       "35  [-15.629056930541992, -13.394790649414062, -0....     -46.332183  \n",
       "36  [-14.350906372070312, -14.789237976074219, -8....     -51.408504  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_no_context_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c5e7a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "phrase_no_context_results.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eebe9711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_ref': 0.02942703608435714,\n",
       " 'pmf': [0.02942703608435714,\n",
       "  0.08518705975877248,\n",
       "  0.00153309522815474,\n",
       "  0.02223181571976897,\n",
       "  0.49502898376941395,\n",
       "  0.006620540822840208,\n",
       "  0.05334360039450061,\n",
       "  0.005839424315377672,\n",
       "  0.19029799722300392,\n",
       "  0.0279927686630204,\n",
       "  0.00036593318764960883,\n",
       "  4.4279190953408884e-07,\n",
       "  0.016561591261916014,\n",
       "  0.012231002196408955,\n",
       "  0.015443991910654193,\n",
       "  0.015744169946309096,\n",
       "  0.01598870792759976,\n",
       "  0.0019328462398086792,\n",
       "  0.00202757444268726,\n",
       "  0.00030843112278552016,\n",
       "  0.0005150109174092671,\n",
       "  0.0007774717419987056,\n",
       "  0.00018063978406505414,\n",
       "  0.00011064914097456609,\n",
       "  0.00016519444097009707,\n",
       "  2.539807869046445e-05,\n",
       "  1.2079753541652437e-05,\n",
       "  3.586496373663749e-05,\n",
       "  4.6547386795370134e-05,\n",
       "  9.675178073893586e-06,\n",
       "  1.0786488684721038e-05,\n",
       "  1.4202459703150708e-07,\n",
       "  1.32861536726391e-06,\n",
       "  1.0233554992817302e-10,\n",
       "  5.5139786685459756e-14,\n",
       "  2.1847368120972857e-06,\n",
       "  1.3638956227979283e-08],\n",
       " 'log_den': -33.29816781462455,\n",
       " 'den': 3.4577171230513927e-15,\n",
       " 'llr_ref_vs_rest': -3.4959727350786665,\n",
       " 'odds_ref': 0.03031924149796808}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_metrics(phrase_no_context_results['log_probs'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895eff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
