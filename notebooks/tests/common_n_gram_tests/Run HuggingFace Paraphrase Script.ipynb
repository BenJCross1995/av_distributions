{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f891be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "from from_root import from_root\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from utils import get_base_location, apply_temp_doc_id\n",
    "from read_and_write_docs import read_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f465872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /Volumes/BCross/paraphrase examples/Wiki-test-Qwen-2-5-0-5B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To the minute (seconds set to \"00\")\n",
    "now = datetime.now()\n",
    "stamp_seconds = now.strftime(\"%Y%m%d%H%M%S\")  # e.g. \"20251008142357\"\n",
    "\n",
    "corpus      = \"Wiki\"\n",
    "data_type   = \"test\"\n",
    "\n",
    "# Set NAS so can run on Windows laptop seamlessly\n",
    "nas_base_loc = get_base_location()\n",
    "\n",
    "known_loc = f\"{nas_base_loc}/datasets/author_verification/{data_type}/{corpus}/known_raw.jsonl\"\n",
    "unknown_loc = f\"{nas_base_loc}/datasets/author_verification/{data_type}/{corpus}/unknown_raw.jsonl\"\n",
    "metadata_loc = f\"{nas_base_loc}/datasets/author_verification/{data_type}/metadata.rds\"\n",
    "model_loc = f\"{nas_base_loc}/models/Qwen 2.5/Qwen2.5-0.5B-Instruct\"\n",
    "save_loc = f\"{nas_base_loc}/paraphrase examples/{corpus}-{data_type}\"\n",
    "completed_loc = f\"{nas_base_loc}/paraphrase examples/{corpus}-{data_type}-completed\"\n",
    "\n",
    "# known_loc = \"/Users/user/Documents/test_data/Wiki/known_raw.jsonl\"\n",
    "# unknown_loc = \"/Users/user/Documents/test_data/Wiki/unknown_raw.jsonl\"\n",
    "# metadata_loc = \"/Users/user/Documents/test_data/metadata.rds\"\n",
    "# model_loc = \"/Users/user/Documents/models/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "paraphrase_model = \"Qwen-2.5-0.5B\"\n",
    "max_tokens   = 5000\n",
    "temperature  = 0.7\n",
    "n_samples    = 10\n",
    "\n",
    "model_str = paraphrase_model.replace(\".\", \"-\").replace(\"_\", \"-\")\n",
    "\n",
    "save_loc = f\"{nas_base_loc}/paraphrase examples/{corpus}-{data_type}-{model_str}\"\n",
    "completed_loc = f\"{nas_base_loc}/paraphrase examples/{corpus}-{data_type}-{model_str}-completed\"\n",
    "print(f\"Saving to: {save_loc}\")\n",
    "\n",
    "script_loc = str(from_root(\"scripts\", \"run_hf_paraphrase_method.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e02f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "known = read_jsonl(known_loc)\n",
    "known = apply_temp_doc_id(known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9806a8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Halidshou, I think you didn't have to make this edit, that omits San Marino from IMF list of advanced economies, beacsue the original text that had San Marino on the list gave a clear source for that.\n",
      "Anyways, yesterday IMF published its new report, in which San Marino was included again on the list, see ibid.\n",
      "If you do, then please tell me if you think that every model - uniquely determined up to isomorphism by an 'infinite' class of second order axioms, can also be uniquely determined up to isomorphism by a 'finite' class of second order axioms?\n",
      "Additionally, can every first order proposition having a model, be contained in a finite class - of first/second order propositions - that uniquely determines a model up to isomorphism ?\n",
      "Anyways, my previous response to you seemed to be a riddle - just because you asked two questions but while you were looking forward to a one-word answer, which is impossible, of course.\n"
     ]
    }
   ],
   "source": [
    "print(known[known['doc_id'] == 'hootmag_text_10'].reset_index().loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33f446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-made problem datasets for speed\n",
    "problem_dataset_base = f\"{nas_base_loc}/datasets/author_verification/{data_type}/{corpus}\"\n",
    "problem_dataset_agg = read_jsonl(f\"{problem_dataset_base}/{corpus}_{data_type}_agg.jsonl\")\n",
    "# problem_dataset_agg = read_jsonl(\"/Users/user/Documents/test_data/Wiki/Wiki_test_agg.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42dbc3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>highest_common_count</th>\n",
       "      <th>highest_common_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Vedant vs Vedant</td>\n",
       "      <td>Vedant</td>\n",
       "      <td>Vedant</td>\n",
       "      <td>vedant_text_2</td>\n",
       "      <td>vedant_text_4</td>\n",
       "      <td>10</td>\n",
       "      <td>this Ġis Ġthe Ġproblem Ġwhen Ġindian Ġnational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Mayalld vs Mayalld</td>\n",
       "      <td>Mayalld</td>\n",
       "      <td>Mayalld</td>\n",
       "      <td>mayalld_text_4</td>\n",
       "      <td>mayalld_text_3</td>\n",
       "      <td>10</td>\n",
       "      <td>Ġunder Ġthe Ġname Ġof Ġthe Ġmaster Ġaccount , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Swift&amp;silent vs Swift&amp;silent</td>\n",
       "      <td>Swift&amp;silent</td>\n",
       "      <td>Swift&amp;silent</td>\n",
       "      <td>swift_silent_text_1</td>\n",
       "      <td>swift_silent_text_2</td>\n",
       "      <td>10</td>\n",
       "      <td>ug ab oy 5 3 5 1 3 6 ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Snowded vs Snowded</td>\n",
       "      <td>Snowded</td>\n",
       "      <td>Snowded</td>\n",
       "      <td>snowded_text_2</td>\n",
       "      <td>snowded_text_1</td>\n",
       "      <td>8</td>\n",
       "      <td>Ġis Ġa Ġbehavioural Ġissue Ġnot Ġa Ġcontent Ġone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>KBlott vs KBlott</td>\n",
       "      <td>KBlott</td>\n",
       "      <td>KBlott</td>\n",
       "      <td>kblott_text_3</td>\n",
       "      <td>kblott_text_1</td>\n",
       "      <td>8</td>\n",
       "      <td>Ġevidence Ġto Ġsupport Ġthe Ġpractice Ġof Ġwit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Richard_Daft vs Richard_Daft</td>\n",
       "      <td>Richard_Daft</td>\n",
       "      <td>Richard_Daft</td>\n",
       "      <td>richard_daft_text_2</td>\n",
       "      <td>richard_daft_text_4</td>\n",
       "      <td>7</td>\n",
       "      <td>Ġpre Ġ 1 8 0 0 Ġcricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>U21980 vs U21980</td>\n",
       "      <td>U21980</td>\n",
       "      <td>U21980</td>\n",
       "      <td>u21980_text_1</td>\n",
       "      <td>u21980_text_5</td>\n",
       "      <td>7</td>\n",
       "      <td>Ġnx iv m Ġand Ġr ani ere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Scheinwerfermann vs Scheinwerfermann</td>\n",
       "      <td>Scheinwerfermann</td>\n",
       "      <td>Scheinwerfermann</td>\n",
       "      <td>scheinwerfermann_text_11</td>\n",
       "      <td>scheinwerfermann_text_10</td>\n",
       "      <td>7</td>\n",
       "      <td>Ġto Ġfind Ġproduction Ġstart Ġand Ġend Ġdates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Thekohser vs Thekohser</td>\n",
       "      <td>Thekohser</td>\n",
       "      <td>Thekohser</td>\n",
       "      <td>thekohser_text_10</td>\n",
       "      <td>thekohser_text_11</td>\n",
       "      <td>7</td>\n",
       "      <td>Ġ 1 6 , 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Yoenit vs Yoenit</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>yoenit_text_4</td>\n",
       "      <td>yoenit_text_2</td>\n",
       "      <td>7</td>\n",
       "      <td>. Ġ' y oen it ' Ġ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  problem      known_author    unknown_author  \\\n",
       "601                      Vedant vs Vedant            Vedant            Vedant   \n",
       "236                    Mayalld vs Mayalld           Mayalld           Mayalld   \n",
       "546          Swift&silent vs Swift&silent      Swift&silent      Swift&silent   \n",
       "506                    Snowded vs Snowded           Snowded           Snowded   \n",
       "138                      KBlott vs KBlott            KBlott            KBlott   \n",
       "426          Richard_Daft vs Richard_Daft      Richard_Daft      Richard_Daft   \n",
       "588                      U21980 vs U21980            U21980            U21980   \n",
       "462  Scheinwerfermann vs Scheinwerfermann  Scheinwerfermann  Scheinwerfermann   \n",
       "565                Thekohser vs Thekohser         Thekohser         Thekohser   \n",
       "661                      Yoenit vs Yoenit            Yoenit            Yoenit   \n",
       "\n",
       "                 known_doc_id            unknown_doc_id  highest_common_count  \\\n",
       "601             vedant_text_2             vedant_text_4                    10   \n",
       "236            mayalld_text_4            mayalld_text_3                    10   \n",
       "546       swift_silent_text_1       swift_silent_text_2                    10   \n",
       "506            snowded_text_2            snowded_text_1                     8   \n",
       "138             kblott_text_3             kblott_text_1                     8   \n",
       "426       richard_daft_text_2       richard_daft_text_4                     7   \n",
       "588             u21980_text_1             u21980_text_5                     7   \n",
       "462  scheinwerfermann_text_11  scheinwerfermann_text_10                     7   \n",
       "565         thekohser_text_10         thekohser_text_11                     7   \n",
       "661             yoenit_text_4             yoenit_text_2                     7   \n",
       "\n",
       "                                  highest_common_ngram  \n",
       "601  this Ġis Ġthe Ġproblem Ġwhen Ġindian Ġnational...  \n",
       "236  Ġunder Ġthe Ġname Ġof Ġthe Ġmaster Ġaccount , ...  \n",
       "546                             ug ab oy 5 3 5 1 3 6 ,  \n",
       "506   Ġis Ġa Ġbehavioural Ġissue Ġnot Ġa Ġcontent Ġone  \n",
       "138  Ġevidence Ġto Ġsupport Ġthe Ġpractice Ġof Ġwit...  \n",
       "426                            Ġpre Ġ 1 8 0 0 Ġcricket  \n",
       "588                           Ġnx iv m Ġand Ġr ani ere  \n",
       "462      Ġto Ġfind Ġproduction Ġstart Ġand Ġend Ġdates  \n",
       "565                                      Ġ 1 6 , 0 0 0  \n",
       "661                                  . Ġ' y oen it ' Ġ  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_probs = problem_dataset_agg[problem_dataset_agg['known_author'] == problem_dataset_agg['unknown_author']].copy()\n",
    "same_probs.sort_values([\"highest_common_count\"], ascending=[False], inplace=True)\n",
    "same_probs[(same_probs['highest_common_count'] >= 3) & (same_probs['highest_common_count'] <= 10)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f8eccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff_probs = problem_dataset_agg[problem_dataset_agg['known_author'] != problem_dataset_agg['unknown_author']].copy()\n",
    "#diff_probs.sort_values([\"highest_common_count\"], ascending=[False], inplace=True)\n",
    "#diff_probs[(diff_probs['highest_common_count'] >= 3) & (diff_probs['highest_common_count'] <= 10)].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12aa35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_dict(df, problem, start=1):\n",
    "    \"\"\"\n",
    "    Build a dictionary of tests from a dataframe with known/unknown doc IDs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns ['problem', 'known_doc_id', 'unknown_doc_id']\n",
    "    problem : str\n",
    "        Problem name to filter on\n",
    "    start : int, optional\n",
    "        Starting number for test IDs (default is 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of tests in the form:\n",
    "        {\n",
    "            \"test_01\": {\"known\": ..., \"unknown\": ...},\n",
    "            \"test_02\": {\"known\": ..., \"unknown\": ...},\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Filter rows for the given problem\n",
    "    sub_df = df[df['problem'] == problem]\n",
    "\n",
    "    # Build dictionary\n",
    "    return {\n",
    "        f\"test_{i:02d}\": {\"known\": row.known_doc_id, \"unknown\": row.unknown_doc_id}\n",
    "        for i, row in enumerate(sub_df.itertuples(index=False), start)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c75262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_test_dict(same_probs, 'Lear_21 vs Lear_21', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2652f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {\n",
    "    \"test_01\": {\"known\": \"vedant_text_5\", \"unknown\": \"vedant_text_4\"},\n",
    "    \"test_02\": {\"known\": \"vedant_text_2\", \"unknown\": \"vedant_text_4\"},\n",
    "    \"test_03\": {\"known\": \"vedant_text_1\", \"unknown\": \"vedant_text_4\"},\n",
    "    \"test_04\": {\"known\": \"mayalld_text_4\", \"unknown\": \"mayalld_text_3\"},\n",
    "    \"test_05\": {\"known\": \"mayalld_text_1\", \"unknown\": \"mayalld_text_3\"},\n",
    "    \"test_06\": {\"known\": \"mayalld_text_2\", \"unknown\": \"mayalld_text_3\"},\n",
    "    \"test_07\": {\"known\": \"swift_silent_text_1\", \"unknown\": \"swift_silent_text_2\"},\n",
    "    \"test_08\": {\"known\": \"swift_silent_text_5\", \"unknown\": \"swift_silent_text_2\"},\n",
    "    \"test_09\": {\"known\": \"swift_silent_text_4\", \"unknown\": \"swift_silent_text_2\"},\n",
    "    \"test_10\": {\"known\": \"snowded_text_2\", \"unknown\": \"snowded_text_1\"},\n",
    "    \"test_11\": {\"known\": \"snowded_text_12\", \"unknown\": \"snowded_text_1\"},\n",
    "    \"test_12\": {\"known\": \"snowded_text_10\", \"unknown\": \"snowded_text_1\"},\n",
    "    'test_13': {'known': 'kblott_text_4', 'unknown': 'kblott_text_1'},\n",
    "    'test_14': {'known': 'kblott_text_3', 'unknown': 'kblott_text_1'},\n",
    "    'test_15': {'known': 'kblott_text_5', 'unknown': 'kblott_text_1'},\n",
    "    'test_16': {'known': 'richard_daft_text_5', 'unknown': 'richard_daft_text_4'},\n",
    "    'test_17': {'known': 'richard_daft_text_2', 'unknown': 'richard_daft_text_4'},\n",
    "    'test_18': {'known': 'richard_daft_text_3', 'unknown': 'richard_daft_text_4'}, \n",
    "    'test_19': {'known': 'u21980_text_1', 'unknown': 'u21980_text_5'},\n",
    "    'test_20': {'known': 'u21980_text_4', 'unknown': 'u21980_text_5'},\n",
    "    'test_21': {'known': 'u21980_text_3', 'unknown': 'u21980_text_5'},\n",
    "    'test_22': {'known': 'scheinwerfermann_text_11', 'unknown': 'scheinwerfermann_text_10'},\n",
    "    'test_23': {'known': 'scheinwerfermann_text_13', 'unknown': 'scheinwerfermann_text_10'},\n",
    "    'test_24': {'known': 'scheinwerfermann_text_12', 'unknown': 'scheinwerfermann_text_10'},\n",
    "    'test_25': {'known': 'thekohser_text_10', 'unknown': 'thekohser_text_11'},\n",
    "    'test_26': {'known': 'thekohser_text_1', 'unknown': 'thekohser_text_11'},\n",
    "    'test_27': {'known': 'thekohser_text_3', 'unknown': 'thekohser_text_11'},\n",
    "    'test_28': {'known': 'yoenit_text_4', 'unknown': 'yoenit_text_2'},\n",
    "    'test_29': {'known': 'yoenit_text_5', 'unknown': 'yoenit_text_2'},\n",
    "    'test_30': {'known': 'yoenit_text_1', 'unknown': 'yoenit_text_2'},\n",
    "    'test_31': {'known': 'hootmag_text_12', 'unknown': 'hootmag_text_13'},\n",
    "    'test_32': {'known': 'hootmag_text_10', 'unknown': 'hootmag_text_13'},\n",
    "    'test_33': {'known': 'hootmag_text_1', 'unknown': 'hootmag_text_13'},\n",
    "    'test_34': {'known': 'icarus3_text_3', 'unknown': 'icarus3_text_4'},\n",
    "    'test_35': {'known': 'icarus3_text_2', 'unknown': 'icarus3_text_4'},\n",
    "    'test_36': {'known': 'icarus3_text_1', 'unknown': 'icarus3_text_4'},\n",
    "    'test_37': {'known': 'rjecina_text_10', 'unknown': 'rjecina_text_11'},\n",
    "    'test_38': {'known': 'rjecina_text_13', 'unknown': 'rjecina_text_11'},\n",
    "    'test_39': {'known': 'rjecina_text_1', 'unknown': 'rjecina_text_11'},\n",
    "    'test_40': {'known': 'lear_21_text_2', 'unknown': 'lear_21_text_3'},\n",
    "    'test_41': {'known': 'lear_21_text_1', 'unknown': 'lear_21_text_3'},\n",
    "    'test_42': {'known': 'lear_21_text_5', 'unknown': 'lear_21_text_3'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60eac76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.executable.replace(\"c:\\\\\", \"C:/\").replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a4adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script_loc.replace(\"C:\\\\\", \"C:/\").replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221d02b",
   "metadata": {},
   "source": [
    "## Test single case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc6060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_num = \"test_32\"\n",
    "# entry = tests[test_num]\n",
    "\n",
    "# known_doc = entry['known']\n",
    "# unknown_doc = entry['unknown']\n",
    "\n",
    "# print(f\"Working on {test_num}: {known_doc} vs {unknown_doc}\")\n",
    "\n",
    "# fake_save_loc = \"/Users/user/Documents/test_data/Wiki/test-docs\"\n",
    "# fake_completed_loc = \"/Users/user/Documents/test_data/Wiki/test-docs-completed\"\n",
    "\n",
    "# env = dict(os.environ, PYTHONUNBUFFERED=\"1\")\n",
    "\n",
    "# cmd = [\n",
    "#     sys.executable.replace(\"c:\\\\\", \"C:/\").replace(\"\\\\\", \"/\"), \"-u\",\n",
    "#     script_loc.replace(\"C:\\\\\", \"C:/\").replace(\"\\\\\", \"/\"),\n",
    "#     \"--known_loc\", known_loc,\n",
    "#     \"--unknown_loc\", unknown_loc,\n",
    "#     \"--metadata_loc\", metadata_loc,\n",
    "#     \"--model_loc\", model_loc,\n",
    "#     \"--prompt_loc\", \"/Users/user/Documents/GitHub/av_distributions/prompts/exhaustive_constrained_ngram_paraphraser_prompt_JSON_newv2.txt\",\n",
    "#     \"--save_loc\", fake_save_loc,\n",
    "#     \"--completed_loc\", fake_completed_loc,\n",
    "#     \"--corpus\", corpus,\n",
    "#     \"--data_type\", data_type,\n",
    "#     \"--known_doc\", known_doc,\n",
    "#     \"--unknown_doc\", unknown_doc,\n",
    "#     \"--openai_model\", openai_model,\n",
    "#     \"--max_tokens\", str(max_tokens),\n",
    "#     \"--temperature\", str(temperature),\n",
    "#     \"--n\", str(n_samples),\n",
    "#     \"--score_texts\"\n",
    "# ]\n",
    "\n",
    "# print(\"Running command:\\n\", \" \".join(cmd), \"\\n\")\n",
    "\n",
    "# process = subprocess.Popen(\n",
    "#     cmd,\n",
    "#     stdout=subprocess.PIPE,\n",
    "#     stderr=subprocess.STDOUT,\n",
    "#     text=True,\n",
    "#     env=env,\n",
    "#     bufsize=1\n",
    "# )\n",
    "\n",
    "# # Live output\n",
    "# try:\n",
    "#     for line in process.stdout:\n",
    "#         print(line, end=\"\")  # stream to notebook/console\n",
    "\n",
    "#     process.stdout.close()\n",
    "#     return_code = process.wait()\n",
    "\n",
    "#     if return_code != 0:\n",
    "#         print(f\"\\n❌ Process exited with code {return_code}\")\n",
    "#     else:\n",
    "#         print(\"\\n✅ Process completed successfully\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n💥 Exception occurred: {e}\")\n",
    "#     process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01554249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = re.search(r'<<<RESULT_JSON_START>>>\\s*(\\{.*\\})\\s*<<<RESULT_JSON_END>>>', result.stdout, re.S)\n",
    "# result_dict = json.loads(m.group(1))\n",
    "# result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21df4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {\n",
    "    'test_31': {'known': 'hootmag_text_12', 'unknown': 'hootmag_text_13'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4503ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test_31: hootmag_text_12 vs hootmag_text_13\n",
      "Working on problem: hootmag_text_12 vs hootmag_text_13\n",
      "Loading tokenizer/model for n-gram scoring\n",
      "Loading local HF model for paraphrasing\n",
      "Loading data\n",
      "Data loaded\n",
      "Getting common n-grams\n",
      "There are 3 n-grams in common!\n",
      "Generating paraphrases with local HF model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mknown_doc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munknown_doc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      9\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[1;32m     10\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-u\u001b[39m\u001b[38;5;124m\"\u001b[39m, script_loc\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n",
      "\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--known_loc\u001b[39m\u001b[38;5;124m\"\u001b[39m, known_loc,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--score_texts\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m     27\u001b[0m ]\n",
      "\u001b[0;32m---> 29\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n",
      "\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1201\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n",
      "\u001b[1;32m   1199\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n",
      "\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n",
      "\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n",
      "\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n",
      "\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n",
      "\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:2046\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   2045\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n",
      "\u001b[0;32m-> 2046\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2047\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n",
      "\u001b[1;32m   2048\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n",
      "\u001b[1;32m   2049\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n",
      "\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:2004\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n",
      "\u001b[1;32m   2002\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   2003\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 2004\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n",
      "\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n",
      "\u001b[1;32m   2007\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n",
      "\u001b[1;32m   2008\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n",
      "\u001b[1;32m   2009\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = dict(os.environ, PYTHONUNBUFFERED=\"1\")\n",
    "\n",
    "for test_num, entry in tests.items():\n",
    "\n",
    "    known_doc = entry['known']\n",
    "    unknown_doc = entry['unknown']\n",
    "    print(f\"Working on {test_num}: {known_doc} vs {unknown_doc}\")\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable.replace(\"c:\\\\\", \"C:/\").replace(\"\\\\\", \"/\"), \"-u\", script_loc.replace(\"C:\\\\\", \"C:/\").replace(\"\\\\\", \"/\"),\n",
    "        \"--known_loc\", known_loc,\n",
    "        \"--unknown_loc\", unknown_loc,\n",
    "        \"--metadata_loc\", metadata_loc,\n",
    "        \"--model_loc\", model_loc,\n",
    "        \"--paraphrase_model_loc\", model_loc,\n",
    "        \"--save_loc\", save_loc,\n",
    "        \"--prompt_loc\", \"/Users/user/Documents/GitHub/av_distributions/prompts/exhaustive_constrained_ngram_paraphraser_prompt_JSON_newv2.txt\",\n",
    "        \"--completed_loc\", completed_loc,\n",
    "        \"--corpus\", corpus,\n",
    "        \"--data_type\", data_type,\n",
    "        \"--known_doc\", known_doc,\n",
    "        \"--unknown_doc\", unknown_doc,\n",
    "        \"--max_tokens\", str(max_tokens),\n",
    "        \"--temperature\", str(temperature),\n",
    "        \"--n\", str(n_samples),\n",
    "        \"--score_texts\"\n",
    "    ]\n",
    "\n",
    "    subprocess.run(cmd, text=True, env=env, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c47540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
