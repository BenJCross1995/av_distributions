{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ef1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "711d8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loc = '/Volumes/BCross/paraphrase examples slurm/Wiki-test/hodja_nasreddin_text_1 vs hodja_nasreddin_text_3.xlsx'\n",
    "phrase_loc = '/Volumes/BCross/paraphrase examples slurm/wiki-phrase-list-reviewed.xlsx'\n",
    "\n",
    "known = pd.read_excel(doc_loc, sheet_name=\"known\")\n",
    "unknown = pd.read_excel(doc_loc, sheet_name=\"unknown\")\n",
    "no_context = pd.read_excel(doc_loc, sheet_name=\"no context\")\n",
    "metadata = pd.read_excel(doc_loc, sheet_name=\"metadata\")\n",
    "\n",
    "phrase_list = pd.read_excel(phrase_loc)\n",
    "phrases_to_keep = phrase_list[phrase_list['keep_phrase'] == 1].copy()\n",
    "\n",
    "# Convert the stringified tuples into actual tuples, then into lists\n",
    "phrases_to_keep['tokens'] = phrases_to_keep['tokens'].apply(lambda x: list(ast.literal_eval(x)) if isinstance(x, str) else list(x))\n",
    "phrases_to_keep = phrases_to_keep[['phrase']]\n",
    "        \n",
    "reference_phrases = no_context[no_context['phrase_type'] == 'reference'].copy()\n",
    "\n",
    "# Perform the merge using the tuple-based key\n",
    "merged_phrases = pd.merge(reference_phrases, phrases_to_keep, on='phrase', how='inner')\n",
    "merged_phrases = merged_phrases[['phrase_num']]\n",
    "\n",
    "no_context = pd.merge(no_context, merged_phrases, on='phrase_num', how='inner')\n",
    "known = pd.merge(known, merged_phrases, on='phrase_num', how='inner')\n",
    "unknown= pd.merge(unknown, merged_phrases, on='phrase_num', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025f951",
   "metadata": {},
   "source": [
    "### Create the base LLR table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6646ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['phrase_num', 'phrase_occurence', 'original_phrase']\n",
    "\n",
    "llr_base = (\n",
    "    pd.concat([known[cols], unknown[cols]], ignore_index=True)\n",
    "      .drop_duplicates()\n",
    "      .sort_values(cols, ascending=[True, True, True])  # explicit\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb28019",
   "metadata": {},
   "source": [
    "### Get phrase statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf78bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) No context phrase stats\n",
    "no_context_phrase_stats = (\n",
    "    no_context\n",
    "    .assign(ref_raw_prob=no_context['raw_prob']\n",
    "        .where(no_context['phrase_type'].eq('reference')))\n",
    "    .groupby('phrase_num', dropna=False)\n",
    "    .agg(\n",
    "        num_phrases=('phrase_num', 'size'),\n",
    "        sum_raw_prob=('raw_prob', 'sum'),\n",
    "        reference_prob=('ref_raw_prob', 'max')\n",
    "    )\n",
    "    .assign(\n",
    "        phrases_kept=lambda d: d['num_phrases'],\n",
    "        pmf_no_context=lambda d: d['reference_prob'].div(d['sum_raw_prob']),\n",
    "        llr_no_context=lambda d: np.where(d['pmf_no_context'] > 0, -np.log10(d['pmf_no_context']), 0.0)\n",
    "    )\n",
    "    .drop(columns=['sum_raw_prob', 'reference_prob'])\n",
    ")\n",
    "\n",
    "# 2) Known phrase stats\n",
    "known_phrase_stats = (\n",
    "    known\n",
    "    .assign(ref_raw_prob=known['raw_prob']\n",
    "        .where(known['phrase_type'].eq('reference')))\n",
    "    .groupby(['phrase_num', 'phrase_occurence'], dropna=False)\n",
    "    .agg(\n",
    "        sum_raw_prob=('raw_prob', 'sum'),\n",
    "        reference_prob=('ref_raw_prob', 'max')\n",
    "    )\n",
    "    .assign(\n",
    "        pmf_known=lambda d: d['reference_prob'].div(d['sum_raw_prob']),\n",
    "        llr_known=lambda d: np.where(d['pmf_known'] > 0, -np.log10(d['pmf_known']), 0.0)\n",
    "    )\n",
    "    .drop(columns=['sum_raw_prob', 'reference_prob'])\n",
    ")\n",
    "\n",
    "# 3) Unknown phrase stats\n",
    "unknown_phrase_stats = (\n",
    "    unknown\n",
    "      .assign(ref_raw_prob=unknown['raw_prob']\n",
    "              .where(unknown['phrase_type'].eq('reference')))\n",
    "      .groupby(['phrase_num', 'phrase_occurence'], dropna=False)\n",
    "      .agg(\n",
    "          sum_raw_prob=('raw_prob', 'sum'),\n",
    "          reference_prob=('ref_raw_prob', 'max')\n",
    "      )\n",
    "      .assign(\n",
    "          pmf_unknown=lambda d: d['reference_prob'].div(d['sum_raw_prob']),\n",
    "          llr_unknown=lambda d: np.where(d['pmf_unknown'] > 0, -np.log10(d['pmf_unknown']), 0.0)\n",
    "      )\n",
    "      .drop(columns=['sum_raw_prob', 'reference_prob'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a47adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join\n",
    "LLR = (\n",
    "    llr_base\n",
    "      .assign(\n",
    "          phrase_num=llr_base['phrase_num'].astype('string'),\n",
    "          phrase_occurence=pd.to_numeric(llr_base['phrase_occurence'], errors='coerce').astype('Int64')\n",
    "      )\n",
    "      .join(no_context_phrase_stats, on='phrase_num', how='left')\n",
    "      .join(known_phrase_stats, on=['phrase_num','phrase_occurence'], how='left')\n",
    "      .join(unknown_phrase_stats, on=['phrase_num','phrase_occurence'], how='left')\n",
    ")\n",
    "\n",
    "LLR = LLR[['phrase_num', 'phrase_occurence', 'original_phrase', 'num_phrases', 'phrases_kept',\n",
    "           'pmf_no_context', 'pmf_known', 'pmf_unknown', 'llr_no_context', 'llr_known', 'llr_unknown']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca16e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_num</th>\n",
       "      <th>phrase_occurence</th>\n",
       "      <th>original_phrase</th>\n",
       "      <th>num_phrases</th>\n",
       "      <th>phrases_kept</th>\n",
       "      <th>pmf_no_context</th>\n",
       "      <th>pmf_known</th>\n",
       "      <th>pmf_unknown</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phrase_01</td>\n",
       "      <td>1</td>\n",
       "      <td>, this is not</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0.488617</td>\n",
       "      <td>0.284798</td>\n",
       "      <td>0.314008</td>\n",
       "      <td>0.311031</td>\n",
       "      <td>0.545463</td>\n",
       "      <td>0.503060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phrase_02</td>\n",
       "      <td>1</td>\n",
       "      <td>, but this</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>1.899381</td>\n",
       "      <td>1.693002</td>\n",
       "      <td>1.617525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phrase_02</td>\n",
       "      <td>2</td>\n",
       "      <td>, but this</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.030038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.899381</td>\n",
       "      <td>1.522332</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phrase_03</td>\n",
       "      <td>1</td>\n",
       "      <td>, you are</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.716338</td>\n",
       "      <td>0.914467</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.144882</td>\n",
       "      <td>0.038832</td>\n",
       "      <td>0.038563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase_04</td>\n",
       "      <td>1</td>\n",
       "      <td>do not have</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.614058</td>\n",
       "      <td>0.291087</td>\n",
       "      <td>3.135517</td>\n",
       "      <td>0.211790</td>\n",
       "      <td>0.535977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phrase_05</td>\n",
       "      <td>1</td>\n",
       "      <td>one of the</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.881184</td>\n",
       "      <td>0.970453</td>\n",
       "      <td>0.959643</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.017890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phrase_06</td>\n",
       "      <td>1</td>\n",
       "      <td>welcome to improve</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.254981</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.593492</td>\n",
       "      <td>1.078997</td>\n",
       "      <td>1.493017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phrase_07</td>\n",
       "      <td>1</td>\n",
       "      <td>you do not</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059834</td>\n",
       "      <td>0.217250</td>\n",
       "      <td>0.377068</td>\n",
       "      <td>1.223055</td>\n",
       "      <td>0.663041</td>\n",
       "      <td>0.423580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phrase_08</td>\n",
       "      <td>1</td>\n",
       "      <td>about this</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0.894526</td>\n",
       "      <td>0.662013</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>0.048407</td>\n",
       "      <td>0.179133</td>\n",
       "      <td>1.236355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phrase_09</td>\n",
       "      <td>1</td>\n",
       "      <td>articles on</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.033955</td>\n",
       "      <td>0.397028</td>\n",
       "      <td>0.425706</td>\n",
       "      <td>1.469096</td>\n",
       "      <td>0.401179</td>\n",
       "      <td>0.370891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phrase_10</td>\n",
       "      <td>1</td>\n",
       "      <td>because the</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>0.216434</td>\n",
       "      <td>1.804979</td>\n",
       "      <td>1.827233</td>\n",
       "      <td>0.664674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phrase_10</td>\n",
       "      <td>2</td>\n",
       "      <td>because the</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.931699</td>\n",
       "      <td>0.301239</td>\n",
       "      <td>1.804979</td>\n",
       "      <td>0.030724</td>\n",
       "      <td>0.521089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phrase_11</td>\n",
       "      <td>1</td>\n",
       "      <td>the subject</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.082468</td>\n",
       "      <td>0.032023</td>\n",
       "      <td>2.327088</td>\n",
       "      <td>1.083715</td>\n",
       "      <td>1.494538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phrase_12</td>\n",
       "      <td>1</td>\n",
       "      <td>this article</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>0.073519</td>\n",
       "      <td>0.142304</td>\n",
       "      <td>1.945226</td>\n",
       "      <td>1.133602</td>\n",
       "      <td>0.846783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_num  phrase_occurence  ... llr_known  llr_unknown\n",
       "0   phrase_01                 1  ...  0.545463     0.503060\n",
       "1   phrase_02                 1  ...  1.693002     1.617525\n",
       "2   phrase_02                 2  ...  1.522332          NaN\n",
       "3   phrase_03                 1  ...  0.038832     0.038563\n",
       "4   phrase_04                 1  ...  0.211790     0.535977\n",
       "5   phrase_05                 1  ...  0.013026     0.017890\n",
       "6   phrase_06                 1  ...  1.078997     1.493017\n",
       "7   phrase_07                 1  ...  0.663041     0.423580\n",
       "8   phrase_08                 1  ...  0.179133     1.236355\n",
       "9   phrase_09                 1  ...  0.401179     0.370891\n",
       "10  phrase_10                 1  ...  1.827233     0.664674\n",
       "11  phrase_10                 2  ...  0.030724     0.521089\n",
       "12  phrase_11                 1  ...  1.083715     1.494538\n",
       "13  phrase_12                 1  ...  1.133602     0.846783\n",
       "\n",
       "[14 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97ec58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLR_summary = pd.DataFrame([{\n",
    "    'num_phrases': LLR['phrase_num'].nunique(),\n",
    "    'phrases_kept': LLR.loc[LLR['phrases_kept'] > 0, 'phrase_num'].nunique(),\n",
    "    'llr_no_context': LLR['llr_no_context'].sum(skipna=True),\n",
    "    'llr_known': LLR['llr_known'].sum(skipna=True),\n",
    "    'llr_unknown': LLR['llr_unknown'].sum(skipna=True),\n",
    "}])\n",
    "\n",
    "LLR_summary = LLR_summary.assign(\n",
    "    normalised_llr_no_context=lambda d: d['llr_no_context'] / d['phrases_kept'],\n",
    "    normalised_llr_known=lambda d: d['llr_known'] / d['phrases_kept'],\n",
    "    normalised_llr_unknown=lambda d: d['llr_unknown'] / d['phrases_kept']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3592a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop any overlapping columns in metadata\n",
    "overlapping_cols = LLR_summary.columns.intersection(metadata.columns)\n",
    "metadata = metadata.drop(columns=overlapping_cols, errors='ignore')\n",
    "\n",
    "# 4. Concatenate new values\n",
    "metadata = pd.concat([metadata, LLR_summary], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45848249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>target</th>\n",
       "      <th>num_phrases</th>\n",
       "      <th>phrases_kept</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>normalised_llr_no_context</th>\n",
       "      <th>normalised_llr_known</th>\n",
       "      <th>normalised_llr_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>18.661448</td>\n",
       "      <td>10.42207</td>\n",
       "      <td>9.763942</td>\n",
       "      <td>1.555121</td>\n",
       "      <td>0.868506</td>\n",
       "      <td>0.813662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  sample_id  ... normalised_llr_known normalised_llr_unknown\n",
       "0      0          1  ...             0.868506               0.813662\n",
       "\n",
       "[1 rows x 17 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dff4f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_doc_pipeline(doc_loc, write_excel=True, save_dir=None, phrase_loc=None):\n",
    "    \"\"\"Pipeline to manually get the results from a document\"\"\"\n",
    "    \n",
    "    doc_name = os.path.basename(doc_loc)\n",
    "    \n",
    "    print(f\"Processing Document: {doc_name}\")\n",
    "    # Read the sheets as dataframes\n",
    "    docs = pd.read_excel(doc_loc, sheet_name=\"docs\")\n",
    "    known = pd.read_excel(doc_loc, sheet_name=\"known\")\n",
    "    unknown = pd.read_excel(doc_loc, sheet_name=\"unknown\")\n",
    "    no_context = pd.read_excel(doc_loc, sheet_name=\"no context\")\n",
    "    metadata = pd.read_excel(doc_loc, sheet_name=\"metadata\")\n",
    "    \n",
    "    # Get phrases to keep\n",
    "    if phrase_loc:\n",
    "        phrase_list = pd.read_excel(phrase_loc)\n",
    "        phrases_to_keep = phrase_list[phrase_list['keep_phrase'] == 1].copy()\n",
    "\n",
    "        # Convert the stringified tuples into actual tuples, then into lists\n",
    "        phrases_to_keep['tokens'] = phrases_to_keep['tokens'].apply(lambda x: list(ast.literal_eval(x)) if isinstance(x, str) else list(x))\n",
    "        phrases_to_keep = phrases_to_keep[['phrase']]\n",
    "        \n",
    "        reference_phrases = no_context[no_context['phrase_type'] == 'reference'].copy()\n",
    "\n",
    "        # Perform the merge using the tuple-based key\n",
    "        merged_phrases = pd.merge(reference_phrases, phrases_to_keep, on='phrase', how='inner')\n",
    "        merged_phrases = merged_phrases[['phrase_num']]\n",
    "\n",
    "        no_context = pd.merge(no_context, merged_phrases, on='phrase_num', how='inner')\n",
    "        known = pd.merge(known, merged_phrases, on='phrase_num', how='inner')\n",
    "        unknown= pd.merge(unknown, merged_phrases, on='phrase_num', how='inner')\n",
    "        \n",
    "    # Get the base LLR table\n",
    "    cols = ['phrase_num', 'phrase_occurence', 'original_phrase']\n",
    "    llr_base = (\n",
    "        pd.concat([known[cols], unknown[cols]], ignore_index=True)\n",
    "        .drop_duplicates()\n",
    "        .sort_values(cols, ascending=[True, True, True])  # explicit\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    # Now get the phrase statistics\n",
    "    # 1) No context phrase stats\n",
    "    no_context_phrase_stats = (\n",
    "        no_context\n",
    "        .assign(ref_raw_prob=no_context['raw_prob']\n",
    "            .where(no_context['phrase_type'].eq('reference')))\n",
    "        .groupby('phrase_num', dropna=False)\n",
    "        .agg(\n",
    "            num_phrases=('phrase_num', 'size'),\n",
    "            sum_raw_prob=('raw_prob', 'sum'),\n",
    "            reference_prob=('ref_raw_prob', 'max')\n",
    "        )\n",
    "        .assign(\n",
    "            phrases_kept=lambda d: d['num_phrases'],\n",
    "            pmf_no_context=lambda d: d['reference_prob'].div(d['sum_raw_prob']),\n",
    "            llr_no_context=lambda d: np.where(d['pmf_no_context'] > 0, -np.log10(d['pmf_no_context']), 0.0)\n",
    "        )\n",
    "        .drop(columns=['sum_raw_prob', 'reference_prob'])\n",
    "    )\n",
    "\n",
    "    # 2) Known phrase stats\n",
    "    known_phrase_stats = (\n",
    "        known\n",
    "        .assign(ref_raw_prob=known['raw_prob']\n",
    "            .where(known['phrase_type'].eq('reference')))\n",
    "        .groupby(['phrase_num', 'phrase_occurence'], dropna=False)\n",
    "        .agg(\n",
    "            sum_raw_prob=('raw_prob', 'sum'),\n",
    "            reference_prob=('ref_raw_prob', 'max')\n",
    "        )\n",
    "        .assign(\n",
    "            pmf_known=lambda d: d['reference_prob'].div(d['sum_raw_prob']),\n",
    "            llr_known=lambda d: np.where(d['pmf_known'] > 0, -np.log10(d['pmf_known']), 0.0)\n",
    "        )\n",
    "        .drop(columns=['sum_raw_prob', 'reference_prob'])\n",
    "    )\n",
    "\n",
    "    # 3) Unknown phrase stats\n",
    "    unknown_phrase_stats = (\n",
    "        unknown\n",
    "        .assign(ref_raw_prob=unknown['raw_prob']\n",
    "                .where(unknown['phrase_type'].eq('reference')))\n",
    "        .groupby(['phrase_num', 'phrase_occurence'], dropna=False)\n",
    "        .agg(\n",
    "            sum_raw_prob=('raw_prob', 'sum'),\n",
    "            reference_prob=('ref_raw_prob', 'max')\n",
    "        )\n",
    "        .assign(\n",
    "            pmf_unknown=lambda d: d['reference_prob'].div(d['sum_raw_prob']),\n",
    "            llr_unknown=lambda d: np.where(d['pmf_unknown'] > 0, -np.log10(d['pmf_unknown']), 0.0)\n",
    "        )\n",
    "        .drop(columns=['sum_raw_prob', 'reference_prob'])\n",
    "    )\n",
    "    \n",
    "    # Create final LLR table\n",
    "    LLR = (\n",
    "        llr_base\n",
    "        .assign(\n",
    "            phrase_num=llr_base['phrase_num'].astype('string'),\n",
    "            phrase_occurence=pd.to_numeric(llr_base['phrase_occurence'], errors='coerce').astype('Int64')\n",
    "        )\n",
    "        .join(no_context_phrase_stats, on='phrase_num', how='left')\n",
    "        .join(known_phrase_stats, on=['phrase_num','phrase_occurence'], how='left').fillna(0)\n",
    "        .join(unknown_phrase_stats, on=['phrase_num','phrase_occurence'], how='left').fillna(0)\n",
    "    )\n",
    "\n",
    "    LLR = LLR[['phrase_num', 'phrase_occurence', 'original_phrase', 'num_phrases', 'phrases_kept',\n",
    "            'pmf_no_context', 'pmf_known', 'pmf_unknown', 'llr_no_context', 'llr_known', 'llr_unknown']]\n",
    "    \n",
    "    # Summarise the LLR table for the metadata\n",
    "    LLR_summary = pd.DataFrame([{\n",
    "    'num_phrases': LLR['phrase_num'].nunique(),\n",
    "    'phrases_kept': LLR.loc[LLR['phrases_kept'] > 0, 'phrase_num'].nunique(),\n",
    "    'llr_no_context': LLR['llr_no_context'].sum(skipna=True),\n",
    "    'llr_known': LLR['llr_known'].sum(skipna=True),\n",
    "    'llr_unknown': LLR['llr_unknown'].sum(skipna=True),\n",
    "    }])\n",
    "\n",
    "    LLR_summary = LLR_summary.assign(\n",
    "        normalised_llr_no_context=lambda d: d['llr_no_context'] / d['phrases_kept'],\n",
    "        normalised_llr_known=lambda d: d['llr_known'] / d['phrases_kept'],\n",
    "        normalised_llr_unknown=lambda d: d['llr_unknown'] / d['phrases_kept']\n",
    "    )\n",
    "    \n",
    "    # Create final metadata table\n",
    "    # 1. Drop any overlapping columns in metadata\n",
    "    overlapping_cols = LLR_summary.columns.intersection(metadata.columns)\n",
    "    metadata_final = metadata.drop(columns=overlapping_cols, errors='ignore')\n",
    "\n",
    "    # 2. Concatenate new values\n",
    "    metadata_final = pd.concat([metadata_final, LLR_summary], axis=1)\n",
    "    \n",
    "    if write_excel:\n",
    "        \n",
    "        print(\"Writing file\")\n",
    "        path = Path(save_dir + '/' + doc_name)\n",
    "        \n",
    "        # Choose writer mode safely\n",
    "        writer_mode = \"a\" if path.exists() else \"w\"\n",
    "        writer_kwargs = {\"engine\": \"openpyxl\", \"mode\": writer_mode}\n",
    "        if writer_mode == \"a\":\n",
    "            writer_kwargs[\"if_sheet_exists\"] = \"replace\"  # only valid in append mode\n",
    "        \n",
    "\n",
    "        with pd.ExcelWriter(path, **writer_kwargs) as writer:\n",
    "            # Write sheets\n",
    "            docs.to_excel(writer, index=False, sheet_name=\"docs\")\n",
    "            known.to_excel(writer, index=False, sheet_name=\"known\")\n",
    "            unknown.to_excel(writer, index=False, sheet_name=\"unknown\")\n",
    "            no_context.to_excel(writer, index=False, sheet_name=\"no context\")\n",
    "            LLR.to_excel(writer, index=False, sheet_name=\"LLR\")\n",
    "            metadata_final.to_excel(writer, index=False, sheet_name=\"metadata\")\n",
    "            \n",
    "            # wb = writer.book\n",
    "            # wb._sheets = [\"docs\", \"metadata\", \"no context\", \"known\", \"unknown\", \"LLR\"]\n",
    "    \n",
    "    return metadata_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ce25a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing file 1 out of 65\n",
      "Processing Document: irvine22_text_1 vs itub_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 2 out of 65\n",
      "Processing Document: honestopl_text_5 vs hootmag_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 3 out of 65\n",
      "Processing Document: hootmag_text_1 vs iain99_text_5.xlsx\n",
      "Writing file\n",
      "Completing file 4 out of 65\n",
      "Processing Document: jc37_text_1 vs jeffrey_vernon_merkey_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 5 out of 65\n",
      "Processing Document: intothefire_text_2 vs intothefire_text_12.xlsx\n",
      "Writing file\n",
      "Completing file 6 out of 65\n",
      "Processing Document: icarus3_text_2 vs icarus3_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 7 out of 65\n",
      "Processing Document: icarus3_text_1 vs icarus3_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 8 out of 65\n",
      "Processing Document: intangible_text_3 vs intothefire_text_12.xlsx\n",
      "Writing file\n",
      "Completing file 9 out of 65\n",
      "Processing Document: jerryfriedman_text_2 vs jimharlow99_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 10 out of 65\n",
      "Processing Document: honestopl_text_5 vs honestopl_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 11 out of 65\n",
      "Processing Document: irvine22_text_4 vs itub_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 12 out of 65\n",
      "Processing Document: hootmag_text_10 vs iain99_text_5.xlsx\n",
      "Writing file\n",
      "Completing file 13 out of 65\n",
      "Processing Document: ivoshandor_text_4 vs jasper_deng_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 14 out of 65\n",
      "Processing Document: hootmag_text_10 vs hootmag_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 15 out of 65\n",
      "Processing Document: jerryfriedman_text_1 vs jimharlow99_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 16 out of 65\n",
      "Processing Document: hodja_nasreddin_text_11 vs hodja_nasreddin_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 17 out of 65\n",
      "Processing Document: jeffrey_vernon_merkey_text_1 vs jeffrey_vernon_merkey_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 18 out of 65\n",
      "Processing Document: honestopl_text_4 vs hootmag_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 19 out of 65\n",
      "Processing Document: intothefire_text_10 vs intothefire_text_12.xlsx\n",
      "Writing file\n",
      "Completing file 20 out of 65\n",
      "Processing Document: ivoshandor_text_2 vs ivoshandor_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 21 out of 65\n",
      "Processing Document: jerekrischel_text_10 vs jerryfriedman_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 22 out of 65\n",
      "Processing Document: hodja_nasreddin_text_10 vs hodja_nasreddin_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 23 out of 65\n",
      "Processing Document: hootmag_text_12 vs iain99_text_5.xlsx\n",
      "Writing file\n",
      "Completing file 24 out of 65\n",
      "Processing Document: jeffrey_vernon_merkey_text_11 vs jerekrischel_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 25 out of 65\n",
      "Processing Document: intangible_text_1 vs intothefire_text_12.xlsx\n",
      "Writing file\n",
      "Completing file 26 out of 65\n",
      "Processing Document: jerryfriedman_text_4 vs jimharlow99_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 27 out of 65\n",
      "Processing Document: jeffrey_vernon_merkey_text_3 vs jeffrey_vernon_merkey_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 28 out of 65\n",
      "Processing Document: intothefire_text_2 vs irvine22_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 29 out of 65\n",
      "Processing Document: itub_text_3 vs ivoshandor_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 30 out of 65\n",
      "Processing Document: icarus3_text_3 vs icarus3_text_4.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/GitHub/av_distributions/my_venv/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file\n",
      "Completing file 31 out of 65\n",
      "Processing Document: jerryfriedman_text_4 vs jerryfriedman_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 32 out of 65\n",
      "Processing Document: jc37_text_1 vs jc37_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 33 out of 65\n",
      "Processing Document: honestopl_text_3 vs hootmag_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 34 out of 65\n",
      "Processing Document: ivoshandor_text_2 vs jasper_deng_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 35 out of 65\n",
      "Processing Document: intothefire_text_10 vs irvine22_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 36 out of 65\n",
      "Processing Document: icarus3_text_1 vs intangible_text_2.xlsx\n",
      "Writing file\n",
      "Completing file 37 out of 65\n",
      "Processing Document: jbmurray_text_5 vs jbmurray_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 38 out of 65\n",
      "Processing Document: iain99_text_1 vs icarus3_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 39 out of 65\n",
      "Processing Document: jerryfriedman_text_1 vs jerryfriedman_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 40 out of 65\n",
      "Processing Document: jeffrey_vernon_merkey_text_1 vs jerekrischel_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 41 out of 65\n",
      "Processing Document: intothefire_text_1 vs irvine22_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 42 out of 65\n",
      "Processing Document: honestopl_text_4 vs honestopl_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 43 out of 65\n",
      "Processing Document: jbmurray_text_5 vs jc37_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 44 out of 65\n",
      "Processing Document: irvine22_text_4 vs irvine22_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 45 out of 65\n",
      "Processing Document: hodja_nasreddin_text_10 vs honestopl_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 46 out of 65\n",
      "Processing Document: jeffrey_vernon_merkey_text_3 vs jerekrischel_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 47 out of 65\n",
      "Processing Document: iain99_text_2 vs icarus3_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 48 out of 65\n",
      "Processing Document: jéské_couriano_text_5 vs kashmiri_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 49 out of 65\n",
      "Processing Document: iain99_text_3 vs icarus3_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 50 out of 65\n",
      "Processing Document: jasper_deng_text_3 vs jasper_deng_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 51 out of 65\n",
      "Processing Document: jc37_text_2 vs jeffrey_vernon_merkey_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 52 out of 65\n",
      "Processing Document: hootmag_text_1 vs hootmag_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 53 out of 65\n",
      "Processing Document: hodja_nasreddin_text_1 vs honestopl_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 54 out of 65\n",
      "Processing Document: hodja_nasreddin_text_1 vs hodja_nasreddin_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 55 out of 65\n",
      "Processing Document: intothefire_text_1 vs intothefire_text_12.xlsx\n",
      "Writing file\n",
      "Completing file 56 out of 65\n",
      "Processing Document: jc37_text_10 vs jeffrey_vernon_merkey_text_10.xlsx\n",
      "Writing file\n",
      "Completing file 57 out of 65\n",
      "Processing Document: hootmag_text_12 vs hootmag_text_13.xlsx\n",
      "Writing file\n",
      "Completing file 58 out of 65\n",
      "Processing Document: irvine22_text_1 vs irvine22_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 59 out of 65\n",
      "Processing Document: hodja_nasreddin_text_11 vs honestopl_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 60 out of 65\n",
      "Processing Document: irvine22_text_2 vs irvine22_text_3.xlsx\n",
      "Writing file\n",
      "Completing file 61 out of 65\n",
      "Processing Document: irvine22_text_2 vs itub_text_4.xlsx\n",
      "Writing file\n",
      "Completing file 62 out of 65\n",
      "Processing Document: intangible_text_5 vs intangible_text_2.xlsx\n",
      "Writing file\n",
      "Completing file 63 out of 65\n",
      "Processing Document: honestopl_text_3 vs honestopl_text_1.xlsx\n",
      "Writing file\n",
      "Completing file 64 out of 65\n",
      "Processing Document: intangible_text_5 vs intothefire_text_12.xlsx\n",
      "Writing file\n",
      "Completing file 65 out of 65\n",
      "Processing Document: intangible_text_3 vs intangible_text_2.xlsx\n",
      "Writing file\n",
      "All files complete\n"
     ]
    }
   ],
   "source": [
    "orig_dir = \"/Volumes/BCross/paraphrase examples slurm/Wiki-test-llama-raw\"\n",
    "save_dir = \"/Volumes/BCross/paraphrase examples slurm/Wiki-test-llama-filtered\"\n",
    "phrase_loc = '/Volumes/BCross/paraphrase examples slurm/wiki-phrase-list-reviewed.xlsx'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Get all .xlsx files from the original directory\n",
    "xlsx_files = glob.glob(os.path.join(orig_dir, \"*.xlsx\"))\n",
    "\n",
    "all_metadata = []\n",
    "\n",
    "for i, file_path in enumerate(xlsx_files, start=1):\n",
    "    print(f\"Completing file {i} out of {len(xlsx_files)}\")\n",
    "    \n",
    "    try:\n",
    "        metadata = create_results_doc_pipeline(file_path, write_excel=True, save_dir=save_dir, phrase_loc=phrase_loc)\n",
    "        all_metadata.append(metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"File failed: {file_path}\\nError: {e}\")\n",
    "        continue\n",
    "\n",
    "# Combine all metadata after processing\n",
    "if all_metadata:\n",
    "    full_metadata = pd.concat(all_metadata, ignore_index=True)\n",
    "    # You can optionally save full_metadata here\n",
    "else:\n",
    "    full_metadata = pd.DataFrame()\n",
    "\n",
    "print(\"All files complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48681998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>target</th>\n",
       "      <th>num_phrases</th>\n",
       "      <th>phrases_kept</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>normalised_llr_no_context</th>\n",
       "      <th>normalised_llr_known</th>\n",
       "      <th>normalised_llr_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>14.326749</td>\n",
       "      <td>8.385606</td>\n",
       "      <td>7.786461</td>\n",
       "      <td>1.193896</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.648872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_10</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>24.738077</td>\n",
       "      <td>3.826455</td>\n",
       "      <td>6.932723</td>\n",
       "      <td>2.248916</td>\n",
       "      <td>0.347860</td>\n",
       "      <td>0.630248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_11</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12.045893</td>\n",
       "      <td>3.717721</td>\n",
       "      <td>3.238463</td>\n",
       "      <td>1.505737</td>\n",
       "      <td>0.464715</td>\n",
       "      <td>0.404808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>honestopl_text_1</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>14.044844</td>\n",
       "      <td>8.395489</td>\n",
       "      <td>4.684318</td>\n",
       "      <td>1.755606</td>\n",
       "      <td>1.049436</td>\n",
       "      <td>0.585540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>honestopl_text_1</td>\n",
       "      <td>hodja_nasreddin_text_10</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.673620</td>\n",
       "      <td>2.237052</td>\n",
       "      <td>1.711093</td>\n",
       "      <td>1.084203</td>\n",
       "      <td>0.279632</td>\n",
       "      <td>0.213887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>JerryFriedman vs JerryFriedman</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>jerryfriedman_text_3</td>\n",
       "      <td>jerryfriedman_text_4</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>36.120316</td>\n",
       "      <td>12.294378</td>\n",
       "      <td>19.388142</td>\n",
       "      <td>1.806016</td>\n",
       "      <td>0.614719</td>\n",
       "      <td>0.969407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>JerryFriedman vs Jimharlow99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>Jimharlow99</td>\n",
       "      <td>jimharlow99_text_10</td>\n",
       "      <td>jerryfriedman_text_1</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>16.917944</td>\n",
       "      <td>3.658647</td>\n",
       "      <td>2.726263</td>\n",
       "      <td>1.691794</td>\n",
       "      <td>0.365865</td>\n",
       "      <td>0.272626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>JerryFriedman vs Jimharlow99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>Jimharlow99</td>\n",
       "      <td>jimharlow99_text_10</td>\n",
       "      <td>jerryfriedman_text_2</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16.362831</td>\n",
       "      <td>2.330475</td>\n",
       "      <td>2.988822</td>\n",
       "      <td>2.045354</td>\n",
       "      <td>0.291309</td>\n",
       "      <td>0.373603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>JerryFriedman vs Jimharlow99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>Jimharlow99</td>\n",
       "      <td>jimharlow99_text_10</td>\n",
       "      <td>jerryfriedman_text_4</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>16.995738</td>\n",
       "      <td>2.342031</td>\n",
       "      <td>3.040590</td>\n",
       "      <td>1.888415</td>\n",
       "      <td>0.260226</td>\n",
       "      <td>0.337843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>Jéské_Couriano vs Kashmiri</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Jéské_Couriano</td>\n",
       "      <td>Kashmiri</td>\n",
       "      <td>kashmiri_text_3</td>\n",
       "      <td>jéské_couriano_text_5</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>21.149549</td>\n",
       "      <td>5.141273</td>\n",
       "      <td>4.443301</td>\n",
       "      <td>1.922686</td>\n",
       "      <td>0.467388</td>\n",
       "      <td>0.403936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  sample_id  ... normalised_llr_known normalised_llr_unknown\n",
       "0       0          1  ...             0.698800               0.648872\n",
       "1       1          2  ...             0.347860               0.630248\n",
       "2       2          3  ...             0.464715               0.404808\n",
       "3       3          4  ...             1.049436               0.585540\n",
       "4       4          5  ...             0.279632               0.213887\n",
       "..    ...        ...  ...                  ...                    ...\n",
       "60     92         93  ...             0.614719               0.969407\n",
       "61     93         94  ...             0.365865               0.272626\n",
       "62     94         95  ...             0.291309               0.373603\n",
       "63     95         96  ...             0.260226               0.337843\n",
       "64    101        102  ...             0.467388               0.403936\n",
       "\n",
       "[65 rows x 17 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_metadata = full_metadata.sort_values(by=\"index\").reset_index(drop=True)\n",
    "full_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49e16488",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_save_loc = '/Volumes/BCross/paraphrase examples slurm/wiki-test-llama-filtered-results.xlsx'\n",
    "\n",
    "full_metadata.to_excel(result_save_loc, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
