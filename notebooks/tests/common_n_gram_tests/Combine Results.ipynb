{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03eac0ed",
   "metadata": {},
   "source": [
    "# Combine Test Results\n",
    "\n",
    "This notebook is used to combine the results for the different models used to score the Author Verification method utilising common n-grams between texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7a21b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from from_root import from_root\n",
    "from glob import glob\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from performance import performance\n",
    "from read_and_write_docs import read_excel_sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccaf2a",
   "metadata": {},
   "source": [
    "## Load data and set save locations\n",
    "\n",
    "Load all of the results data into the notebook and set the save locations. I call each dataframe by the model used to score the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a46955f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_model_name(df, model, col_after='sample_id'):\n",
    "    \"\"\"Insert the model name after user defined column default sample_id\"\"\"\n",
    "    insert_loc = df.columns.get_loc(col_after) + 1\n",
    "    df.insert(insert_loc, \"model\", model)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "49e94ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results in LambdaG Table 224\n",
      "Number of problems Qwen Table 661\n",
      "Number of problems Gemma Table 661\n",
      "Number of problems Llama Table 661\n",
      "Number of problems GPT 2 Table 661\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_loc = '/Volumes/BCross/paraphrase examples slurm'\n",
    "# base_loc = '/Users/user/Library/CloudStorage/OneDrive-TheUniversityofManchester/paraphrase examples slurm'\n",
    "\n",
    "phrases = pd.read_excel(f\"{base_loc}/wiki-phrase-list-reviewed.xlsx\")\n",
    "phrases = phrases[phrases['keep_phrase'] == 1]\n",
    "\n",
    "results_save_loc = f\"{base_loc}/wiki-test-results.xlsx\"\n",
    "agg_results_save_loc = f\"{base_loc}/wiki-test-results_agg.xlsx\"\n",
    "\n",
    "## ---- LambdaG Results ---- ##\n",
    "lambdag_metrics = pd.read_csv(f\"{base_loc}/LambdaG_results.csv\")\n",
    "lambdag_metrics['corpus']='Wiki'\n",
    "lambdag_metrics = lambdag_metrics[['problem', 'corpus', 'known_author', 'unknown_author', 'target', 'score', 'Magnitude']]\n",
    "\n",
    "## ---- Qwen Results ---- ##\n",
    "qwen_metrics = pd.read_excel(f\"{base_loc}/qwen results/filtered_results.xlsx\")\n",
    "qwen_metrics = insert_model_name(qwen_metrics, \"Qwen\")\n",
    "\n",
    "## ---- Google Gemma Results ---- ##\n",
    "gemma_metrics = pd.read_excel(f'{base_loc}/gemma results/filtered_results.xlsx')\n",
    "gemma_metrics = insert_model_name(gemma_metrics, \"Gemma\")\n",
    "\n",
    "## ---- Meta Llama Results ---- ##\n",
    "llama_metrics = pd.read_excel(f'{base_loc}/llama results/filtered_results.xlsx')\n",
    "llama_metrics = insert_model_name(llama_metrics, \"Llama\")\n",
    "\n",
    "## ---- GPT 2 Results ---- ##\n",
    "gpt2_metrics = pd.read_excel(f'{base_loc}/gpt2 results/filtered_results.xlsx')\n",
    "gpt2_metrics = insert_model_name(gpt2_metrics, \"GPT2\")\n",
    "\n",
    "## ---- Print number of records in each table ---- ##\n",
    "print(f\"Number of results in LambdaG Table {len(lambdag_metrics)}\")\n",
    "print(f\"Number of problems Qwen Table {len(qwen_metrics)}\")\n",
    "print(f\"Number of problems Gemma Table {len(gemma_metrics)}\")\n",
    "print(f\"Number of problems Llama Table {len(llama_metrics)}\")\n",
    "print(f\"Number of problems GPT 2 Table {len(gpt2_metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b612291",
   "metadata": {},
   "source": [
    "## Merge dataframes\n",
    "\n",
    "The function below allows us to merge the dataframes together in a loop keeping the columns the user wishes and also what columns are used for metrics.\n",
    "\n",
    "The dataframes are given as a dictionary with the key being the suffix in the new metric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "28fb2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_model_metrics(model_dfs, id_cols, metric_cols):\n",
    "    \"\"\"\n",
    "    model_dfs: dict mapping model name -> dataframe\n",
    "               e.g. {\"gemma\": gemma_metrics, \"llama\": llama_metrics}\n",
    "    id_cols: list of columns to join on\n",
    "    metric_cols: list of metric columns to rename per model\n",
    "    \"\"\"\n",
    "    columns_to_keep = id_cols + metric_cols\n",
    "    prepared = []\n",
    "\n",
    "    for model_name, df in model_dfs.items():\n",
    "        tmp = df[columns_to_keep].copy()\n",
    "        tmp = tmp.rename(\n",
    "            columns={col: f\"{col}_{model_name}\" for col in metric_cols}\n",
    "        )\n",
    "        prepared.append(tmp)\n",
    "\n",
    "    # Outer-join them all on id_cols\n",
    "    merged = reduce(\n",
    "        lambda left, right: left.merge(right, on=id_cols, how=\"outer\"),\n",
    "        prepared\n",
    "    )\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6f051eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that identify a row (join keys)\n",
    "id_cols = [\n",
    "    \"index\", \"sample_id\", \"problem\", \"corpus\", \n",
    "    \"known_author\", \"unknown_author\", \"known_doc_id\", \"unknown_doc_id\",\n",
    "    \"target\",\n",
    "]\n",
    "\n",
    "# Metric columns you don’t want to join on\n",
    "metric_cols = [\"llr_unknown\"]\n",
    "\n",
    "model_dfs = {\n",
    "    \"gpt2\": gpt2_metrics,\n",
    "    \"qwen\": qwen_metrics,\n",
    "    \"gemma\": gemma_metrics,\n",
    "    \"llama\": llama_metrics,\n",
    "}\n",
    "\n",
    "merged = merge_model_metrics(\n",
    "    model_dfs,\n",
    "    id_cols=id_cols,\n",
    "    metric_cols=metric_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e47f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged.to_excel(results_save_loc, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683b4e9",
   "metadata": {},
   "source": [
    "## Aggregate the dataframe\n",
    "\n",
    "Here we aggregate the dataframe to gather the results together for each problem rather than for each known and unknown document pair in the the problems. Here a sum is used. I also count the number of rows for which there is data for each problem, the problems should all have 3 rows of data. Any that don't should be filtered out before final results, or the code to get the paraphrases should be run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "dbf2ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that identify a group\n",
    "agg_cols = [\n",
    "    \"problem\", \"corpus\", \"known_author\", \"unknown_author\", \"target\"\n",
    "]\n",
    "\n",
    "# Metric columns you don’t want to join on\n",
    "metric_cols_prefix = [\"llr_unknown\"]\n",
    "\n",
    "# we treat these as prefixes in the merged df\n",
    "metric_prefixes = [f\"{m}_\" for m in metric_cols_prefix]   # -> [\"llr_unknown_\"]\n",
    "\n",
    "# ---- aggregation helper ----\n",
    "def aggregate_by_prefix(df, group_cols, metric_prefixes):\n",
    "    # Find all columns whose names start with any of the prefixes\n",
    "    metric_cols = [\n",
    "        col for col in df.columns\n",
    "        if any(col.startswith(pref) for pref in metric_prefixes)\n",
    "    ]\n",
    "\n",
    "    # Build named aggregations: one SUM and one COUNT (non-null) per metric column\n",
    "    agg_spec = {\n",
    "        **{f\"{col}_count\": (col, \"count\") for col in metric_cols},\n",
    "        **{f\"{col}_sum\":   (col, \"sum\")   for col in metric_cols},\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .groupby(group_cols, dropna=False)\n",
    "        .agg(**agg_spec)\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c5da6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = aggregate_by_prefix(\n",
    "    merged,\n",
    "    group_cols=agg_cols,\n",
    "    metric_prefixes=metric_cols_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9cf9fd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>llr_unknown_gpt2_count</th>\n",
       "      <th>llr_unknown_qwen_count</th>\n",
       "      <th>llr_unknown_gemma_count</th>\n",
       "      <th>llr_unknown_llama_count</th>\n",
       "      <th>llr_unknown_gpt2_sum</th>\n",
       "      <th>llr_unknown_qwen_sum</th>\n",
       "      <th>llr_unknown_gemma_sum</th>\n",
       "      <th>llr_unknown_llama_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.983477</td>\n",
       "      <td>5.949244</td>\n",
       "      <td>5.791008</td>\n",
       "      <td>40.844842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOOTmag vs Iain99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.875691</td>\n",
       "      <td>9.703337</td>\n",
       "      <td>9.063104</td>\n",
       "      <td>8.835369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21.018562</td>\n",
       "      <td>22.053801</td>\n",
       "      <td>21.359321</td>\n",
       "      <td>17.957647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.453268</td>\n",
       "      <td>7.361303</td>\n",
       "      <td>8.951198</td>\n",
       "      <td>8.193341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HonestopL vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.771749</td>\n",
       "      <td>8.472696</td>\n",
       "      <td>9.871460</td>\n",
       "      <td>5.895896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              problem corpus     known_author  \\\n",
       "0                  HOOTmag vs HOOTmag   Wiki          HOOTmag   \n",
       "1                   HOOTmag vs Iain99   Wiki          HOOTmag   \n",
       "2  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki  Hodja_Nasreddin   \n",
       "3        Hodja_Nasreddin vs HonestopL   Wiki  Hodja_Nasreddin   \n",
       "4                HonestopL vs HOOTmag   Wiki        HonestopL   \n",
       "\n",
       "    unknown_author  target  llr_unknown_gpt2_count  llr_unknown_qwen_count  \\\n",
       "0          HOOTmag    True                       3                       3   \n",
       "1           Iain99   False                       3                       3   \n",
       "2  Hodja_Nasreddin    True                       3                       3   \n",
       "3        HonestopL   False                       3                       3   \n",
       "4          HOOTmag   False                       3                       3   \n",
       "\n",
       "   llr_unknown_gemma_count  llr_unknown_llama_count  llr_unknown_gpt2_sum  \\\n",
       "0                        3                        3              7.983477   \n",
       "1                        3                        3             12.875691   \n",
       "2                        3                        3             21.018562   \n",
       "3                        3                        3              9.453268   \n",
       "4                        3                        3              6.771749   \n",
       "\n",
       "   llr_unknown_qwen_sum  llr_unknown_gemma_sum  llr_unknown_llama_sum  \n",
       "0              5.949244               5.791008              40.844842  \n",
       "1              9.703337               9.063104               8.835369  \n",
       "2             22.053801              21.359321              17.957647  \n",
       "3              7.361303               8.951198               8.193341  \n",
       "4              8.472696               9.871460               5.895896  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7750a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated.to_excel(agg_results_save_loc, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7a949",
   "metadata": {},
   "source": [
    "## Score the non-aggregated dataset\n",
    "\n",
    "Now first we score the non-aggregated dataset, I have an altered version of the performance function which also shows the predictions of whether the result is a TP, TN, FP, or FN result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c346eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_preds_errors_with_summary(\n",
    "    merged_df,\n",
    "    models,\n",
    "    id_cols,\n",
    "    base_metric=\"llr_unknown\",\n",
    "    target_col=\"target\",\n",
    "    keep_cols=(\"corpus\",),\n",
    "    performance_fn=performance,\n",
    "    include_score=True,   # keep the per-model score in detailed output\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    summary_all : pd.DataFrame\n",
    "        Concatenation of raw_summary from each model (with a 'model' column).\n",
    "    detailed_merged : pd.DataFrame\n",
    "        id_cols + (score_col) + y_pred_<model>, error_<model> for each model (outer-merged).\n",
    "    \"\"\"\n",
    "    per_model_detailed = []\n",
    "    per_model_summaries = []\n",
    "\n",
    "    for model in models:\n",
    "        score_col = f\"{base_metric}_{model}\"\n",
    "        df_non_null = merged_df[merged_df[score_col].notna()]\n",
    "        if df_non_null.empty:\n",
    "            continue\n",
    "\n",
    "        raw_summary, raw_detailed = performance_fn(\n",
    "            df_non_null,\n",
    "            additional_metadata={\"model\": model},\n",
    "            keep_cols=list(keep_cols),\n",
    "            score_col=score_col,\n",
    "            target_col=target_col,\n",
    "            return_pred_rows=True,\n",
    "            id_cols=id_cols,\n",
    "        )\n",
    "\n",
    "        # --- collect summary ---\n",
    "        if \"model\" not in raw_summary.columns:\n",
    "            raw_summary = raw_summary.copy()\n",
    "            raw_summary[\"model\"] = model\n",
    "        per_model_summaries.append(raw_summary)\n",
    "\n",
    "        # --- bring the score into raw_detailed (it's not included by performance) ---\n",
    "        if include_score and score_col not in raw_detailed.columns:\n",
    "            score_frame = (\n",
    "                df_non_null[id_cols + [score_col]]\n",
    "                .drop_duplicates(subset=id_cols)  # avoid dup join keys\n",
    "            )\n",
    "            raw_detailed = raw_detailed.merge(score_frame, on=id_cols, how=\"left\")\n",
    "\n",
    "        # --- collect detailed ---\n",
    "        keep = id_cols + [\"y_pred\", \"error\"]\n",
    "        if include_score:\n",
    "            keep = id_cols + [score_col, \"y_pred\", \"error\"]\n",
    "\n",
    "        df_small = raw_detailed[keep].rename(\n",
    "            columns={\n",
    "                \"y_pred\": f\"y_pred_{model}\",\n",
    "                \"error\": f\"error_{model}\",\n",
    "                # score_col already contains the model suffix; keep as-is\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # If duplicates per key can occur, you can dedupe here:\n",
    "        # df_small = df_small.drop_duplicates(subset=id_cols, keep=\"last\")\n",
    "\n",
    "        per_model_detailed.append(df_small)\n",
    "\n",
    "    # Build final summary\n",
    "    summary_all = (\n",
    "        pd.concat(per_model_summaries, ignore_index=True)\n",
    "        if per_model_summaries else pd.DataFrame()\n",
    "    )\n",
    "\n",
    "    # Build final detailed\n",
    "    if per_model_detailed:\n",
    "        detailed_merged = reduce(\n",
    "            lambda left, right: left.merge(right, on=id_cols, how=\"outer\"),\n",
    "            per_model_detailed\n",
    "        )\n",
    "    else:\n",
    "        detailed_merged = pd.DataFrame(columns=id_cols)\n",
    "\n",
    "    return summary_all, detailed_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "85f32041",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    \"index\", \"sample_id\", \"problem\", \"corpus\",\n",
    "    \"known_author\", \"unknown_author\",\n",
    "    \"known_doc_id\", \"unknown_doc_id\",\n",
    "    \"target\",\n",
    "]\n",
    "\n",
    "# Reuse the model dictionary used earlier\n",
    "models = list(model_dfs.keys())\n",
    "\n",
    "raw_summary, raw_detailed = collect_preds_errors_with_summary(\n",
    "    merged_df=merged,\n",
    "    models=models,\n",
    "    id_cols=id_cols,\n",
    "    base_metric=\"llr_unknown\",\n",
    "    target_col=\"target\",\n",
    "    keep_cols=(\"corpus\",),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "3a3a9b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>target</th>\n",
       "      <th>llr_unknown_gpt2</th>\n",
       "      <th>...</th>\n",
       "      <th>error_gpt2</th>\n",
       "      <th>llr_unknown_qwen</th>\n",
       "      <th>y_pred_qwen</th>\n",
       "      <th>error_qwen</th>\n",
       "      <th>llr_unknown_gemma</th>\n",
       "      <th>y_pred_gemma</th>\n",
       "      <th>error_gemma</th>\n",
       "      <th>llr_unknown_llama</th>\n",
       "      <th>y_pred_llama</th>\n",
       "      <th>error_llama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>True</td>\n",
       "      <td>8.983871</td>\n",
       "      <td>...</td>\n",
       "      <td>FN</td>\n",
       "      <td>9.763942</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>8.856316</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>7.786461</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_10</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>True</td>\n",
       "      <td>6.480075</td>\n",
       "      <td>...</td>\n",
       "      <td>FN</td>\n",
       "      <td>6.377775</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>7.284163</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>6.932723</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_11</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>True</td>\n",
       "      <td>5.554616</td>\n",
       "      <td>...</td>\n",
       "      <td>FN</td>\n",
       "      <td>5.912084</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>5.218841</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>3.238463</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>honestopl_text_1</td>\n",
       "      <td>False</td>\n",
       "      <td>5.072673</td>\n",
       "      <td>...</td>\n",
       "      <td>TN</td>\n",
       "      <td>3.635344</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>4.395038</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>4.684318</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>hodja_nasreddin_text_10</td>\n",
       "      <td>honestopl_text_1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.046288</td>\n",
       "      <td>...</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.965029</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>2.188174</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.711093</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  sample_id                             problem corpus  \\\n",
       "0      0          1  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "1      1          2  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "2      2          3  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "3      3          4        Hodja_Nasreddin vs HonestopL   Wiki   \n",
       "4      4          5        Hodja_Nasreddin vs HonestopL   Wiki   \n",
       "\n",
       "      known_author   unknown_author             known_doc_id  \\\n",
       "0  Hodja_Nasreddin  Hodja_Nasreddin   hodja_nasreddin_text_1   \n",
       "1  Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_10   \n",
       "2  Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_11   \n",
       "3  Hodja_Nasreddin        HonestopL   hodja_nasreddin_text_1   \n",
       "4  Hodja_Nasreddin        HonestopL  hodja_nasreddin_text_10   \n",
       "\n",
       "           unknown_doc_id  target  llr_unknown_gpt2  ...  error_gpt2  \\\n",
       "0  hodja_nasreddin_text_3    True          8.983871  ...          FN   \n",
       "1  hodja_nasreddin_text_3    True          6.480075  ...          FN   \n",
       "2  hodja_nasreddin_text_3    True          5.554616  ...          FN   \n",
       "3        honestopl_text_1   False          5.072673  ...          TN   \n",
       "4        honestopl_text_1   False          2.046288  ...          TN   \n",
       "\n",
       "  llr_unknown_qwen  y_pred_qwen  error_qwen llr_unknown_gemma  y_pred_gemma  \\\n",
       "0         9.763942         True          TP          8.856316         False   \n",
       "1         6.377775        False          FN          7.284163         False   \n",
       "2         5.912084        False          FN          5.218841         False   \n",
       "3         3.635344        False          TN          4.395038         False   \n",
       "4         1.965029        False          TN          2.188174         False   \n",
       "\n",
       "   error_gemma llr_unknown_llama  y_pred_llama  error_llama  \n",
       "0           FN          7.786461         False           FN  \n",
       "1           FN          6.932723         False           FN  \n",
       "2           FN          3.238463         False           FN  \n",
       "3           TN          4.684318         False           TN  \n",
       "4           TN          1.711093         False           TN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_detailed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fd73762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.903748</td>\n",
       "      <td>0.903748</td>\n",
       "      <td>0.339339</td>\n",
       "      <td>0.139717</td>\n",
       "      <td>-0.121838</td>\n",
       "      <td>328</td>\n",
       "      <td>333</td>\n",
       "      <td>0.692824</td>\n",
       "      <td>0.656046</td>\n",
       "      <td>0.678445</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.628478</td>\n",
       "      <td>192</td>\n",
       "      <td>91</td>\n",
       "      <td>136</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.916797</td>\n",
       "      <td>0.916797</td>\n",
       "      <td>0.366366</td>\n",
       "      <td>0.120072</td>\n",
       "      <td>-0.105766</td>\n",
       "      <td>328</td>\n",
       "      <td>333</td>\n",
       "      <td>0.680144</td>\n",
       "      <td>0.645513</td>\n",
       "      <td>0.663194</td>\n",
       "      <td>0.582317</td>\n",
       "      <td>0.620130</td>\n",
       "      <td>191</td>\n",
       "      <td>97</td>\n",
       "      <td>137</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.908034</td>\n",
       "      <td>0.908034</td>\n",
       "      <td>0.357357</td>\n",
       "      <td>0.136814</td>\n",
       "      <td>-0.116221</td>\n",
       "      <td>328</td>\n",
       "      <td>333</td>\n",
       "      <td>0.688255</td>\n",
       "      <td>0.647014</td>\n",
       "      <td>0.665505</td>\n",
       "      <td>0.582317</td>\n",
       "      <td>0.621138</td>\n",
       "      <td>191</td>\n",
       "      <td>96</td>\n",
       "      <td>137</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.922444</td>\n",
       "      <td>0.922444</td>\n",
       "      <td>0.360360</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>-0.098572</td>\n",
       "      <td>328</td>\n",
       "      <td>333</td>\n",
       "      <td>0.675456</td>\n",
       "      <td>0.639461</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.576220</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>189</td>\n",
       "      <td>99</td>\n",
       "      <td>139</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model corpus      Cllr  Cllr_min       EER  Mean_TRUE_LLR  Mean_FALSE_LLR  \\\n",
       "0   gpt2   Wiki  0.903748  0.903748  0.339339       0.139717       -0.121838   \n",
       "1   qwen   Wiki  0.916797  0.916797  0.366366       0.120072       -0.105766   \n",
       "2  gemma   Wiki  0.908034  0.908034  0.357357       0.136814       -0.116221   \n",
       "3  llama   Wiki  0.922444  0.922444  0.360360       0.113556       -0.098572   \n",
       "\n",
       "   TRUE_trials  FALSE_trials       AUC  Balanced_Accuracy  Precision  \\\n",
       "0          328           333  0.692824           0.656046   0.678445   \n",
       "1          328           333  0.680144           0.645513   0.663194   \n",
       "2          328           333  0.688255           0.647014   0.665505   \n",
       "3          328           333  0.675456           0.639461   0.656250   \n",
       "\n",
       "     Recall        F1   TP  FP   FN   TN  \n",
       "0  0.585366  0.628478  192  91  136  242  \n",
       "1  0.582317  0.620130  191  97  137  236  \n",
       "2  0.582317  0.621138  191  96  137  237  \n",
       "3  0.576220  0.613636  189  99  139  234  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5e445abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_detailed.to_excel(f\"{base_loc}/raw_results_detailed.xlsx\", index=False)\n",
    "# raw_summary.to_excel(f\"{base_loc}/raw_results_summary.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efc677",
   "metadata": {},
   "source": [
    "## Score the aggregated dataset\n",
    "\n",
    "Next we score the aggregated dataset, we must ensure to only include those problems which have the correct number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "61582ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdag_sum, lambdag_detailed = performance(\n",
    "    lambdag_metrics,\n",
    "    score_col='score',\n",
    "    target_col='target',\n",
    "    return_pred_rows=True,\n",
    "    id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "    additional_metadata={\"model\": \"LambdaG\"}\n",
    ")\n",
    "\n",
    "lambdag_detailed = (\n",
    "    lambdag_detailed\n",
    "      .rename(columns={\"y_pred\": \"y_pred_lambdag\", \"error\": \"error_lambdag\"})\n",
    "      .drop(columns=[\"pred_prob\", \"pred_llr\", 'index'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f6307de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdag_metrics.rename(columns={\"target\": \"y_true\", \"score\": \"llr_lambdaG\"}, inplace=True)\n",
    "\n",
    "lambdag_merged = ( lambdag_detailed\n",
    "    .merge(lambdag_metrics, on=['problem', 'corpus', 'known_author', 'unknown_author', 'y_true'], how='left')\n",
    "    .drop(columns=\"Magnitude\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9c763772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>llr_unknown_gpt2_count</th>\n",
       "      <th>llr_unknown_qwen_count</th>\n",
       "      <th>llr_unknown_gemma_count</th>\n",
       "      <th>llr_unknown_llama_count</th>\n",
       "      <th>llr_unknown_gpt2_sum</th>\n",
       "      <th>llr_unknown_qwen_sum</th>\n",
       "      <th>llr_unknown_gemma_sum</th>\n",
       "      <th>llr_unknown_llama_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.983477</td>\n",
       "      <td>5.949244</td>\n",
       "      <td>5.791008</td>\n",
       "      <td>40.844842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOOTmag vs Iain99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.875691</td>\n",
       "      <td>9.703337</td>\n",
       "      <td>9.063104</td>\n",
       "      <td>8.835369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21.018562</td>\n",
       "      <td>22.053801</td>\n",
       "      <td>21.359321</td>\n",
       "      <td>17.957647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.453268</td>\n",
       "      <td>7.361303</td>\n",
       "      <td>8.951198</td>\n",
       "      <td>8.193341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HonestopL vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.771749</td>\n",
       "      <td>8.472696</td>\n",
       "      <td>9.871460</td>\n",
       "      <td>5.895896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Xtv vs Yoenit</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Xtv</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30.242804</td>\n",
       "      <td>28.710436</td>\n",
       "      <td>26.981082</td>\n",
       "      <td>24.958740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Yoenit vs Yoenit</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30.917279</td>\n",
       "      <td>23.723406</td>\n",
       "      <td>22.681577</td>\n",
       "      <td>22.114786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Yoenit vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22.737351</td>\n",
       "      <td>19.217741</td>\n",
       "      <td>20.592835</td>\n",
       "      <td>16.853033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ZjarriRrethues vs 142.196.88.228</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13.619872</td>\n",
       "      <td>11.119647</td>\n",
       "      <td>13.298563</td>\n",
       "      <td>9.891038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16.421702</td>\n",
       "      <td>16.045661</td>\n",
       "      <td>14.181579</td>\n",
       "      <td>10.935706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                problem corpus     known_author  \\\n",
       "0                    HOOTmag vs HOOTmag   Wiki          HOOTmag   \n",
       "1                     HOOTmag vs Iain99   Wiki          HOOTmag   \n",
       "2    Hodja_Nasreddin vs Hodja_Nasreddin   Wiki  Hodja_Nasreddin   \n",
       "3          Hodja_Nasreddin vs HonestopL   Wiki  Hodja_Nasreddin   \n",
       "4                  HonestopL vs HOOTmag   Wiki        HonestopL   \n",
       "..                                  ...    ...              ...   \n",
       "219                       Xtv vs Yoenit   Wiki              Xtv   \n",
       "220                    Yoenit vs Yoenit   Wiki           Yoenit   \n",
       "221            Yoenit vs ZjarriRrethues   Wiki           Yoenit   \n",
       "222    ZjarriRrethues vs 142.196.88.228   Wiki   ZjarriRrethues   \n",
       "223    ZjarriRrethues vs ZjarriRrethues   Wiki   ZjarriRrethues   \n",
       "\n",
       "      unknown_author  target  llr_unknown_gpt2_count  llr_unknown_qwen_count  \\\n",
       "0            HOOTmag    True                       3                       3   \n",
       "1             Iain99   False                       3                       3   \n",
       "2    Hodja_Nasreddin    True                       3                       3   \n",
       "3          HonestopL   False                       3                       3   \n",
       "4            HOOTmag   False                       3                       3   \n",
       "..               ...     ...                     ...                     ...   \n",
       "219           Yoenit   False                       3                       3   \n",
       "220           Yoenit    True                       2                       2   \n",
       "221   ZjarriRrethues   False                       3                       3   \n",
       "222   142.196.88.228   False                       3                       3   \n",
       "223   ZjarriRrethues    True                       3                       3   \n",
       "\n",
       "     llr_unknown_gemma_count  llr_unknown_llama_count  llr_unknown_gpt2_sum  \\\n",
       "0                          3                        3              7.983477   \n",
       "1                          3                        3             12.875691   \n",
       "2                          3                        3             21.018562   \n",
       "3                          3                        3              9.453268   \n",
       "4                          3                        3              6.771749   \n",
       "..                       ...                      ...                   ...   \n",
       "219                        3                        3             30.242804   \n",
       "220                        2                        2             30.917279   \n",
       "221                        3                        3             22.737351   \n",
       "222                        3                        3             13.619872   \n",
       "223                        3                        3             16.421702   \n",
       "\n",
       "     llr_unknown_qwen_sum  llr_unknown_gemma_sum  llr_unknown_llama_sum  \n",
       "0                5.949244               5.791008              40.844842  \n",
       "1                9.703337               9.063104               8.835369  \n",
       "2               22.053801              21.359321              17.957647  \n",
       "3                7.361303               8.951198               8.193341  \n",
       "4                8.472696               9.871460               5.895896  \n",
       "..                    ...                    ...                    ...  \n",
       "219             28.710436              26.981082              24.958740  \n",
       "220             23.723406              22.681577              22.114786  \n",
       "221             19.217741              20.592835              16.853033  \n",
       "222             11.119647              13.298563               9.891038  \n",
       "223             16.045661              14.181579              10.935706  \n",
       "\n",
       "[224 rows x 13 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3750b033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred_lambdag</th>\n",
       "      <th>error_lambdag</th>\n",
       "      <th>llr_lambdaG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>161.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>153.800067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rjecina vs Rjecina</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Rjecina</td>\n",
       "      <td>Rjecina</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>118.796333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lear_21 vs Lear_21</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Lear_21</td>\n",
       "      <td>Lear_21</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>101.188267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard_Daft vs Richard_Daft</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Richard_Daft</td>\n",
       "      <td>Richard_Daft</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>97.970333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>N419BH vs Nableezy</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>N419BH</td>\n",
       "      <td>Nableezy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.753467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>O_Fenian vs Paul_Siebert</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>O_Fenian</td>\n",
       "      <td>Paul_Siebert</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>-0.663733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Nigel_Ish vs Nigel_Ish</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Nigel_Ish</td>\n",
       "      <td>Nigel_Ish</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.502133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Kashmiri vs KBlott</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Kashmiri</td>\n",
       "      <td>KBlott</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.376267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>L.tak vs L.tak</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>L.tak</td>\n",
       "      <td>L.tak</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>-0.334333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          problem corpus  known_author unknown_author  y_true  \\\n",
       "0              HOOTmag vs HOOTmag   Wiki       HOOTmag        HOOTmag    True   \n",
       "1              Icarus3 vs Icarus3   Wiki       Icarus3        Icarus3    True   \n",
       "2              Rjecina vs Rjecina   Wiki       Rjecina        Rjecina    True   \n",
       "3              Lear_21 vs Lear_21   Wiki       Lear_21        Lear_21    True   \n",
       "4    Richard_Daft vs Richard_Daft   Wiki  Richard_Daft   Richard_Daft    True   \n",
       "..                            ...    ...           ...            ...     ...   \n",
       "219            N419BH vs Nableezy   Wiki        N419BH       Nableezy   False   \n",
       "220      O_Fenian vs Paul_Siebert   Wiki      O_Fenian   Paul_Siebert   False   \n",
       "221        Nigel_Ish vs Nigel_Ish   Wiki     Nigel_Ish      Nigel_Ish    True   \n",
       "222            Kashmiri vs KBlott   Wiki      Kashmiri         KBlott   False   \n",
       "223                L.tak vs L.tak   Wiki         L.tak          L.tak    True   \n",
       "\n",
       "     y_pred_lambdag error_lambdag  llr_lambdaG  \n",
       "0              True            TP   161.614000  \n",
       "1              True            TP   153.800067  \n",
       "2              True            TP   118.796333  \n",
       "3              True            TP   101.188267  \n",
       "4              True            TP    97.970333  \n",
       "..              ...           ...          ...  \n",
       "219           False            TN     0.753467  \n",
       "220           False            TN    -0.663733  \n",
       "221           False            FN     0.502133  \n",
       "222           False            TN     0.376267  \n",
       "223           False            FN    -0.334333  \n",
       "\n",
       "[224 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdag_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c5dfd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_agg = aggregated[aggregated['llr_unknown_gpt2_count'] == 3].copy()\n",
    "\n",
    "gpt2_agg_sum, gpt2_agg_detailed = performance(\n",
    "    gpt2_agg,\n",
    "    score_col='llr_unknown_gpt2_sum',\n",
    "    target_col='target',\n",
    "    return_pred_rows=True,\n",
    "    id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "    additional_metadata={\"model\": \"gpt2\"}\n",
    ")\n",
    "\n",
    "gpt2_agg_detailed = (\n",
    "    gpt2_agg_detailed\n",
    "      .rename(columns={\"y_pred\": \"y_pred_gpt2\", \"error\": \"error_gpt2\"})\n",
    "      .drop(columns=[\"pred_prob\", \"pred_llr\", \"index\"])\n",
    ")\n",
    "\n",
    "gemma_agg = aggregated[aggregated['llr_unknown_gemma_count'] == 3].copy()\n",
    "\n",
    "gemma_agg_sum, gemma_agg_detailed = performance(\n",
    "    gemma_agg,\n",
    "    score_col='llr_unknown_gemma_sum',\n",
    "    target_col='target',\n",
    "    return_pred_rows=True,\n",
    "    id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "    additional_metadata={\"model\": \"gemma\"}\n",
    ")\n",
    "\n",
    "gemma_agg_detailed = (\n",
    "    gemma_agg_detailed\n",
    "      .rename(columns={\"y_pred\": \"y_pred_gemma\", \"error\": \"error_gemma\"})\n",
    "      .drop(columns=[\"pred_prob\", \"pred_llr\", \"index\"])\n",
    ")\n",
    "\n",
    "qwen_agg = aggregated[aggregated['llr_unknown_qwen_count'] == 3].copy()\n",
    "\n",
    "qwen_agg_sum, qwen_agg_detailed = performance(\n",
    "    qwen_agg,\n",
    "    score_col='llr_unknown_qwen_sum',\n",
    "    target_col='target',\n",
    "    return_pred_rows=True,\n",
    "    id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "    additional_metadata={\"model\": \"qwen\"}\n",
    ")\n",
    "\n",
    "qwen_agg_detailed = (\n",
    "    qwen_agg_detailed\n",
    "      .rename(columns={\"y_pred\": \"y_pred_qwen\", \"error\": \"error_qwen\"})\n",
    "      .drop(columns=[\"pred_prob\", \"pred_llr\", \"index\"])\n",
    ")\n",
    "\n",
    "llama_agg = aggregated[aggregated['llr_unknown_llama_count'] == 3].copy()\n",
    "\n",
    "llama_agg_sum, llama_agg_detailed = performance(\n",
    "    llama_agg,\n",
    "    score_col='llr_unknown_llama_sum',\n",
    "    target_col='target',\n",
    "    return_pred_rows=True,\n",
    "    id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "    additional_metadata={\"model\": \"llama\"}\n",
    ")\n",
    "\n",
    "llama_agg_detailed = (\n",
    "    llama_agg_detailed\n",
    "      .rename(columns={\"y_pred\": \"y_pred_llama\", \"error\": \"error_llama\"})\n",
    "      .drop(columns=[\"pred_prob\", \"pred_llr\", \"index\"])\n",
    ")\n",
    "\n",
    "combined_df = pd.concat([lambdag_sum, gpt2_agg_sum, qwen_agg_sum, gemma_agg_sum, llama_agg_sum], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4af53cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>0.573212</td>\n",
       "      <td>0.573212</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>1.088023</td>\n",
       "      <td>-0.754360</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.900351</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.857070</td>\n",
       "      <td>0.856730</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.204198</td>\n",
       "      <td>-0.207509</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>0.735974</td>\n",
       "      <td>0.669857</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen</td>\n",
       "      <td>0.873891</td>\n",
       "      <td>0.873545</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.180513</td>\n",
       "      <td>-0.184612</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>0.720625</td>\n",
       "      <td>0.646701</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.623116</td>\n",
       "      <td>62</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.858543</td>\n",
       "      <td>0.858205</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.205317</td>\n",
       "      <td>-0.205123</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>0.735709</td>\n",
       "      <td>0.670078</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama</td>\n",
       "      <td>0.873800</td>\n",
       "      <td>0.873459</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.178813</td>\n",
       "      <td>-0.183374</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>0.720625</td>\n",
       "      <td>0.656096</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model      Cllr  Cllr_min       EER  Mean_TRUE_LLR  Mean_FALSE_LLR  \\\n",
       "0  LambdaG  0.573212  0.573212  0.169643       1.088023       -0.754360   \n",
       "1     gpt2  0.857070  0.856730  0.357798       0.204198       -0.207509   \n",
       "2     qwen  0.873891  0.873545  0.366972       0.180513       -0.184612   \n",
       "3    gemma  0.858543  0.858205  0.348624       0.205317       -0.205123   \n",
       "4    llama  0.873800  0.873459  0.357798       0.178813       -0.183374   \n",
       "\n",
       "   TRUE_trials  FALSE_trials       AUC  Balanced_Accuracy  Precision  \\\n",
       "0          112           112  0.900351           0.825893   0.828829   \n",
       "1          104           109  0.735974           0.669857   0.684783   \n",
       "2          104           109  0.720625           0.646701   0.652632   \n",
       "3          104           109  0.735709           0.670078   0.680851   \n",
       "4          104           109  0.720625           0.656096   0.663158   \n",
       "\n",
       "     Recall        F1  TP  FP  FN  TN  \n",
       "0  0.821429  0.825112  92  19  20  93  \n",
       "1  0.605769  0.642857  63  29  41  80  \n",
       "2  0.596154  0.623116  62  33  42  76  \n",
       "3  0.615385  0.646465  64  30  40  79  \n",
       "4  0.605769  0.633166  63  32  41  77  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "cbd185d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_excel(f\"{base_loc}/agg_results_summary.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a68645b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_detailed_results = (\n",
    "    qwen_agg_detailed\n",
    "    .merge(gemma_agg_detailed, on=['problem', 'corpus', 'known_author', 'unknown_author', 'y_true'], how='outer')\n",
    "    .merge(llama_agg_detailed, on=['problem', 'corpus', 'known_author', 'unknown_author', 'y_true'], how='outer')\n",
    "    .merge(gpt2_agg_detailed, on=['problem', 'corpus', 'known_author', 'unknown_author', 'y_true'], how='outer')\n",
    "    .merge(aggregated, on=['problem', 'corpus', 'known_author', 'unknown_author'], how='left')\n",
    "    .drop(columns=[\"target\", \"llr_unknown_qwen_count\", \"llr_unknown_gemma_count\", \"llr_unknown_llama_count\", \"llr_unknown_gpt2_count\"])\n",
    "    .rename(columns={\"llr_unknown_qwen_sum\": \"llr_unknown_qwen\", \"llr_unknown_gemma_sum\": \"llr_unknown_gemma\",\n",
    "                     \"llr_unknown_llama_sum\": \"llr_unknown_llama\", \"llr_unknown_gpt2_sum\": \"llr_unknown_gpt2\"})\n",
    "    .merge(lambdag_merged, on=['problem', 'corpus', 'known_author', 'unknown_author', 'y_true'], how='outer')\n",
    "    .loc[:, [\n",
    "        'problem', 'corpus', 'known_author', 'unknown_author', 'y_true',\n",
    "        'llr_lambdaG', 'y_pred_lambdag', 'error_lambdag',\n",
    "        'llr_unknown_gpt2', 'y_pred_gpt2', 'error_gpt2',\n",
    "        'llr_unknown_qwen', 'y_pred_qwen', 'error_qwen',\n",
    "        'llr_unknown_gemma', 'y_pred_gemma', 'error_gemma',\n",
    "        'llr_unknown_llama', 'y_pred_llama', 'error_llama'\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "97e67480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>y_true</th>\n",
       "      <th>llr_lambdaG</th>\n",
       "      <th>y_pred_lambdag</th>\n",
       "      <th>error_lambdag</th>\n",
       "      <th>llr_unknown_gpt2</th>\n",
       "      <th>y_pred_gpt2</th>\n",
       "      <th>error_gpt2</th>\n",
       "      <th>llr_unknown_qwen</th>\n",
       "      <th>y_pred_qwen</th>\n",
       "      <th>error_qwen</th>\n",
       "      <th>llr_unknown_gemma</th>\n",
       "      <th>y_pred_gemma</th>\n",
       "      <th>error_gemma</th>\n",
       "      <th>llr_unknown_llama</th>\n",
       "      <th>y_pred_llama</th>\n",
       "      <th>error_llama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>161.614000</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>7.983477</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>5.949244</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>5.791008</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>40.844842</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOOTmag vs Iain99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>False</td>\n",
       "      <td>-42.095733</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>12.875691</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>9.703337</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>9.063104</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>8.835369</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>True</td>\n",
       "      <td>21.316867</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>21.018562</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>22.053801</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>21.359321</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>17.957647</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>False</td>\n",
       "      <td>9.259067</td>\n",
       "      <td>True</td>\n",
       "      <td>FP</td>\n",
       "      <td>9.453268</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>7.361303</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>8.951198</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>8.193341</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HonestopL vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>False</td>\n",
       "      <td>-13.158267</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>6.771749</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>8.472696</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>9.871460</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>5.895896</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Xtv vs Yoenit</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Xtv</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>False</td>\n",
       "      <td>5.556133</td>\n",
       "      <td>True</td>\n",
       "      <td>FP</td>\n",
       "      <td>30.242804</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>28.710436</td>\n",
       "      <td>True</td>\n",
       "      <td>FP</td>\n",
       "      <td>26.981082</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>24.958740</td>\n",
       "      <td>True</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Yoenit vs Yoenit</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>True</td>\n",
       "      <td>60.363067</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Yoenit vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Yoenit</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>False</td>\n",
       "      <td>-22.850667</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>22.737351</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>19.217741</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>20.592835</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>16.853033</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ZjarriRrethues vs 142.196.88.228</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>False</td>\n",
       "      <td>-33.414400</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>13.619872</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>11.119647</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>13.298563</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>9.891038</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>True</td>\n",
       "      <td>8.893733</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>16.421702</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>16.045661</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>14.181579</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>10.935706</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                problem corpus     known_author  \\\n",
       "0                    HOOTmag vs HOOTmag   Wiki          HOOTmag   \n",
       "1                     HOOTmag vs Iain99   Wiki          HOOTmag   \n",
       "2    Hodja_Nasreddin vs Hodja_Nasreddin   Wiki  Hodja_Nasreddin   \n",
       "3          Hodja_Nasreddin vs HonestopL   Wiki  Hodja_Nasreddin   \n",
       "4                  HonestopL vs HOOTmag   Wiki        HonestopL   \n",
       "..                                  ...    ...              ...   \n",
       "219                       Xtv vs Yoenit   Wiki              Xtv   \n",
       "220                    Yoenit vs Yoenit   Wiki           Yoenit   \n",
       "221            Yoenit vs ZjarriRrethues   Wiki           Yoenit   \n",
       "222    ZjarriRrethues vs 142.196.88.228   Wiki   ZjarriRrethues   \n",
       "223    ZjarriRrethues vs ZjarriRrethues   Wiki   ZjarriRrethues   \n",
       "\n",
       "      unknown_author  y_true  llr_lambdaG  y_pred_lambdag error_lambdag  \\\n",
       "0            HOOTmag    True   161.614000            True            TP   \n",
       "1             Iain99   False   -42.095733           False            TN   \n",
       "2    Hodja_Nasreddin    True    21.316867            True            TP   \n",
       "3          HonestopL   False     9.259067            True            FP   \n",
       "4            HOOTmag   False   -13.158267           False            TN   \n",
       "..               ...     ...          ...             ...           ...   \n",
       "219           Yoenit   False     5.556133            True            FP   \n",
       "220           Yoenit    True    60.363067            True            TP   \n",
       "221   ZjarriRrethues   False   -22.850667           False            TN   \n",
       "222   142.196.88.228   False   -33.414400           False            TN   \n",
       "223   ZjarriRrethues    True     8.893733            True            TP   \n",
       "\n",
       "     llr_unknown_gpt2 y_pred_gpt2 error_gpt2  llr_unknown_qwen y_pred_qwen  \\\n",
       "0            7.983477       False         FN          5.949244       False   \n",
       "1           12.875691       False         TN          9.703337       False   \n",
       "2           21.018562       False         FN         22.053801       False   \n",
       "3            9.453268       False         TN          7.361303       False   \n",
       "4            6.771749       False         TN          8.472696       False   \n",
       "..                ...         ...        ...               ...         ...   \n",
       "219         30.242804       False         TN         28.710436        True   \n",
       "220               NaN         NaN        NaN               NaN         NaN   \n",
       "221         22.737351       False         TN         19.217741       False   \n",
       "222         13.619872       False         TN         11.119647       False   \n",
       "223         16.421702       False         FN         16.045661       False   \n",
       "\n",
       "    error_qwen  llr_unknown_gemma y_pred_gemma error_gemma  llr_unknown_llama  \\\n",
       "0           FN           5.791008        False          FN          40.844842   \n",
       "1           TN           9.063104        False          TN           8.835369   \n",
       "2           FN          21.359321        False          FN          17.957647   \n",
       "3           TN           8.951198        False          TN           8.193341   \n",
       "4           TN           9.871460        False          TN           5.895896   \n",
       "..         ...                ...          ...         ...                ...   \n",
       "219         FP          26.981082        False          TN          24.958740   \n",
       "220        NaN                NaN          NaN         NaN                NaN   \n",
       "221         TN          20.592835        False          TN          16.853033   \n",
       "222         TN          13.298563        False          TN           9.891038   \n",
       "223         FN          14.181579        False          FN          10.935706   \n",
       "\n",
       "    y_pred_llama error_llama  \n",
       "0           True          TP  \n",
       "1          False          TN  \n",
       "2          False          FN  \n",
       "3          False          TN  \n",
       "4          False          TN  \n",
       "..           ...         ...  \n",
       "219         True          FP  \n",
       "220          NaN         NaN  \n",
       "221        False          TN  \n",
       "222        False          TN  \n",
       "223        False          FN  \n",
       "\n",
       "[224 rows x 20 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "cdf39fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_detailed_results.to_excel(f\"{base_loc}/agg_results_detailed.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc074f2d",
   "metadata": {},
   "source": [
    "## View by Token Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "306591c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_token_level_results = pd.read_excel(f'{base_loc}/gpt2 results/token_level_results.xlsx')\n",
    "gpt2_token_level_results['model'] = \"GPT2\"\n",
    "\n",
    "llama_token_level_results = pd.read_excel(f'{base_loc}/llama results/token_level_results.xlsx')\n",
    "llama_token_level_results['model'] = \"Llama\"\n",
    "\n",
    "gemma_token_level_results = pd.read_excel(f'{base_loc}/gemma results/token_level_results.xlsx')\n",
    "gemma_token_level_results['model'] = \"Gemma\"\n",
    "\n",
    "qwen_token_level_results = pd.read_excel(f'{base_loc}/qwen results/token_level_results.xlsx')\n",
    "qwen_token_level_results['model'] = \"Qwen\"\n",
    "\n",
    "token_level_results = pd.concat([gpt2_token_level_results, llama_token_level_results, gemma_token_level_results, qwen_token_level_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9c0ef",
   "metadata": {},
   "source": [
    "### Find Valid Token Ranges\n",
    "\n",
    "To get a result using **performance** we need to ensure that there is a True and False example for at least a single case for each token size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "01cb5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest token range we can test on is 5\n"
     ]
    }
   ],
   "source": [
    "token_level_results_info = (\n",
    "    token_level_results\n",
    "    .groupby(['model', 'min_token_size', 'target'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# keep only rows where both True and False counts are >= 1\n",
    "valid_rows = token_level_results_info[\n",
    "    (token_level_results_info[True]  > 1) &\n",
    "    (token_level_results_info[False] > 1)\n",
    "]\n",
    "\n",
    "# Get the level values for min_token_size from the multi-index\n",
    "min_token_sizes = valid_rows.index.get_level_values('min_token_size')\n",
    "\n",
    "# Find the highest min_token_size\n",
    "highest_min_token_size = int(min_token_sizes.max()) if not valid_rows.empty else None\n",
    "\n",
    "print(f\"The highest token range we can test on is {highest_min_token_size}\")\n",
    "\n",
    "filtered_token_level_results = (\n",
    "    token_level_results\n",
    "    .query(f\"min_token_size <= {highest_min_token_size}\")\n",
    ")\n",
    "\n",
    "agg_token_problems_to_keep = (\n",
    "    filtered_token_level_results\n",
    "    [['problem', 'corpus', 'min_token_size']]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "agg_token_dataset = (\n",
    "    token_level_results\n",
    "    .merge(agg_token_problems_to_keep, on = ['problem', 'corpus', 'min_token_size'], how='inner')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9197b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    \"model\", \"index\", \"sample_id\", \"problem\", \"corpus\",\n",
    "    \"known_author\", \"unknown_author\",\n",
    "    \"known_doc_id\", \"unknown_doc_id\",\n",
    "    \"target\", \"min_token_size\"\n",
    "]\n",
    "\n",
    "token_summary, token_detailed = performance(\n",
    "    filtered_token_level_results,\n",
    "    # additional_metadata={\"model\": \"gpt2\"},\n",
    "    keep_cols=[\"corpus\"],\n",
    "    score_col=\"llr_unknown\",\n",
    "    target_col=\"target\",\n",
    "    return_pred_rows=True,\n",
    "    id_cols=id_cols,\n",
    "    group_cols=[\"model\", \"min_token_size\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "3b87f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum by token size\n",
    "aggregated_filtered_token_level_results = (\n",
    "    agg_token_dataset\n",
    "    .groupby(\n",
    "        [\"model\", \"problem\", \"corpus\", \"known_author\", \"unknown_author\", \"target\", \"min_token_size\"],\n",
    "        as_index=False\n",
    "    )[\"llr_unknown\"]\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "21b75e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grouped scores\n",
    "id_cols = [\n",
    "    \"problem\", \"corpus\",\n",
    "    \"known_author\", \"unknown_author\",\n",
    "    \"target\", \"min_token_size\"\n",
    "]\n",
    "\n",
    "token_summary, token_detailed = performance(\n",
    "    aggregated_filtered_token_level_results,\n",
    "    keep_cols=[\"corpus\"],\n",
    "    score_col=\"llr_unknown\",\n",
    "    target_col=\"target\",\n",
    "    return_pred_rows=True,\n",
    "    id_cols=id_cols,\n",
    "    group_cols=[\"model\", \"min_token_size\"]\n",
    ")\n",
    "token_summary = token_summary.sort_values(by=['min_token_size', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "b2cfc561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>min_token_size</th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.865559</td>\n",
       "      <td>0.865559</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.208998</td>\n",
       "      <td>-0.173308</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.728715</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0.654378</td>\n",
       "      <td>71</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.211959</td>\n",
       "      <td>-0.172018</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.728476</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.881299</td>\n",
       "      <td>0.881299</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.186027</td>\n",
       "      <td>-0.151607</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.638393</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>69</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.880486</td>\n",
       "      <td>0.880486</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.188741</td>\n",
       "      <td>-0.153150</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.713170</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.617512</td>\n",
       "      <td>67</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.757940</td>\n",
       "      <td>0.757940</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.644993</td>\n",
       "      <td>-0.283621</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.719902</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>69</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.748783</td>\n",
       "      <td>0.748783</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.755199</td>\n",
       "      <td>-0.297221</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.807862</td>\n",
       "      <td>0.747011</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.765751</td>\n",
       "      <td>0.765751</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.598792</td>\n",
       "      <td>-0.274310</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.796888</td>\n",
       "      <td>0.706183</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.639640</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.784350</td>\n",
       "      <td>0.784350</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.585540</td>\n",
       "      <td>-0.247986</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.782965</td>\n",
       "      <td>0.710770</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.922905</td>\n",
       "      <td>0.901566</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.474158</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.910830</td>\n",
       "      <td>0.889861</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.589082</td>\n",
       "      <td>0.039772</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.635833</td>\n",
       "      <td>0.559444</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.941129</td>\n",
       "      <td>0.919387</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.423787</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.609444</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.942433</td>\n",
       "      <td>0.920607</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.438487</td>\n",
       "      <td>0.071780</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.526389</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.077874</td>\n",
       "      <td>0.912090</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.946139</td>\n",
       "      <td>0.329320</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.204581</td>\n",
       "      <td>1.029580</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.938732</td>\n",
       "      <td>0.426749</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Llama</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.199987</td>\n",
       "      <td>1.025905</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.780013</td>\n",
       "      <td>0.429498</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.138986</td>\n",
       "      <td>0.963623</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.005130</td>\n",
       "      <td>0.382986</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  min_token_size corpus      Cllr  Cllr_min       EER  Mean_TRUE_LLR  \\\n",
       "0    GPT2               2   Wiki  0.865559  0.865559  0.348214       0.208998   \n",
       "4   Gemma               2   Wiki  0.865899  0.865899  0.339286       0.211959   \n",
       "8   Llama               2   Wiki  0.881299  0.881299  0.357143       0.186027   \n",
       "12   Qwen               2   Wiki  0.880486  0.880486  0.357143       0.188741   \n",
       "1    GPT2               3   Wiki  0.757940  0.757940  0.309091       0.644993   \n",
       "5   Gemma               3   Wiki  0.748783  0.748783  0.254545       0.755199   \n",
       "9   Llama               3   Wiki  0.765751  0.765751  0.272727       0.598792   \n",
       "13   Qwen               3   Wiki  0.784350  0.784350  0.263636       0.585540   \n",
       "2    GPT2               4   Wiki  0.922905  0.901566  0.300000       0.474158   \n",
       "6   Gemma               4   Wiki  0.910830  0.889861  0.440000       0.589082   \n",
       "10  Llama               4   Wiki  0.941129  0.919387  0.380000       0.423787   \n",
       "14   Qwen               4   Wiki  0.942433  0.920607  0.460000       0.438487   \n",
       "3    GPT2               5   Wiki  1.077874  0.912090  0.333333       0.946139   \n",
       "7   Gemma               5   Wiki  1.204581  1.029580  0.333333       0.938732   \n",
       "11  Llama               5   Wiki  1.199987  1.025905  0.222222       0.780013   \n",
       "15   Qwen               5   Wiki  1.138986  0.963623  0.222222       1.005130   \n",
       "\n",
       "    Mean_FALSE_LLR  TRUE_trials  FALSE_trials       AUC  Balanced_Accuracy  \\\n",
       "0        -0.173308          112           112  0.728715           0.665179   \n",
       "4        -0.172018          112           112  0.728476           0.665179   \n",
       "8        -0.151607          112           112  0.713967           0.638393   \n",
       "12       -0.153150          112           112  0.713170           0.629464   \n",
       "1        -0.283621          111           110  0.803358           0.719902   \n",
       "5        -0.297221          111           110  0.807862           0.747011   \n",
       "9        -0.274310          111           110  0.796888           0.706183   \n",
       "13       -0.247986          111           110  0.782965           0.710770   \n",
       "2         0.050562           72            50  0.630000           0.572500   \n",
       "6         0.039772           72            50  0.635833           0.559444   \n",
       "10        0.070483           72            50  0.609444           0.553333   \n",
       "14        0.071780           72            50  0.608333           0.526389   \n",
       "3         0.329320           25             9  0.697778           0.460000   \n",
       "7         0.426749           25             9  0.684444           0.500000   \n",
       "11        0.429498           25             9  0.644444           0.500000   \n",
       "15        0.382986           25             9  0.671111           0.500000   \n",
       "\n",
       "    Precision    Recall        F1  TP  FP  FN  TN  \n",
       "0    0.676190  0.633929  0.654378  71  34  41  78  \n",
       "4    0.679612  0.625000  0.651163  70  33  42  79  \n",
       "8    0.644860  0.616071  0.630137  69  38  43  74  \n",
       "12   0.638095  0.598214  0.617512  67  38  45  74  \n",
       "1    0.775281  0.621622  0.690000  69  20  42  90  \n",
       "5    0.802198  0.657658  0.722772  73  18  38  92  \n",
       "9    0.739583  0.639640  0.685990  71  25  40  85  \n",
       "13   0.752688  0.630631  0.686275  70  23  41  87  \n",
       "2    0.652174  0.625000  0.638298  45  24  27  26  \n",
       "6    0.638889  0.638889  0.638889  46  26  26  24  \n",
       "10   0.631579  0.666667  0.648649  48  28  24  22  \n",
       "14   0.610390  0.652778  0.630872  47  30  25  20  \n",
       "3    0.718750  0.920000  0.807018  23   9   2   0  \n",
       "7    0.735294  1.000000  0.847458  25   9   0   0  \n",
       "11   0.735294  1.000000  0.847458  25   9   0   0  \n",
       "15   0.735294  1.000000  0.847458  25   9   0   0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "be6d19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_lambdag_sum = pd.DataFrame()\n",
    "\n",
    "token_ranges = agg_token_problems_to_keep['min_token_size'].drop_duplicates().tolist()\n",
    "\n",
    "for token in token_ranges:\n",
    "    problems = (\n",
    "        agg_token_problems_to_keep\n",
    "        .query(f'min_token_size == {token}')\n",
    "        [['problem']]\n",
    "    )\n",
    "    \n",
    "    filtered_lambda_g = (\n",
    "        lambdag_metrics\n",
    "        .merge(problems, on=['problem'], how='inner')\n",
    "    )\n",
    "    \n",
    "    filtered_lambdag_sum, filtered_lambdag_detailed = performance(\n",
    "        filtered_lambda_g,\n",
    "        score_col='llr_lambdaG',\n",
    "        target_col='y_true',\n",
    "        return_pred_rows=True,\n",
    "        id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "        additional_metadata={\"model\": \"LambdaG\", \"min_token_size\": token, \"corpus\": \"Wiki\"}\n",
    "    )\n",
    "    \n",
    "    all_filtered_lambdag_sum = pd.concat([all_filtered_lambdag_sum, filtered_lambdag_sum], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "12f9a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_range_summary = (\n",
    "    pd.concat([token_summary, all_filtered_lambdag_sum], ignore_index=True)\n",
    "    .sort_values(by=['min_token_size', 'model'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "a93f36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_range_summary.to_excel(f'{base_loc}/token_results_summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "16a5767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>min_token_size</th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.865559</td>\n",
       "      <td>0.865559</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.208998</td>\n",
       "      <td>-0.173308</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.728715</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0.654378</td>\n",
       "      <td>71</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.211959</td>\n",
       "      <td>-0.172018</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.728476</td>\n",
       "      <td>0.665179</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.573212</td>\n",
       "      <td>0.573212</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>1.088023</td>\n",
       "      <td>-0.754360</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.900351</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.881299</td>\n",
       "      <td>0.881299</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.186027</td>\n",
       "      <td>-0.151607</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.638393</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>69</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.880486</td>\n",
       "      <td>0.880486</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.188741</td>\n",
       "      <td>-0.153150</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.713170</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.617512</td>\n",
       "      <td>67</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.757940</td>\n",
       "      <td>0.757940</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.644993</td>\n",
       "      <td>-0.283621</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.719902</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>69</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.748783</td>\n",
       "      <td>0.748783</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.755199</td>\n",
       "      <td>-0.297221</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.807862</td>\n",
       "      <td>0.747011</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.562312</td>\n",
       "      <td>0.562312</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>1.139454</td>\n",
       "      <td>-0.780592</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>0.828051</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.765751</td>\n",
       "      <td>0.765751</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.598792</td>\n",
       "      <td>-0.274310</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.796888</td>\n",
       "      <td>0.706183</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.639640</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.784350</td>\n",
       "      <td>0.784350</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.585540</td>\n",
       "      <td>-0.247986</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.782965</td>\n",
       "      <td>0.710770</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.922905</td>\n",
       "      <td>0.901566</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.474158</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.910830</td>\n",
       "      <td>0.889861</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.589082</td>\n",
       "      <td>0.039772</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.635833</td>\n",
       "      <td>0.559444</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.599499</td>\n",
       "      <td>0.587093</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.237530</td>\n",
       "      <td>-0.537456</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.896389</td>\n",
       "      <td>0.811389</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.941129</td>\n",
       "      <td>0.919387</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.423787</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.609444</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.942433</td>\n",
       "      <td>0.920607</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.438487</td>\n",
       "      <td>0.071780</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.526389</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GPT2</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.077874</td>\n",
       "      <td>0.912090</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.946139</td>\n",
       "      <td>0.329320</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gemma</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.204581</td>\n",
       "      <td>1.029580</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.938732</td>\n",
       "      <td>0.426749</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.749561</td>\n",
       "      <td>-0.108504</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.868889</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.199987</td>\n",
       "      <td>1.025905</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.780013</td>\n",
       "      <td>0.429498</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.138986</td>\n",
       "      <td>0.963623</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.005130</td>\n",
       "      <td>0.382986</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  min_token_size corpus      Cllr  Cllr_min       EER  \\\n",
       "0      GPT2               2   Wiki  0.865559  0.865559  0.348214   \n",
       "1     Gemma               2   Wiki  0.865899  0.865899  0.339286   \n",
       "18  LambdaG               2   Wiki  0.573212  0.573212  0.169643   \n",
       "2     Llama               2   Wiki  0.881299  0.881299  0.357143   \n",
       "3      Qwen               2   Wiki  0.880486  0.880486  0.357143   \n",
       "4      GPT2               3   Wiki  0.757940  0.757940  0.309091   \n",
       "5     Gemma               3   Wiki  0.748783  0.748783  0.254545   \n",
       "17  LambdaG               3   Wiki  0.562312  0.562312  0.172727   \n",
       "6     Llama               3   Wiki  0.765751  0.765751  0.272727   \n",
       "7      Qwen               3   Wiki  0.784350  0.784350  0.263636   \n",
       "8      GPT2               4   Wiki  0.922905  0.901566  0.300000   \n",
       "9     Gemma               4   Wiki  0.910830  0.889861  0.440000   \n",
       "16  LambdaG               4   Wiki  0.599499  0.587093  0.160000   \n",
       "10    Llama               4   Wiki  0.941129  0.919387  0.380000   \n",
       "11     Qwen               4   Wiki  0.942433  0.920607  0.460000   \n",
       "12     GPT2               5   Wiki  1.077874  0.912090  0.333333   \n",
       "13    Gemma               5   Wiki  1.204581  1.029580  0.333333   \n",
       "19  LambdaG               5   Wiki  0.938053  0.847183  0.111111   \n",
       "14    Llama               5   Wiki  1.199987  1.025905  0.222222   \n",
       "15     Qwen               5   Wiki  1.138986  0.963623  0.222222   \n",
       "\n",
       "    Mean_TRUE_LLR  Mean_FALSE_LLR  TRUE_trials  FALSE_trials       AUC  \\\n",
       "0        0.208998       -0.173308          112           112  0.728715   \n",
       "1        0.211959       -0.172018          112           112  0.728476   \n",
       "18       1.088023       -0.754360          112           112  0.900351   \n",
       "2        0.186027       -0.151607          112           112  0.713967   \n",
       "3        0.188741       -0.153150          112           112  0.713170   \n",
       "4        0.644993       -0.283621          111           110  0.803358   \n",
       "5        0.755199       -0.297221          111           110  0.807862   \n",
       "17       1.139454       -0.780592          111           110  0.904177   \n",
       "6        0.598792       -0.274310          111           110  0.796888   \n",
       "7        0.585540       -0.247986          111           110  0.782965   \n",
       "8        0.474158        0.050562           72            50  0.630000   \n",
       "9        0.589082        0.039772           72            50  0.635833   \n",
       "16       1.237530       -0.537456           72            50  0.896389   \n",
       "10       0.423787        0.070483           72            50  0.609444   \n",
       "11       0.438487        0.071780           72            50  0.608333   \n",
       "12       0.946139        0.329320           25             9  0.697778   \n",
       "13       0.938732        0.426749           25             9  0.684444   \n",
       "19       1.749561       -0.108504           25             9  0.884444   \n",
       "14       0.780013        0.429498           25             9  0.644444   \n",
       "15       1.005130        0.382986           25             9  0.671111   \n",
       "\n",
       "    Balanced_Accuracy  Precision    Recall        F1  TP  FP  FN  TN  \n",
       "0            0.665179   0.676190  0.633929  0.654378  71  34  41  78  \n",
       "1            0.665179   0.679612  0.625000  0.651163  70  33  42  79  \n",
       "18           0.825893   0.828829  0.821429  0.825112  92  19  20  93  \n",
       "2            0.638393   0.644860  0.616071  0.630137  69  38  43  74  \n",
       "3            0.629464   0.638095  0.598214  0.617512  67  38  45  74  \n",
       "4            0.719902   0.775281  0.621622  0.690000  69  20  42  90  \n",
       "5            0.747011   0.802198  0.657658  0.722772  73  18  38  92  \n",
       "17           0.828051   0.828829  0.828829  0.828829  92  19  19  91  \n",
       "6            0.706183   0.739583  0.639640  0.685990  71  25  40  85  \n",
       "7            0.710770   0.752688  0.630631  0.686275  70  23  41  87  \n",
       "8            0.572500   0.652174  0.625000  0.638298  45  24  27  26  \n",
       "9            0.559444   0.638889  0.638889  0.638889  46  26  26  24  \n",
       "16           0.811389   0.822785  0.902778  0.860927  65  14   7  36  \n",
       "10           0.553333   0.631579  0.666667  0.648649  48  28  24  22  \n",
       "11           0.526389   0.610390  0.652778  0.630872  47  30  25  20  \n",
       "12           0.460000   0.718750  0.920000  0.807018  23   9   2   0  \n",
       "13           0.500000   0.735294  1.000000  0.847458  25   9   0   0  \n",
       "19           0.868889   0.923077  0.960000  0.941176  24   2   1   7  \n",
       "14           0.500000   0.735294  1.000000  0.847458  25   9   0   0  \n",
       "15           0.500000   0.735294  1.000000  0.847458  25   9   0   0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_range_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7857ef56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>y_true</th>\n",
       "      <th>llr_lambdaG</th>\n",
       "      <th>Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>161.614000</td>\n",
       "      <td>161.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>153.800067</td>\n",
       "      <td>153.800067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rjecina vs Rjecina</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Rjecina</td>\n",
       "      <td>Rjecina</td>\n",
       "      <td>True</td>\n",
       "      <td>118.796333</td>\n",
       "      <td>118.796333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lear_21 vs Lear_21</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Lear_21</td>\n",
       "      <td>Lear_21</td>\n",
       "      <td>True</td>\n",
       "      <td>101.188267</td>\n",
       "      <td>101.188267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard_Daft vs Richard_Daft</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Richard_Daft</td>\n",
       "      <td>Richard_Daft</td>\n",
       "      <td>True</td>\n",
       "      <td>97.970333</td>\n",
       "      <td>97.970333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        problem corpus  known_author unknown_author  y_true  \\\n",
       "0            HOOTmag vs HOOTmag   Wiki       HOOTmag        HOOTmag    True   \n",
       "1            Icarus3 vs Icarus3   Wiki       Icarus3        Icarus3    True   \n",
       "2            Rjecina vs Rjecina   Wiki       Rjecina        Rjecina    True   \n",
       "3            Lear_21 vs Lear_21   Wiki       Lear_21        Lear_21    True   \n",
       "4  Richard_Daft vs Richard_Daft   Wiki  Richard_Daft   Richard_Daft    True   \n",
       "\n",
       "   llr_lambdaG   Magnitude  \n",
       "0   161.614000  161.614000  \n",
       "1   153.800067  153.800067  \n",
       "2   118.796333  118.796333  \n",
       "3   101.188267  101.188267  \n",
       "4    97.970333   97.970333  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdag_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "41883498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>min_token_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_llr</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>error</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.148831</td>\n",
       "      <td>-0.757322</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>GPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HOOTmag vs Iain99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218624</td>\n",
       "      <td>-0.553163</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>GPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.332957</td>\n",
       "      <td>-0.301765</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "      <td>GPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.177761</td>\n",
       "      <td>-0.665160</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>GPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>HonestopL vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.150081</td>\n",
       "      <td>-0.753053</td>\n",
       "      <td>False</td>\n",
       "      <td>TN</td>\n",
       "      <td>GPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2347</td>\n",
       "      <td>Viewfinder vs Viewfinder</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Viewfinder</td>\n",
       "      <td>Viewfinder</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.679126</td>\n",
       "      <td>0.325615</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>Qwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2358</td>\n",
       "      <td>Vr vs Vr</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Vr</td>\n",
       "      <td>Vr</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.897528</td>\n",
       "      <td>0.942443</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>Qwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2368</td>\n",
       "      <td>VsevolodKrolikov vs WIKI-GUY-16</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>VsevolodKrolikov</td>\n",
       "      <td>WIKI-GUY-16</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.226772</td>\n",
       "      <td>True</td>\n",
       "      <td>FP</td>\n",
       "      <td>Qwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2387</td>\n",
       "      <td>Wobble vs Wobble</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Wobble</td>\n",
       "      <td>Wobble</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.549256</td>\n",
       "      <td>0.085845</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>Qwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>2403</td>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.962211</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "      <td>Qwen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                             problem corpus      known_author  \\\n",
       "0         0                  HOOTmag vs HOOTmag   Wiki           HOOTmag   \n",
       "1         2                   HOOTmag vs Iain99   Wiki           HOOTmag   \n",
       "2         4  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   Hodja_Nasreddin   \n",
       "3         8        Hodja_Nasreddin vs HonestopL   Wiki   Hodja_Nasreddin   \n",
       "4        11                HonestopL vs HOOTmag   Wiki         HonestopL   \n",
       "...     ...                                 ...    ...               ...   \n",
       "2399   2347            Viewfinder vs Viewfinder   Wiki        Viewfinder   \n",
       "2400   2358                            Vr vs Vr   Wiki                Vr   \n",
       "2401   2368     VsevolodKrolikov vs WIKI-GUY-16   Wiki  VsevolodKrolikov   \n",
       "2402   2387                    Wobble vs Wobble   Wiki            Wobble   \n",
       "2403   2403    ZjarriRrethues vs ZjarriRrethues   Wiki    ZjarriRrethues   \n",
       "\n",
       "       unknown_author  target  min_token_size  y_true  pred_prob  pred_llr  \\\n",
       "0             HOOTmag    True               2    True   0.148831 -0.757322   \n",
       "1              Iain99   False               2   False   0.218624 -0.553163   \n",
       "2     Hodja_Nasreddin    True               2    True   0.332957 -0.301765   \n",
       "3           HonestopL   False               2   False   0.177761 -0.665160   \n",
       "4             HOOTmag   False               2   False   0.150081 -0.753053   \n",
       "...               ...     ...             ...     ...        ...       ...   \n",
       "2399       Viewfinder    True               5    True   0.679126  0.325615   \n",
       "2400               Vr    True               5    True   0.897528  0.942443   \n",
       "2401      WIKI-GUY-16   False               5   False   0.627653  0.226772   \n",
       "2402           Wobble    True               5    True   0.549256  0.085845   \n",
       "2403   ZjarriRrethues    True               5    True   0.901639  0.962211   \n",
       "\n",
       "      y_pred error model  \n",
       "0      False    FN  GPT2  \n",
       "1      False    TN  GPT2  \n",
       "2      False    FN  GPT2  \n",
       "3      False    TN  GPT2  \n",
       "4      False    TN  GPT2  \n",
       "...      ...   ...   ...  \n",
       "2399    True    TP  Qwen  \n",
       "2400    True    TP  Qwen  \n",
       "2401    True    FP  Qwen  \n",
       "2402    True    TP  Qwen  \n",
       "2403    True    TP  Qwen  \n",
       "\n",
       "[2404 rows x 13 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_detailed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c37a0",
   "metadata": {},
   "source": [
    "# New Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "53b185af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model: gpt2\n",
      "Working on model: gemma\n",
      "Working on model: llama\n",
      "Working on model: qwen\n"
     ]
    }
   ],
   "source": [
    "models = [\"gpt2\", \"gemma\", \"llama\", \"qwen\"]\n",
    "all_model_data = []\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Working on model: {model}\")\n",
    "    filtered_results_loc = f\"{base_loc}/{model} results/filtered\"\n",
    "    excel_files = sorted(glob(os.path.join(filtered_results_loc, \"*.xlsx\")))\n",
    "    all_merged = []\n",
    "\n",
    "    for file in excel_files:\n",
    "        data = read_excel_sheets(file, ['metadata', 'LLR'])\n",
    "\n",
    "        metadata = data['metadata']\n",
    "        metadata['model'] = model\n",
    "        llr = data['LLR']\n",
    "\n",
    "        metadata_info = metadata[[\n",
    "            'model', 'sample_id', 'problem', 'corpus', 'known_author',\n",
    "            'unknown_author', 'unknown_doc_id', 'known_doc_id', 'target'\n",
    "        ]].copy()\n",
    "\n",
    "        metadata_repeated = pd.concat([metadata_info] * len(llr), ignore_index=True)\n",
    "        llr_with_metadata = pd.concat([metadata_repeated, llr.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        merged = llr_with_metadata.merge(\n",
    "            phrases,\n",
    "            left_on='original_phrase',\n",
    "            right_on='phrase',\n",
    "            how='inner'\n",
    "        )\n",
    "\n",
    "        all_merged.append(merged)\n",
    "\n",
    "    final_merged_table = pd.concat(all_merged, ignore_index=True)\n",
    "    all_model_data.append(final_merged_table)\n",
    "\n",
    "# Combine all model results\n",
    "results = pd.concat(all_model_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "918fe918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>target</th>\n",
       "      <th>phrase_num</th>\n",
       "      <th>...</th>\n",
       "      <th>pmf_no_context</th>\n",
       "      <th>pmf_known</th>\n",
       "      <th>pmf_unknown</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>keep_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.786260e-01</td>\n",
       "      <td>0.538874</td>\n",
       "      <td>0.342302</td>\n",
       "      <td>0.748055</td>\n",
       "      <td>0.268512</td>\n",
       "      <td>0.465591</td>\n",
       "      <td>, this is not</td>\n",
       "      <td>(',', 'Ġthis', 'Ġis', 'Ġnot')</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.456316e-02</td>\n",
       "      <td>0.025498</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>1.836744</td>\n",
       "      <td>1.593489</td>\n",
       "      <td>1.593377</td>\n",
       "      <td>, but this</td>\n",
       "      <td>(',', 'Ġbut', 'Ġthis')</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.456316e-02</td>\n",
       "      <td>0.037797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.836744</td>\n",
       "      <td>1.422542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>, but this</td>\n",
       "      <td>(',', 'Ġbut', 'Ġthis')</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.041954e-01</td>\n",
       "      <td>0.798107</td>\n",
       "      <td>0.634982</td>\n",
       "      <td>0.516847</td>\n",
       "      <td>0.097939</td>\n",
       "      <td>0.197239</td>\n",
       "      <td>, you are</td>\n",
       "      <td>(',', 'Ġyou', 'Ġare')</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>hodja_nasreddin_text_1</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.193018e-02</td>\n",
       "      <td>0.182487</td>\n",
       "      <td>0.337093</td>\n",
       "      <td>1.658958</td>\n",
       "      <td>0.738769</td>\n",
       "      <td>0.472250</td>\n",
       "      <td>do not have</td>\n",
       "      <td>('Ġdo', 'Ġnot', 'Ġhave')</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79555</th>\n",
       "      <td>qwen</td>\n",
       "      <td>672</td>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>zjarrirrethues_text_2</td>\n",
       "      <td>zjarrirrethues_text_5</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_12</td>\n",
       "      <td>...</td>\n",
       "      <td>5.797459e-08</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.269715</td>\n",
       "      <td>7.236762</td>\n",
       "      <td>1.762178</td>\n",
       "      <td>0.569095</td>\n",
       "      <td>regarded as</td>\n",
       "      <td>('Ġregarded', 'Ġas')</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79556</th>\n",
       "      <td>qwen</td>\n",
       "      <td>672</td>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>zjarrirrethues_text_2</td>\n",
       "      <td>zjarrirrethues_text_5</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.685062e-04</td>\n",
       "      <td>0.312985</td>\n",
       "      <td>0.172824</td>\n",
       "      <td>3.773384</td>\n",
       "      <td>0.504476</td>\n",
       "      <td>0.762397</td>\n",
       "      <td>the two</td>\n",
       "      <td>('Ġthe', 'Ġtwo')</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79557</th>\n",
       "      <td>qwen</td>\n",
       "      <td>672</td>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>zjarrirrethues_text_2</td>\n",
       "      <td>zjarrirrethues_text_5</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.685062e-04</td>\n",
       "      <td>0.516038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.773384</td>\n",
       "      <td>0.287318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>the two</td>\n",
       "      <td>('Ġthe', 'Ġtwo')</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79558</th>\n",
       "      <td>qwen</td>\n",
       "      <td>672</td>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>zjarrirrethues_text_2</td>\n",
       "      <td>zjarrirrethues_text_5</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602955e-02</td>\n",
       "      <td>0.552751</td>\n",
       "      <td>0.957715</td>\n",
       "      <td>1.795079</td>\n",
       "      <td>0.257471</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>with the</td>\n",
       "      <td>('Ġwith', 'Ġthe')</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79559</th>\n",
       "      <td>qwen</td>\n",
       "      <td>672</td>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>zjarrirrethues_text_2</td>\n",
       "      <td>zjarrirrethues_text_5</td>\n",
       "      <td>True</td>\n",
       "      <td>phrase_14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602955e-02</td>\n",
       "      <td>0.969113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.795079</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>with the</td>\n",
       "      <td>('Ġwith', 'Ġthe')</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79560 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  sample_id                             problem corpus  \\\n",
       "0      gpt2          1  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "1      gpt2          1  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "2      gpt2          1  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "3      gpt2          1  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "4      gpt2          1  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "...     ...        ...                                 ...    ...   \n",
       "79555  qwen        672    ZjarriRrethues vs ZjarriRrethues   Wiki   \n",
       "79556  qwen        672    ZjarriRrethues vs ZjarriRrethues   Wiki   \n",
       "79557  qwen        672    ZjarriRrethues vs ZjarriRrethues   Wiki   \n",
       "79558  qwen        672    ZjarriRrethues vs ZjarriRrethues   Wiki   \n",
       "79559  qwen        672    ZjarriRrethues vs ZjarriRrethues   Wiki   \n",
       "\n",
       "          known_author   unknown_author          unknown_doc_id  \\\n",
       "0      Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_3   \n",
       "1      Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_3   \n",
       "2      Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_3   \n",
       "3      Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_3   \n",
       "4      Hodja_Nasreddin  Hodja_Nasreddin  hodja_nasreddin_text_3   \n",
       "...                ...              ...                     ...   \n",
       "79555   ZjarriRrethues   ZjarriRrethues   zjarrirrethues_text_2   \n",
       "79556   ZjarriRrethues   ZjarriRrethues   zjarrirrethues_text_2   \n",
       "79557   ZjarriRrethues   ZjarriRrethues   zjarrirrethues_text_2   \n",
       "79558   ZjarriRrethues   ZjarriRrethues   zjarrirrethues_text_2   \n",
       "79559   ZjarriRrethues   ZjarriRrethues   zjarrirrethues_text_2   \n",
       "\n",
       "                 known_doc_id  target phrase_num  ...  pmf_no_context  \\\n",
       "0      hodja_nasreddin_text_1    True  phrase_01  ...    1.786260e-01   \n",
       "1      hodja_nasreddin_text_1    True  phrase_02  ...    1.456316e-02   \n",
       "2      hodja_nasreddin_text_1    True  phrase_02  ...    1.456316e-02   \n",
       "3      hodja_nasreddin_text_1    True  phrase_03  ...    3.041954e-01   \n",
       "4      hodja_nasreddin_text_1    True  phrase_04  ...    2.193018e-02   \n",
       "...                       ...     ...        ...  ...             ...   \n",
       "79555   zjarrirrethues_text_5    True  phrase_12  ...    5.797459e-08   \n",
       "79556   zjarrirrethues_text_5    True  phrase_13  ...    1.685062e-04   \n",
       "79557   zjarrirrethues_text_5    True  phrase_13  ...    1.685062e-04   \n",
       "79558   zjarrirrethues_text_5    True  phrase_14  ...    1.602955e-02   \n",
       "79559   zjarrirrethues_text_5    True  phrase_14  ...    1.602955e-02   \n",
       "\n",
       "      pmf_known  pmf_unknown  llr_no_context  llr_known  llr_unknown  \\\n",
       "0      0.538874     0.342302        0.748055   0.268512     0.465591   \n",
       "1      0.025498     0.025505        1.836744   1.593489     1.593377   \n",
       "2      0.037797     0.000000        1.836744   1.422542     0.000000   \n",
       "3      0.798107     0.634982        0.516847   0.097939     0.197239   \n",
       "4      0.182487     0.337093        1.658958   0.738769     0.472250   \n",
       "...         ...          ...             ...        ...          ...   \n",
       "79555  0.017291     0.269715        7.236762   1.762178     0.569095   \n",
       "79556  0.312985     0.172824        3.773384   0.504476     0.762397   \n",
       "79557  0.516038     0.000000        3.773384   0.287318     0.000000   \n",
       "79558  0.552751     0.957715        1.795079   0.257471     0.018764   \n",
       "79559  0.969113     0.000000        1.795079   0.013626     0.000000   \n",
       "\n",
       "              phrase                         tokens  num_tokens  keep_phrase  \n",
       "0      , this is not  (',', 'Ġthis', 'Ġis', 'Ġnot')           4          1.0  \n",
       "1         , but this         (',', 'Ġbut', 'Ġthis')           3          1.0  \n",
       "2         , but this         (',', 'Ġbut', 'Ġthis')           3          1.0  \n",
       "3          , you are          (',', 'Ġyou', 'Ġare')           3          1.0  \n",
       "4        do not have       ('Ġdo', 'Ġnot', 'Ġhave')           3          1.0  \n",
       "...              ...                            ...         ...          ...  \n",
       "79555    regarded as           ('Ġregarded', 'Ġas')           2          1.0  \n",
       "79556        the two               ('Ġthe', 'Ġtwo')           2          1.0  \n",
       "79557        the two               ('Ġthe', 'Ġtwo')           2          1.0  \n",
       "79558       with the              ('Ġwith', 'Ġthe')           2          1.0  \n",
       "79559       with the              ('Ġwith', 'Ġthe')           2          1.0  \n",
       "\n",
       "[79560 rows x 24 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0baac61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    'model', 'problem', 'corpus', 'known_author', 'unknown_author', 'target',\n",
    "    'original_phrase', 'num_tokens', 'phrase_occurence'\n",
    "]\n",
    "\n",
    "avg_cols = [\n",
    "    'llr_no_context', 'llr_known', 'llr_unknown'\n",
    "]\n",
    "\n",
    "# Group and compute the mean\n",
    "grouped_results = (\n",
    "    results\n",
    "    .groupby(group_cols, as_index=False)[avg_cols]\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8502723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grouping and aggregation columns\n",
    "group_cols = [\n",
    "    'model', 'problem', 'corpus', 'known_author', 'unknown_author', 'target'\n",
    "]\n",
    "\n",
    "avg_cols = [\n",
    "    'llr_no_context', 'llr_known', 'llr_unknown'\n",
    "]\n",
    "\n",
    "# Get unique num_tokens thresholds (sorted ascending)\n",
    "token_thresholds = sorted(grouped_results['num_tokens'].dropna().unique())\n",
    "\n",
    "# Container for results\n",
    "all_summaries = []\n",
    "\n",
    "# Loop through each token threshold\n",
    "for min_token_size in token_thresholds:\n",
    "    # Filter rows where num_tokens >= threshold\n",
    "    filtered = grouped_results[grouped_results['num_tokens'] >= min_token_size]\n",
    "\n",
    "    # Group and sum\n",
    "    grouped = (\n",
    "        filtered\n",
    "        .groupby(group_cols, as_index=False)[avg_cols]\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "    # Add the min_token_size column\n",
    "    grouped['min_token_size'] = min_token_size\n",
    "\n",
    "    # Append to results\n",
    "    all_summaries.append(grouped)\n",
    "\n",
    "# Combine all grouped results\n",
    "final_summary = pd.concat(all_summaries, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7bf03c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>min_token_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma</td>\n",
       "      <td>HOOTmag vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>True</td>\n",
       "      <td>11.465530</td>\n",
       "      <td>6.466093</td>\n",
       "      <td>5.573082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma</td>\n",
       "      <td>HOOTmag vs Iain99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>False</td>\n",
       "      <td>20.322664</td>\n",
       "      <td>9.369514</td>\n",
       "      <td>8.975726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma</td>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>True</td>\n",
       "      <td>37.195349</td>\n",
       "      <td>18.902095</td>\n",
       "      <td>21.116380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma</td>\n",
       "      <td>Hodja_Nasreddin vs HonestopL</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>False</td>\n",
       "      <td>20.874336</td>\n",
       "      <td>11.303276</td>\n",
       "      <td>6.707240</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma</td>\n",
       "      <td>HonestopL vs HOOTmag</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>HonestopL</td>\n",
       "      <td>HOOTmag</td>\n",
       "      <td>False</td>\n",
       "      <td>14.216544</td>\n",
       "      <td>5.793687</td>\n",
       "      <td>8.871717</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>gemma</td>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>llama</td>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>qwen</td>\n",
       "      <td>Icarus3 vs Icarus3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>Icarus3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                             problem corpus     known_author  \\\n",
       "0     gemma                  HOOTmag vs HOOTmag   Wiki          HOOTmag   \n",
       "1     gemma                   HOOTmag vs Iain99   Wiki          HOOTmag   \n",
       "2     gemma  Hodja_Nasreddin vs Hodja_Nasreddin   Wiki  Hodja_Nasreddin   \n",
       "3     gemma        Hodja_Nasreddin vs HonestopL   Wiki  Hodja_Nasreddin   \n",
       "4     gemma                HonestopL vs HOOTmag   Wiki        HonestopL   \n",
       "...     ...                                 ...    ...              ...   \n",
       "4103   qwen                  Icarus3 vs Icarus3   Wiki          Icarus3   \n",
       "4104  gemma                  Icarus3 vs Icarus3   Wiki          Icarus3   \n",
       "4105   gpt2                  Icarus3 vs Icarus3   Wiki          Icarus3   \n",
       "4106  llama                  Icarus3 vs Icarus3   Wiki          Icarus3   \n",
       "4107   qwen                  Icarus3 vs Icarus3   Wiki          Icarus3   \n",
       "\n",
       "       unknown_author  target  llr_no_context  llr_known  llr_unknown  \\\n",
       "0             HOOTmag    True       11.465530   6.466093     5.573082   \n",
       "1              Iain99   False       20.322664   9.369514     8.975726   \n",
       "2     Hodja_Nasreddin    True       37.195349  18.902095    21.116380   \n",
       "3           HonestopL   False       20.874336  11.303276     6.707240   \n",
       "4             HOOTmag   False       14.216544   5.793687     8.871717   \n",
       "...               ...     ...             ...        ...          ...   \n",
       "4103          Icarus3    True        0.000000   0.000000     0.000000   \n",
       "4104          Icarus3    True        0.000000   0.000000     0.000000   \n",
       "4105          Icarus3    True        0.000000   0.000000     0.000000   \n",
       "4106          Icarus3    True        0.000000   0.000000     0.000000   \n",
       "4107          Icarus3    True        0.000000   0.000000     0.000000   \n",
       "\n",
       "      min_token_size  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "...              ...  \n",
       "4103             300  \n",
       "4104             320  \n",
       "4105             320  \n",
       "4106             320  \n",
       "4107             320  \n",
       "\n",
       "[4108 rows x 10 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "c4d47002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_summary.to_excel('/Volumes/BCross/paraphrase examples slurm/score_by_token_size_avg.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7f94f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_token_level_results = (\n",
    "    final_summary\n",
    "    .query(f\"min_token_size <= {highest_min_token_size}\")\n",
    ")\n",
    "\n",
    "agg_token_problems_to_keep = (\n",
    "    filtered_token_level_results\n",
    "    [['problem', 'corpus', 'min_token_size', 'target']]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "agg_token_dataset = (\n",
    "    final_summary\n",
    "    .merge(agg_token_problems_to_keep, on = ['problem', 'corpus', 'min_token_size', 'target'], how='inner')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_token_problems_to_keep.to_excel('/Volumes/BCross/paraphrase examples slurm/token_size_problems.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "735fdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grouped scores\n",
    "id_cols = [\n",
    "    \"problem\", \"corpus\",\n",
    "    \"known_author\", \"unknown_author\",\n",
    "    \"target\", \"min_token_size\"\n",
    "]\n",
    "\n",
    "token_summary, token_detailed = performance(\n",
    "    agg_token_dataset,\n",
    "    keep_cols=[\"corpus\"],\n",
    "    score_col=\"llr_unknown\",\n",
    "    target_col=\"target\",\n",
    "    return_pred_rows=True,\n",
    "    id_cols=id_cols,\n",
    "    group_cols=[\"model\", \"min_token_size\"]\n",
    ")\n",
    "token_summary = token_summary.sort_values(by=['min_token_size', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "f7549a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>corpus</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>y_true</th>\n",
       "      <th>llr_lambdaG</th>\n",
       "      <th>Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rjecina vs Rjecina</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Rjecina</td>\n",
       "      <td>Rjecina</td>\n",
       "      <td>True</td>\n",
       "      <td>118.796333</td>\n",
       "      <td>118.796333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jimharlow99 vs Jimharlow99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Jimharlow99</td>\n",
       "      <td>Jimharlow99</td>\n",
       "      <td>True</td>\n",
       "      <td>53.548867</td>\n",
       "      <td>53.548867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vr vs Vr</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Vr</td>\n",
       "      <td>Vr</td>\n",
       "      <td>True</td>\n",
       "      <td>52.380867</td>\n",
       "      <td>52.380867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sennen_goroshi vs Sennen_goroshi</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Sennen_goroshi</td>\n",
       "      <td>Sennen_goroshi</td>\n",
       "      <td>True</td>\n",
       "      <td>49.705867</td>\n",
       "      <td>49.705867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul_Siebert vs Paul_Siebert</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Paul_Siebert</td>\n",
       "      <td>Paul_Siebert</td>\n",
       "      <td>True</td>\n",
       "      <td>48.321400</td>\n",
       "      <td>48.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iain99 vs Iain99</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>Iain99</td>\n",
       "      <td>True</td>\n",
       "      <td>46.865867</td>\n",
       "      <td>46.865867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jeffrey_Vernon_Merkey vs Jeffrey_Vernon_Merkey</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Jeffrey_Vernon_Merkey</td>\n",
       "      <td>Jeffrey_Vernon_Merkey</td>\n",
       "      <td>True</td>\n",
       "      <td>39.656667</td>\n",
       "      <td>39.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nirvana888 vs Nirvana888</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Nirvana888</td>\n",
       "      <td>Nirvana888</td>\n",
       "      <td>True</td>\n",
       "      <td>37.432733</td>\n",
       "      <td>37.432733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JerryFriedman vs JerryFriedman</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>JerryFriedman</td>\n",
       "      <td>True</td>\n",
       "      <td>33.485000</td>\n",
       "      <td>33.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mystichumwipe vs Mystichumwipe</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Mystichumwipe</td>\n",
       "      <td>Mystichumwipe</td>\n",
       "      <td>True</td>\n",
       "      <td>32.708600</td>\n",
       "      <td>32.708600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PinkAmpersand vs PinkAmpersand</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>PinkAmpersand</td>\n",
       "      <td>PinkAmpersand</td>\n",
       "      <td>True</td>\n",
       "      <td>26.719000</td>\n",
       "      <td>26.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Musical_Linguist vs Musical_Linguist</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Musical_Linguist</td>\n",
       "      <td>Musical_Linguist</td>\n",
       "      <td>True</td>\n",
       "      <td>24.939067</td>\n",
       "      <td>24.939067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pro-Lick vs Protonk</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Pro-Lick</td>\n",
       "      <td>Protonk</td>\n",
       "      <td>False</td>\n",
       "      <td>-24.179400</td>\n",
       "      <td>24.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tintin1107 vs Tintin1107</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Tintin1107</td>\n",
       "      <td>Tintin1107</td>\n",
       "      <td>True</td>\n",
       "      <td>24.108667</td>\n",
       "      <td>24.108667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mathsci vs Maunus</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Mathsci</td>\n",
       "      <td>Maunus</td>\n",
       "      <td>False</td>\n",
       "      <td>22.692800</td>\n",
       "      <td>22.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hodja_Nasreddin vs Hodja_Nasreddin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>True</td>\n",
       "      <td>21.316867</td>\n",
       "      <td>21.316867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KillerChihuahua vs KillerChihuahua</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>KillerChihuahua</td>\n",
       "      <td>KillerChihuahua</td>\n",
       "      <td>True</td>\n",
       "      <td>16.782600</td>\n",
       "      <td>16.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Viewfinder vs Viewfinder</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Viewfinder</td>\n",
       "      <td>Viewfinder</td>\n",
       "      <td>True</td>\n",
       "      <td>12.431933</td>\n",
       "      <td>12.431933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wobble vs Wobble</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Wobble</td>\n",
       "      <td>Wobble</td>\n",
       "      <td>True</td>\n",
       "      <td>11.273067</td>\n",
       "      <td>11.273067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Milomedes vs Milomedes</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Milomedes</td>\n",
       "      <td>Milomedes</td>\n",
       "      <td>True</td>\n",
       "      <td>11.228467</td>\n",
       "      <td>11.228467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Orangemarlin vs Orangemarlin</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Orangemarlin</td>\n",
       "      <td>Orangemarlin</td>\n",
       "      <td>True</td>\n",
       "      <td>10.855667</td>\n",
       "      <td>10.855667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U21980 vs UpDown</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>U21980</td>\n",
       "      <td>UpDown</td>\n",
       "      <td>False</td>\n",
       "      <td>-10.703400</td>\n",
       "      <td>10.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IvoShandor vs Jasper_Deng</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>IvoShandor</td>\n",
       "      <td>Jasper_Deng</td>\n",
       "      <td>False</td>\n",
       "      <td>-10.521267</td>\n",
       "      <td>10.521267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NJGW vs NJGW</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>NJGW</td>\n",
       "      <td>NJGW</td>\n",
       "      <td>True</td>\n",
       "      <td>-8.915533</td>\n",
       "      <td>8.915533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ZjarriRrethues vs ZjarriRrethues</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>ZjarriRrethues</td>\n",
       "      <td>True</td>\n",
       "      <td>8.893733</td>\n",
       "      <td>8.893733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VsevolodKrolikov vs WIKI-GUY-16</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>VsevolodKrolikov</td>\n",
       "      <td>WIKI-GUY-16</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.880133</td>\n",
       "      <td>7.880133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PeterSymonds vs PeterSymonds</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>PeterSymonds</td>\n",
       "      <td>PeterSymonds</td>\n",
       "      <td>True</td>\n",
       "      <td>7.748067</td>\n",
       "      <td>7.748067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>N419BH vs N419BH</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>N419BH</td>\n",
       "      <td>N419BH</td>\n",
       "      <td>True</td>\n",
       "      <td>6.683267</td>\n",
       "      <td>6.683267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nableezy vs Nableezy</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Nableezy</td>\n",
       "      <td>Nableezy</td>\n",
       "      <td>True</td>\n",
       "      <td>5.494867</td>\n",
       "      <td>5.494867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>T34CH vs T34CH</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>T34CH</td>\n",
       "      <td>T34CH</td>\n",
       "      <td>True</td>\n",
       "      <td>5.425867</td>\n",
       "      <td>5.425867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sally_Season vs Scheinwerfermann</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Sally_Season</td>\n",
       "      <td>Scheinwerfermann</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.962267</td>\n",
       "      <td>3.962267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nableezy vs Nathan</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Nableezy</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.502000</td>\n",
       "      <td>3.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PeterSymonds vs Peter_James</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>PeterSymonds</td>\n",
       "      <td>Peter_James</td>\n",
       "      <td>False</td>\n",
       "      <td>1.819267</td>\n",
       "      <td>1.819267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Notpietru vs Obamafan70</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Notpietru</td>\n",
       "      <td>Obamafan70</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.793667</td>\n",
       "      <td>0.793667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           problem corpus  \\\n",
       "0                               Rjecina vs Rjecina   Wiki   \n",
       "1                       Jimharlow99 vs Jimharlow99   Wiki   \n",
       "2                                         Vr vs Vr   Wiki   \n",
       "3                 Sennen_goroshi vs Sennen_goroshi   Wiki   \n",
       "4                     Paul_Siebert vs Paul_Siebert   Wiki   \n",
       "5                                 Iain99 vs Iain99   Wiki   \n",
       "6   Jeffrey_Vernon_Merkey vs Jeffrey_Vernon_Merkey   Wiki   \n",
       "7                         Nirvana888 vs Nirvana888   Wiki   \n",
       "8                   JerryFriedman vs JerryFriedman   Wiki   \n",
       "9                   Mystichumwipe vs Mystichumwipe   Wiki   \n",
       "10                  PinkAmpersand vs PinkAmpersand   Wiki   \n",
       "11            Musical_Linguist vs Musical_Linguist   Wiki   \n",
       "12                             Pro-Lick vs Protonk   Wiki   \n",
       "13                        Tintin1107 vs Tintin1107   Wiki   \n",
       "14                               Mathsci vs Maunus   Wiki   \n",
       "15              Hodja_Nasreddin vs Hodja_Nasreddin   Wiki   \n",
       "16              KillerChihuahua vs KillerChihuahua   Wiki   \n",
       "17                        Viewfinder vs Viewfinder   Wiki   \n",
       "18                                Wobble vs Wobble   Wiki   \n",
       "19                          Milomedes vs Milomedes   Wiki   \n",
       "20                    Orangemarlin vs Orangemarlin   Wiki   \n",
       "21                                U21980 vs UpDown   Wiki   \n",
       "22                       IvoShandor vs Jasper_Deng   Wiki   \n",
       "23                                    NJGW vs NJGW   Wiki   \n",
       "24                ZjarriRrethues vs ZjarriRrethues   Wiki   \n",
       "25                 VsevolodKrolikov vs WIKI-GUY-16   Wiki   \n",
       "26                    PeterSymonds vs PeterSymonds   Wiki   \n",
       "27                                N419BH vs N419BH   Wiki   \n",
       "28                            Nableezy vs Nableezy   Wiki   \n",
       "29                                  T34CH vs T34CH   Wiki   \n",
       "30                Sally_Season vs Scheinwerfermann   Wiki   \n",
       "31                              Nableezy vs Nathan   Wiki   \n",
       "32                     PeterSymonds vs Peter_James   Wiki   \n",
       "33                         Notpietru vs Obamafan70   Wiki   \n",
       "\n",
       "             known_author         unknown_author  y_true  llr_lambdaG  \\\n",
       "0                 Rjecina                Rjecina    True   118.796333   \n",
       "1             Jimharlow99            Jimharlow99    True    53.548867   \n",
       "2                      Vr                     Vr    True    52.380867   \n",
       "3          Sennen_goroshi         Sennen_goroshi    True    49.705867   \n",
       "4            Paul_Siebert           Paul_Siebert    True    48.321400   \n",
       "5                  Iain99                 Iain99    True    46.865867   \n",
       "6   Jeffrey_Vernon_Merkey  Jeffrey_Vernon_Merkey    True    39.656667   \n",
       "7              Nirvana888             Nirvana888    True    37.432733   \n",
       "8           JerryFriedman          JerryFriedman    True    33.485000   \n",
       "9           Mystichumwipe          Mystichumwipe    True    32.708600   \n",
       "10          PinkAmpersand          PinkAmpersand    True    26.719000   \n",
       "11       Musical_Linguist       Musical_Linguist    True    24.939067   \n",
       "12               Pro-Lick                Protonk   False   -24.179400   \n",
       "13             Tintin1107             Tintin1107    True    24.108667   \n",
       "14                Mathsci                 Maunus   False    22.692800   \n",
       "15        Hodja_Nasreddin        Hodja_Nasreddin    True    21.316867   \n",
       "16        KillerChihuahua        KillerChihuahua    True    16.782600   \n",
       "17             Viewfinder             Viewfinder    True    12.431933   \n",
       "18                 Wobble                 Wobble    True    11.273067   \n",
       "19              Milomedes              Milomedes    True    11.228467   \n",
       "20           Orangemarlin           Orangemarlin    True    10.855667   \n",
       "21                 U21980                 UpDown   False   -10.703400   \n",
       "22             IvoShandor            Jasper_Deng   False   -10.521267   \n",
       "23                   NJGW                   NJGW    True    -8.915533   \n",
       "24         ZjarriRrethues         ZjarriRrethues    True     8.893733   \n",
       "25       VsevolodKrolikov            WIKI-GUY-16   False    -7.880133   \n",
       "26           PeterSymonds           PeterSymonds    True     7.748067   \n",
       "27                 N419BH                 N419BH    True     6.683267   \n",
       "28               Nableezy               Nableezy    True     5.494867   \n",
       "29                  T34CH                  T34CH    True     5.425867   \n",
       "30           Sally_Season       Scheinwerfermann   False    -3.962267   \n",
       "31               Nableezy                 Nathan   False    -3.502000   \n",
       "32           PeterSymonds            Peter_James   False     1.819267   \n",
       "33              Notpietru             Obamafan70   False    -0.793667   \n",
       "\n",
       "     Magnitude  \n",
       "0   118.796333  \n",
       "1    53.548867  \n",
       "2    52.380867  \n",
       "3    49.705867  \n",
       "4    48.321400  \n",
       "5    46.865867  \n",
       "6    39.656667  \n",
       "7    37.432733  \n",
       "8    33.485000  \n",
       "9    32.708600  \n",
       "10   26.719000  \n",
       "11   24.939067  \n",
       "12   24.179400  \n",
       "13   24.108667  \n",
       "14   22.692800  \n",
       "15   21.316867  \n",
       "16   16.782600  \n",
       "17   12.431933  \n",
       "18   11.273067  \n",
       "19   11.228467  \n",
       "20   10.855667  \n",
       "21   10.703400  \n",
       "22   10.521267  \n",
       "23    8.915533  \n",
       "24    8.893733  \n",
       "25    7.880133  \n",
       "26    7.748067  \n",
       "27    6.683267  \n",
       "28    5.494867  \n",
       "29    5.425867  \n",
       "30    3.962267  \n",
       "31    3.502000  \n",
       "32    1.819267  \n",
       "33    0.793667  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_lambda_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0e5ea26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_lambdag_sum = pd.DataFrame()\n",
    "\n",
    "token_ranges = agg_token_problems_to_keep['min_token_size'].drop_duplicates().tolist()\n",
    "\n",
    "for token in token_ranges:\n",
    "    problems = (\n",
    "        agg_token_problems_to_keep\n",
    "        .query(f'min_token_size == {token}')\n",
    "        [['problem']]\n",
    "    )\n",
    "    \n",
    "    filtered_lambda_g = (\n",
    "        lambdag_metrics\n",
    "        .merge(problems, on=['problem'], how='inner')\n",
    "    )\n",
    "    \n",
    "    filtered_lambdag_sum, filtered_lambdag_detailed = performance(\n",
    "        filtered_lambda_g,\n",
    "        score_col='llr_lambdaG',\n",
    "        target_col='y_true',\n",
    "        return_pred_rows=True,\n",
    "        id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "        additional_metadata={\"model\": \"LambdaG\", \"min_token_size\": token, \"corpus\": \"Wiki\"}\n",
    "    )\n",
    "    \n",
    "    all_filtered_lambdag_sum = pd.concat([all_filtered_lambdag_sum, filtered_lambdag_sum], ignore_index=True)\n",
    "    \n",
    "token_range_summary = (\n",
    "    pd.concat([token_summary, all_filtered_lambdag_sum], ignore_index=True)\n",
    "    .sort_values(by=['min_token_size', 'model'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "21c6f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>min_token_size</th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.573212</td>\n",
       "      <td>0.573212</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>1.088023</td>\n",
       "      <td>-0.754360</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.900351</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.820367</td>\n",
       "      <td>0.820367</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.310633</td>\n",
       "      <td>-0.230369</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.765226</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.300450</td>\n",
       "      <td>-0.233368</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.764509</td>\n",
       "      <td>0.691964</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.839782</td>\n",
       "      <td>0.839782</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.270608</td>\n",
       "      <td>-0.204705</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.749761</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>73</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen</td>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.840464</td>\n",
       "      <td>0.840464</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.267257</td>\n",
       "      <td>-0.204060</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>0.747210</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.562312</td>\n",
       "      <td>0.562312</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>1.139454</td>\n",
       "      <td>-0.780592</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>0.828051</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.707660</td>\n",
       "      <td>0.707660</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>1.011163</td>\n",
       "      <td>-0.354872</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.836446</td>\n",
       "      <td>0.746970</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.718715</td>\n",
       "      <td>0.718715</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>-0.335827</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.830057</td>\n",
       "      <td>0.728911</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.639640</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>0.722694</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.880921</td>\n",
       "      <td>-0.330686</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.826699</td>\n",
       "      <td>0.728829</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>qwen</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.748168</td>\n",
       "      <td>0.748168</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.747834</td>\n",
       "      <td>-0.296374</td>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>0.719902</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>69</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.556246</td>\n",
       "      <td>0.532731</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>1.539337</td>\n",
       "      <td>-0.587689</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>0.916143</td>\n",
       "      <td>0.819602</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemma</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.856437</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>1.078950</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>0.709224</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>63</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.840497</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.810071</td>\n",
       "      <td>0.060908</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>0.702935</td>\n",
       "      <td>0.610273</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.884603</td>\n",
       "      <td>0.842333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.913779</td>\n",
       "      <td>0.066089</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.615828</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.718232</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>qwen</td>\n",
       "      <td>4</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.892014</td>\n",
       "      <td>0.849453</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.072411</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>0.683648</td>\n",
       "      <td>0.600839</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.707182</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.680027</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.664632</td>\n",
       "      <td>-0.160827</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.101909</td>\n",
       "      <td>0.770853</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.041698</td>\n",
       "      <td>0.427209</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.066751</td>\n",
       "      <td>0.736722</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.041125</td>\n",
       "      <td>0.403061</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.126576</td>\n",
       "      <td>0.781958</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.955373</td>\n",
       "      <td>0.455422</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen</td>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1.069130</td>\n",
       "      <td>0.739412</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.033265</td>\n",
       "      <td>0.404918</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  min_token_size corpus      Cllr  Cllr_min       EER  \\\n",
       "16  LambdaG               2   Wiki  0.573212  0.573212  0.169643   \n",
       "0     gemma               2   Wiki  0.820367  0.820367  0.303571   \n",
       "1      gpt2               2   Wiki  0.819109  0.819109  0.330357   \n",
       "2     llama               2   Wiki  0.839782  0.839782  0.330357   \n",
       "3      qwen               2   Wiki  0.840464  0.840464  0.366071   \n",
       "17  LambdaG               3   Wiki  0.562312  0.562312  0.172727   \n",
       "4     gemma               3   Wiki  0.707660  0.707660  0.236364   \n",
       "5      gpt2               3   Wiki  0.718715  0.718715  0.290909   \n",
       "6     llama               3   Wiki  0.722694  0.722694  0.263636   \n",
       "7      qwen               3   Wiki  0.748168  0.748168  0.290909   \n",
       "18  LambdaG               4   Wiki  0.556246  0.532731  0.150943   \n",
       "8     gemma               4   Wiki  0.856437  0.815686  0.358491   \n",
       "9      gpt2               4   Wiki  0.882488  0.840497  0.339623   \n",
       "10    llama               4   Wiki  0.884603  0.842333  0.339623   \n",
       "11     qwen               4   Wiki  0.892014  0.849453  0.377358   \n",
       "19  LambdaG               5   Wiki  0.863487  0.680027  0.100000   \n",
       "12    gemma               5   Wiki  1.101909  0.770853  0.300000   \n",
       "13     gpt2               5   Wiki  1.066751  0.736722  0.300000   \n",
       "14    llama               5   Wiki  1.126576  0.781958  0.300000   \n",
       "15     qwen               5   Wiki  1.069130  0.739412  0.300000   \n",
       "\n",
       "    Mean_TRUE_LLR  Mean_FALSE_LLR  TRUE_trials  FALSE_trials       AUC  \\\n",
       "16       1.088023       -0.754360          112           112  0.900351   \n",
       "0        0.310633       -0.230369          112           112  0.765226   \n",
       "1        0.300450       -0.233368          112           112  0.764509   \n",
       "2        0.270608       -0.204705          112           112  0.749761   \n",
       "3        0.267257       -0.204060          112           112  0.747210   \n",
       "17       1.139454       -0.780592          111           110  0.904177   \n",
       "4        1.011163       -0.354872          111           110  0.836446   \n",
       "5        0.836390       -0.335827          111           110  0.830057   \n",
       "6        0.880921       -0.330686          111           110  0.826699   \n",
       "7        0.747834       -0.296374          111           110  0.810074   \n",
       "18       1.539337       -0.587689           90            53  0.916143   \n",
       "8        1.078950        0.036200           90            53  0.709224   \n",
       "9        0.810071        0.060908           90            53  0.702935   \n",
       "10       0.913779        0.066089           90            53  0.688889   \n",
       "11       0.796078        0.072411           90            53  0.683648   \n",
       "19       2.664632       -0.160827           48            10  0.906250   \n",
       "12       2.041698        0.427209           48            10  0.766667   \n",
       "13       2.041125        0.403061           48            10  0.777083   \n",
       "14       1.955373        0.455422           48            10  0.731250   \n",
       "15       2.033265        0.404918           48            10  0.783333   \n",
       "\n",
       "    Balanced_Accuracy  Precision    Recall        F1  TP  FP  FN  TN  \n",
       "16           0.825893   0.828829  0.821429  0.825112  92  19  20  93  \n",
       "0            0.687500   0.698113  0.660714  0.678899  74  32  38  80  \n",
       "1            0.691964   0.700935  0.669643  0.684932  75  32  37  80  \n",
       "2            0.678571   0.688679  0.651786  0.669725  73  33  39  79  \n",
       "3            0.669643   0.675926  0.651786  0.663636  73  35  39  77  \n",
       "17           0.828051   0.828829  0.828829  0.828829  92  19  19  91  \n",
       "4            0.746970   0.795699  0.666667  0.725490  74  19  37  91  \n",
       "5            0.728911   0.780220  0.639640  0.702970  71  20  40  90  \n",
       "6            0.728829   0.768421  0.657658  0.708738  73  22  38  88  \n",
       "7            0.719902   0.775281  0.621622  0.690000  69  20  42  90  \n",
       "18           0.819602   0.846939  0.922222  0.882979  83  15   7  38  \n",
       "8            0.595283   0.700000  0.700000  0.700000  63  27  27  26  \n",
       "9            0.610273   0.711111  0.711111  0.711111  64  26  26  27  \n",
       "10           0.615828   0.714286  0.722222  0.718232  65  26  25  27  \n",
       "11           0.600839   0.703297  0.711111  0.707182  64  27  26  26  \n",
       "19           0.829167   0.938776  0.958333  0.948454  46   3   2   7  \n",
       "12           0.500000   0.827586  1.000000  0.905660  48  10   0   0  \n",
       "13           0.500000   0.827586  1.000000  0.905660  48  10   0   0  \n",
       "14           0.500000   0.827586  1.000000  0.905660  48  10   0   0  \n",
       "15           0.500000   0.827586  1.000000  0.905660  48  10   0   0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_range_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7af22baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_range_summary.to_excel(f\"{base_loc}/token_results_summary_avg.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83aee7",
   "metadata": {},
   "source": [
    "## Test splitting into train and test splits for n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "1800e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_3_tokens_dataset = agg_token_dataset[agg_token_dataset['min_token_size'] == 3].copy()\n",
    "\n",
    "min_3_tokens_problems = min_3_tokens_dataset[['problem', 'target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "6b581941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose your DataFrame is called df and the column to predict is 'target'\n",
    "X = min_3_tokens_problems.drop(columns=['target'])\n",
    "y = min_3_tokens_problems['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.4,         # 20% test, change as needed\n",
    "    stratify=y,            # <- THIS ensures 'target' is evenly spread\n",
    "    random_state=42        # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "1de82995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = min_3_tokens_dataset.merge(X_train, on='problem', how='inner')\n",
    "test_df = min_3_tokens_dataset.merge(X_test, on='problem', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5eb81d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_summary_3, token_detailed_3 = performance(\n",
    "    df_train=train_df,\n",
    "    df_test=test_df,\n",
    "    keep_cols=[\"corpus\"],\n",
    "    score_col=\"llr_unknown\",\n",
    "    target_col=\"target\",\n",
    "    return_pred_rows=True,\n",
    "    id_cols=id_cols,\n",
    "    group_cols=[\"model\", \"min_token_size\"]\n",
    ")\n",
    "token_summary_3 = token_summary_3.sort_values(by=['min_token_size', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "22c37802",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_token_3_lambdag_train = lambdag_metrics.merge(X_train, on='problem', how='inner')\n",
    "min_token_3_lambdag_test = lambdag_metrics.merge(X_test, on='problem', how='inner')\n",
    "\n",
    "min_token_filtered_lambdag_sum, min_token_filtered_lambdag_detailed = performance(\n",
    "        df_train=min_token_3_lambdag_train,\n",
    "        df_test=min_token_3_lambdag_test,\n",
    "        score_col='llr_lambdaG',\n",
    "        target_col='y_true',\n",
    "        return_pred_rows=True,\n",
    "        id_cols=['problem', 'corpus', 'known_author', 'unknown_author'],\n",
    "        additional_metadata={\"model\": \"LambdaG\", \"min_token_size\": 3, \"corpus\": \"Wiki\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "494c5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_summary = pd.concat([min_token_filtered_lambdag_sum, token_summary_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "e6f5fc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>min_token_size</th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LambdaG</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.487462</td>\n",
       "      <td>0.487271</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>1.275918</td>\n",
       "      <td>-0.753135</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>0.938384</td>\n",
       "      <td>0.876768</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.685389</td>\n",
       "      <td>0.683557</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.709607</td>\n",
       "      <td>-0.380573</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>0.851515</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.679472</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.683920</td>\n",
       "      <td>-0.373504</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.720455</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.661979</td>\n",
       "      <td>0.661920</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.827357</td>\n",
       "      <td>-0.355007</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>0.864646</td>\n",
       "      <td>0.765404</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qwen</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>0.723914</td>\n",
       "      <td>0.721469</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>-0.333190</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>0.829798</td>\n",
       "      <td>0.709343</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  min_token_size corpus      Cllr  Cllr_min       EER  \\\n",
       "0  LambdaG               3   Wiki  0.487462  0.487271  0.113636   \n",
       "1    gemma               3   Wiki  0.685389  0.683557  0.272727   \n",
       "2     gpt2               3   Wiki  0.680496  0.679472  0.295455   \n",
       "3    llama               3   Wiki  0.661979  0.661920  0.204545   \n",
       "4     qwen               3   Wiki  0.723914  0.721469  0.318182   \n",
       "\n",
       "   Mean_TRUE_LLR  Mean_FALSE_LLR  TRUE_trials  FALSE_trials       AUC  \\\n",
       "0       1.275918       -0.753135           45            44  0.938384   \n",
       "1       0.709607       -0.380573           45            44  0.851515   \n",
       "2       0.683920       -0.373504           45            44  0.852525   \n",
       "3       0.827357       -0.355007           45            44  0.864646   \n",
       "4       0.512276       -0.333190           45            44  0.829798   \n",
       "\n",
       "   Balanced_Accuracy  Precision    Recall        F1  TP  FP  FN  TN  \n",
       "0           0.876768   0.904762  0.844444  0.873563  38   4   7  40  \n",
       "1           0.754545   0.870968  0.600000  0.710526  27   4  18  40  \n",
       "2           0.720455   0.794118  0.600000  0.683544  27   7  18  37  \n",
       "3           0.765404   0.852941  0.644444  0.734177  29   5  16  39  \n",
       "4           0.709343   0.787879  0.577778  0.666667  26   7  19  37  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "45c2c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_summary.to_excel(f\"{base_loc}/calibrated_token_results_summary_avg.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
