{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea448b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc82e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_excel(path=\"test_docs.xlsx\"):\n",
    "    \"\"\"\n",
    "    Create a tiny Excel workbook with sheets:\n",
    "      - docs\n",
    "      - known\n",
    "      - unknown\n",
    "      - no context\n",
    "      - metadata\n",
    "    Using phrase_num as string keys: 'phrase_1', 'phrase_2'\n",
    "    \"\"\"\n",
    "    # ---- sheet: docs ----\n",
    "    docs = pd.DataFrame({\n",
    "        \"doc_id\":[1],\n",
    "        \"title\":[\"Toy Example (string phrase ids)\"],\n",
    "        \"notes\":[\"Tiny dataset for LLR test with phrase_num='phrase_*'\"]\n",
    "    })\n",
    "\n",
    "    # ---- base table with string phrase IDs ----\n",
    "    rows = [\n",
    "        # phrase_1, occurrence 1\n",
    "        (\"phrase_1\", 1, \"I went to the shop\",   \"reference\",  0.40),\n",
    "        (\"phrase_1\", 1, \"I visited the shop\",   \"paraphrase\", 0.25),\n",
    "        (\"phrase_1\", 1, \"I walked to the shop\", \"paraphrase\", 0.20),\n",
    "        (\"phrase_1\", 1, \"I drove to the shop\",  \"paraphrase\", 0.15),\n",
    "\n",
    "        # phrase_2, occurrence 1\n",
    "        (\"phrase_2\", 1, \"He likes music\",       \"reference\",  0.60),\n",
    "        (\"phrase_2\", 1, \"He enjoys music\",      \"paraphrase\", 0.30),\n",
    "        (\"phrase_2\", 1, \"He loves music\",       \"paraphrase\", 0.10),\n",
    "    ]\n",
    "    cols = [\"phrase_num\",\"phrase_occurence\",\"original_phrase\",\"phrase_type\",\"raw_prob\"]\n",
    "    base = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    # ---- split into known / unknown / no context ----\n",
    "    known = base.copy()\n",
    "    unknown = base.copy()\n",
    "    noctx = base.copy()\n",
    "    metadata = pd.DataFrame({\"source\":[\"synthetic\"], \"comment\":[\"for pipeline test with string keys\"]})\n",
    "\n",
    "    # Slight tweaks so results differ across sheets\n",
    "    # (scale paraphrase probs a bit in unknown; scale all in no-context)\n",
    "    # For phrase_1, nudge paraphrases\n",
    "    mask1 = unknown[\"phrase_num\"].eq(\"phrase_1\")\n",
    "    # multiply paraphrase rows only\n",
    "    is_para = unknown[\"phrase_type\"].eq(\"paraphrase\")\n",
    "    unknown.loc[mask1 & is_para & unknown[\"original_phrase\"].str.contains(\"visited\"), \"raw_prob\"] *= 0.90\n",
    "    unknown.loc[mask1 & is_para & unknown[\"original_phrase\"].str.contains(\"walked\"),  \"raw_prob\"] *= 1.10\n",
    "    unknown.loc[mask1 & is_para & unknown[\"original_phrase\"].str.contains(\"drove\"),   \"raw_prob\"] *= 1.20\n",
    "\n",
    "    # Global downscale for no-context\n",
    "    noctx[\"raw_prob\"] = noctx[\"raw_prob\"] * 0.80\n",
    "\n",
    "    # (Optional) re-normalize per (phrase_num, phrase_occurence) block to keep sums ~1\n",
    "    def _renorm(df):\n",
    "        return df.assign(raw_prob=df[\"raw_prob\"] / df[\"raw_prob\"].sum())\n",
    "    known  = known.groupby([\"phrase_num\",\"phrase_occurence\"], group_keys=False).apply(_renorm)\n",
    "    unknown= unknown.groupby([\"phrase_num\",\"phrase_occurence\"], group_keys=False).apply(_renorm)\n",
    "    noctx  = noctx.groupby([\"phrase_num\",\"phrase_occurence\"], group_keys=False).apply(_renorm)\n",
    "\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as writer:\n",
    "        docs.to_excel(writer, index=False, sheet_name=\"docs\")\n",
    "        known.to_excel(writer, index=False, sheet_name=\"known\")\n",
    "        unknown.to_excel(writer, index=False, sheet_name=\"unknown\")\n",
    "        noctx.to_excel(writer, index=False, sheet_name=\"no context\")\n",
    "        metadata.to_excel(writer, index=False, sheet_name=\"metadata\")\n",
    "\n",
    "    print(f\"Created {Path(path).resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c20ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /Volumes/BCross/paraphrase examples slurm/Test blank doc.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-17>:56: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "<positron-console-cell-17>:57: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "<positron-console-cell-17>:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "make_test_excel('/Volumes/BCross/paraphrase examples slurm/Test blank doc.xlsx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
