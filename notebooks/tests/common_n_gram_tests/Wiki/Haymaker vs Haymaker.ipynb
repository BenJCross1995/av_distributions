{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32190cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e7b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../../../src'))\n",
    "\n",
    "from read_and_write_docs import read_jsonl, read_rds\n",
    "from tokenize_and_score import load_model\n",
    "from utils import apply_temp_doc_id, build_metadata_df\n",
    "from n_gram_functions import (\n",
    "    common_ngrams,\n",
    "    pretty_print_common_ngrams,\n",
    "    keep_before_phrase,\n",
    "    score_phrases,\n",
    "    add_pmf_column,\n",
    "    score_phrases_no_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0f4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"Wiki\"\n",
    "data_type = \"training\"\n",
    "\n",
    "known_loc = f\"/Volumes/BCross/datasets/author_verification/{data_type}/{corpus}/known_raw.jsonl\"\n",
    "known = read_jsonl(known_loc)\n",
    "known = apply_temp_doc_id(known)\n",
    "\n",
    "unknown_loc = f\"/Volumes/BCross/datasets/author_verification/{data_type}/{corpus}/unknown_raw.jsonl\"\n",
    "unknown = read_jsonl(unknown_loc)\n",
    "unknown_df = apply_temp_doc_id(unknown)\n",
    "\n",
    "metadata_loc = f\"/Volumes/BCross/datasets/author_verification/{data_type}/metadata.rds\"\n",
    "metadata = read_rds(metadata_loc)\n",
    "filtered_metadata = metadata[metadata['corpus'] == corpus]\n",
    "agg_metadata = build_metadata_df(filtered_metadata, known, unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a16b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dataset_agg = read_jsonl(\"/Users/user/Documents/test_data/n-gram_tracing/Wiki_training_agg.jsonl\")\n",
    "problem_dataset_profile = read_jsonl(\"/Users/user/Documents/test_data/n-gram_tracing/Wiki_training_profile.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fa9b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>highest_common_count</th>\n",
       "      <th>highest_common_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Greg_L vs Greg_L</td>\n",
       "      <td>Greg_L</td>\n",
       "      <td>Greg_L</td>\n",
       "      <td>greg_l_text_11</td>\n",
       "      <td>greg_l_text_10</td>\n",
       "      <td>9</td>\n",
       "      <td>, Ġthey Ġshould Ġhave Ġparticipated Ġin Ġthe Ġ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Haymaker vs Haymaker</td>\n",
       "      <td>Haymaker</td>\n",
       "      <td>Haymaker</td>\n",
       "      <td>haymaker_text_3</td>\n",
       "      <td>haymaker_text_2</td>\n",
       "      <td>9</td>\n",
       "      <td>Ġat Ġthe Ġend Ġof Ġthe Ġday , Ġwe 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Fragments_of_Jade vs Fragments_of_Jade</td>\n",
       "      <td>Fragments_of_Jade</td>\n",
       "      <td>Fragments_of_Jade</td>\n",
       "      <td>fragments_of_jade_text_2</td>\n",
       "      <td>fragments_of_jade_text_10</td>\n",
       "      <td>8</td>\n",
       "      <td>Ġme , Ġand Ġit 's Ġgetting Ġold .Ċ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Fixentries vs Fixentries</td>\n",
       "      <td>Fixentries</td>\n",
       "      <td>Fixentries</td>\n",
       "      <td>fixentries_text_2</td>\n",
       "      <td>fixentries_text_5</td>\n",
       "      <td>8</td>\n",
       "      <td>Ġthe Ġindividual Ġher it ability Ġof Ġintellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>DonaNobisPacem vs DonaNobisPacem</td>\n",
       "      <td>DonaNobisPacem</td>\n",
       "      <td>DonaNobisPacem</td>\n",
       "      <td>donanobispacem_text_5</td>\n",
       "      <td>donanobispacem_text_2</td>\n",
       "      <td>8</td>\n",
       "      <td>Ġafter Ġ 1 8 - 2 0 Ġweeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>David_Shankbone vs David_Shankbone</td>\n",
       "      <td>David_Shankbone</td>\n",
       "      <td>David_Shankbone</td>\n",
       "      <td>david_shankbone_text_1</td>\n",
       "      <td>david_shankbone_text_4</td>\n",
       "      <td>3</td>\n",
       "      <td>, Ġwhich Ġis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>D7G1DX~0 vs D7G1DX~0</td>\n",
       "      <td>D7G1DX~0</td>\n",
       "      <td>D7G1DX~0</td>\n",
       "      <td>d7g1dx_0_text_2</td>\n",
       "      <td>d7g1dx_0_text_5</td>\n",
       "      <td>3</td>\n",
       "      <td>Ġdon 't Ġthink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Collect vs Collect</td>\n",
       "      <td>Collect</td>\n",
       "      <td>Collect</td>\n",
       "      <td>collect_text_12</td>\n",
       "      <td>collect_text_11</td>\n",
       "      <td>3</td>\n",
       "      <td>, Ġand Ġi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Cptnono vs Cptnono</td>\n",
       "      <td>Cptnono</td>\n",
       "      <td>Cptnono</td>\n",
       "      <td>cptnono_text_1</td>\n",
       "      <td>cptnono_text_12</td>\n",
       "      <td>3</td>\n",
       "      <td>, Ġthough .Ċ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Danlaycock vs Danlaycock</td>\n",
       "      <td>Danlaycock</td>\n",
       "      <td>Danlaycock</td>\n",
       "      <td>danlaycock_text_5</td>\n",
       "      <td>danlaycock_text_2</td>\n",
       "      <td>3</td>\n",
       "      <td>.Ċ also ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    problem       known_author  \\\n",
       "379                        Greg_L vs Greg_L             Greg_L   \n",
       "432                    Haymaker vs Haymaker           Haymaker   \n",
       "354  Fragments_of_Jade vs Fragments_of_Jade  Fragments_of_Jade   \n",
       "337                Fixentries vs Fixentries         Fixentries   \n",
       "248        DonaNobisPacem vs DonaNobisPacem     DonaNobisPacem   \n",
       "..                                      ...                ...   \n",
       "222      David_Shankbone vs David_Shankbone    David_Shankbone   \n",
       "211                    D7G1DX~0 vs D7G1DX~0           D7G1DX~0   \n",
       "187                      Collect vs Collect            Collect   \n",
       "198                      Cptnono vs Cptnono            Cptnono   \n",
       "218                Danlaycock vs Danlaycock         Danlaycock   \n",
       "\n",
       "        unknown_author              known_doc_id             unknown_doc_id  \\\n",
       "379             Greg_L            greg_l_text_11             greg_l_text_10   \n",
       "432           Haymaker           haymaker_text_3            haymaker_text_2   \n",
       "354  Fragments_of_Jade  fragments_of_jade_text_2  fragments_of_jade_text_10   \n",
       "337         Fixentries         fixentries_text_2          fixentries_text_5   \n",
       "248     DonaNobisPacem     donanobispacem_text_5      donanobispacem_text_2   \n",
       "..                 ...                       ...                        ...   \n",
       "222    David_Shankbone    david_shankbone_text_1     david_shankbone_text_4   \n",
       "211           D7G1DX~0           d7g1dx_0_text_2            d7g1dx_0_text_5   \n",
       "187            Collect           collect_text_12            collect_text_11   \n",
       "198            Cptnono            cptnono_text_1            cptnono_text_12   \n",
       "218         Danlaycock         danlaycock_text_5          danlaycock_text_2   \n",
       "\n",
       "     highest_common_count                               highest_common_ngram  \n",
       "379                     9  , Ġthey Ġshould Ġhave Ġparticipated Ġin Ġthe Ġ...  \n",
       "432                     9              Ġat Ġthe Ġend Ġof Ġthe Ġday , Ġwe 're  \n",
       "354                     8                 Ġme , Ġand Ġit 's Ġgetting Ġold .Ċ  \n",
       "337                     8  Ġthe Ġindividual Ġher it ability Ġof Ġintellig...  \n",
       "248                     8                          Ġafter Ġ 1 8 - 2 0 Ġweeks  \n",
       "..                    ...                                                ...  \n",
       "222                     3                                       , Ġwhich Ġis  \n",
       "211                     3                                     Ġdon 't Ġthink  \n",
       "187                     3                                          , Ġand Ġi  \n",
       "198                     3                                       , Ġthough .Ċ  \n",
       "218                     3                                          .Ċ also ,  \n",
       "\n",
       "[197 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_author_problems = problem_dataset_agg[problem_dataset_agg['known_author'] == problem_dataset_agg['unknown_author']].copy()\n",
    "same_author_problems.sort_values([\"highest_common_count\"], ascending=[False], inplace=True)\n",
    "same_author_problems[(same_author_problems['highest_common_count'] >= 3) & (same_author_problems['highest_common_count'] <= 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6993e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_doc = \"haymaker_text_3\"\n",
    "known_text = known[known['doc_id'] == known_doc].reset_index().loc[0, 'text']\n",
    "\n",
    "unknown_doc = \"haymaker_text_2\"\n",
    "unknown_text = unknown[unknown['doc_id'] == unknown_doc].reset_index().loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be309b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See, I can play that game to, consensus is solid against the category you want.\n",
      "Does anyone know if there is precedent with regard to this?\n",
      "Remember that you're the one trying to impact consensus in this instance so the onus is on you. - Perhaps it has shifted to include non-official organizations that are inline with Rome?\n",
      "Also, try not to put things in quotes that are not quotes in the future.\n",
      "The CL is more than adequate for a statement on what the CL believes.\n",
      "The pro-choice article's name is also strange and, in American terms, certainly fails to adequately the pro-choice cause.\n",
      "I will leave it to persons with a better perspective on that side of the aisle to find the most fitting term.\n",
      "I think the current text does a decent job of informing the reader of the stats that the sources provide.\n",
      "I don't think we should present it as fact.\n",
      "I'm under the impression that this was pretty taboo in the 40s.\n",
      "Do we have sources that definitively examine this aspect of the event?\n",
      "I think Poland is worthwhile as it was in many ways the same phenomenon by the same perpetrators\n",
      "I did not aim to move the French/American sections to the bottom, but rather to keep the Soviet information together.\n",
      "I think that at the end of the day, we're talking about two very different phenomenons, none of the literature I have read has examined rape in the east and the west, it has been one or the other.\n",
      "With that shake up in mind, it does look like many of these sections could be condensed.\n",
      "Per the removal, there is myself, Biophys, TFD and AM in favor of removal.\n",
      "While less than unshakable, I felt that was strong enough to move forward.\n",
      "If a reader wants to keep some sort of a score card let him do it on his own time.\n",
      "No mention of Japanese crimes in article documenting American war crimes though the same emotions were no doubt at play.\n",
      "I am reluctant to accept Russian language sources only because I don't speak Russian and have no way to assess whether or not said sources are reliable.\n",
      "Surely there must be some solid Russian sources which have been translated? -\n",
      "Agreed, I am surprised it took him this long to get indeffed.\n",
      "It looks more and more like there are two codes of conduct.\n",
      "I never knew that this had moved onto the evidence and later proposed decision sections until I looked one day for the first time and saw that I was going to be sanctioned.\n",
      "If I had been made aware of how far this would have progressed I would have been active in the evidence section not only sharing diffs and commenting on other users actions but also in working to explain mine.\n",
      "I generally agree with Kenatipo, this feels more like justice half done than justice miscarried.\n"
     ]
    }
   ],
   "source": [
    "print(unknown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097eadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model(\"/Volumes/BCross/models/Qwen 2.5/Qwen2.5-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72faabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = common_ngrams(known_text, unknown_text, 2, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1787f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams (25): ['\\ni', ' and the', ' are two', ' for a', ' for the', ' i have', ' in the', ' it was', ' more than', ' not to', ' that i', ' that you', ' the east', ' the same', ' this was', ' to put', ' trying to', ' we have', ', but', ', i', ', there', '.\\ni', '.\\nit', 'also,', \"i'm\"]\n",
      "4-grams (2): [' i would have been', ' some sort of a']\n",
      "9-grams (1): [\" at the end of the day, we're\"]\n"
     ]
    }
   ],
   "source": [
    "pretty_print_common_ngrams(common, tokenizer=tokenizer, order='len_asc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb60015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<DOC>\n",
      "Even if you choose not to have any faith in the editors under sanction at least have some in the scores of admins watching these articles.\n",
      "Thanks for the heads up on the discussion, I will apply that metric to a few other conversations and will return if I have any other questions.\n",
      "Also, is it kosher for me to continue my participation in discussion on the NPOV board ?\n",
      "Since I didn't really see this hammered out previously I would like to see both users review this after 6 months, continue it if both parties agree and set a date for another review point at that first review.\n",
      "I would love nothing more than to walk away, God knows this takes up a fair bit of time\n",
      "I'm still holding out hope for a i-ban on my end.\n",
      "You said your blog is reachable through google\n",
      "And I would have been more than happy to have the conversation in private\n",
      "I'm trying to put a reasonable deal on the table that puts neither of us at a disadvantage and has us both editing productively again.\n",
      "So what do you think? - Are you denying that you posted immediately above that your blog was reachable through google?\n",
      "Tell you what, I tire of the dance we've been doing low these many months.\n",
      "How about for the next 90 days we both agree to walk away from all non-administrative pages we have mutually edited\n",
      "Just before you protected it a vandal hit it, could you revert that?\n",
      "Even if you disliked the source that mentioned Soros in it\n",
      "Did you even read the page before you hit undo?\n",
      "Ros and I are two different heads, but at the end of the day, we're on the same coin.\n",
      "Hopefully we're headed toward an agreement that will have us contributing productively to our areas of expertise.\n",
      "My biggest concern is Ros will initiate changes to terminology across swaths of pages that only really her and I edit and that I won't be able to contest them.\n",
      "I'd like some sort of a clause that Ros will not alter terms on these articles and she can certainly ask the same of me.\n",
      "I'd also like to tone the initial 1 year installment down to 3 months.\n",
      "I this was the only scenario that I envisioned that didn't end with both of s blocked.\n",
      "It was late at night on the east coast, there was a 2 and a half hour lag in between the time I requested protection and the time it was granted.\n",
      "</DOC>\n",
      "<NGRAM>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "<DOC>\n",
    "{known_text}\n",
    "</DOC>\n",
    "<NGRAM>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98c4cd",
   "metadata": {},
   "source": [
    "## Phrase 1 -  \" at the end of the day, we're\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d334e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = \" at the end of the day, we're\"\n",
    "\n",
    "para_1 = [\" at the end of the day, we are\", \" at the end of the day, we’re\", \" we're, at the end of the day\", \" we are, at the end of the day\", \" at the end of the day we're\", \" at the end of the day we are\", \" at the end of the day — we're\", \" at the end of the day — we are\", \" we're at the end of the day\", \" we are at the end of the day\", \" we’re, at the end of the day\", \" we’re at the end of the day\"]\n",
    "\n",
    "known_base_p1 = keep_before_phrase(known_text, p_1, True)\n",
    "unknown_base_p1 = keep_before_phrase(unknown_text, p_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f416098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Scoring base_text alone…\n",
      "   base_total = -1304.8726\n",
      "\n",
      "→ [1/13] Processing reference…\n",
      "→ [2/13] Processing paraphrase…\n",
      "→ [3/13] Processing paraphrase…\n",
      "→ [4/13] Processing paraphrase…\n",
      "→ [5/13] Processing paraphrase…\n",
      "→ [6/13] Processing paraphrase…\n",
      "→ [7/13] Processing paraphrase…\n",
      "→ [8/13] Processing paraphrase…\n",
      "→ [9/13] Processing paraphrase…\n",
      "→ [10/13] Processing paraphrase…\n",
      "→ [11/13] Processing paraphrase…\n",
      "→ [12/13] Processing paraphrase…\n",
      "→ [13/13] Processing paraphrase…\n",
      "→ Scoring base_text alone…\n",
      "   base_total = -1009.3887\n",
      "\n",
      "→ [1/13] Processing reference…\n",
      "→ [2/13] Processing paraphrase…\n",
      "→ [3/13] Processing paraphrase…\n",
      "→ [4/13] Processing paraphrase…\n",
      "→ [5/13] Processing paraphrase…\n",
      "→ [6/13] Processing paraphrase…\n",
      "→ [7/13] Processing paraphrase…\n",
      "→ [8/13] Processing paraphrase…\n",
      "→ [9/13] Processing paraphrase…\n",
      "→ [10/13] Processing paraphrase…\n",
      "→ [11/13] Processing paraphrase…\n",
      "→ [12/13] Processing paraphrase…\n",
      "→ [13/13] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "known_p1_scores = score_phrases(known_base_p1, p_1, para_1, tokenizer, model)\n",
    "unknown_p1_scores = score_phrases(unknown_base_p1, p_1, para_1, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f766da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p1_pmf = add_pmf_column(known_p1_scores, 'phrase_log_probs')\n",
    "unknown_p1_pmf = add_pmf_column(unknown_p1_scores, 'phrase_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47b77e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ [1/13] Processing reference…\n",
      "→ [2/13] Processing paraphrase…\n",
      "→ [3/13] Processing paraphrase…\n",
      "→ [4/13] Processing paraphrase…\n",
      "→ [5/13] Processing paraphrase…\n",
      "→ [6/13] Processing paraphrase…\n",
      "→ [7/13] Processing paraphrase…\n",
      "→ [8/13] Processing paraphrase…\n",
      "→ [9/13] Processing paraphrase…\n",
      "→ [10/13] Processing paraphrase…\n",
      "→ [11/13] Processing paraphrase…\n",
      "→ [12/13] Processing paraphrase…\n",
      "→ [13/13] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "p1_pmf = score_phrases_no_context(p_1, para_1, tokenizer, model)\n",
    "p1_pmf = add_pmf_column(p1_pmf, 'log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3fe876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_p1_pmf.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a7ca6",
   "metadata": {},
   "source": [
    "## Phrase 2 - \" some sort of a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505c5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2 = \" some sort of a\"\n",
    "\n",
    "para_2 = [\" some sort of an\", \" some kind of a\", \" some kind of an\", \" some type of a\", \" some type of an\", \" some sort-of a\", \" some sort-of an\", \" some kind-of a\", \" some kind-of an\", \" some type-of a\", \" some type-of an\", \" some sorta a\", \" some sorta an\", \" some kinda a\", \" some kinda an\", \" some sort o' a\", \" some sort o' an\", \" some kind o' a\", \" some kind o' an\", \" some type o' a\", \" some type o' an\"]\n",
    "\n",
    "known_base_p2 = keep_before_phrase(known_text, p_2, True)\n",
    "unknown_base_p2 = keep_before_phrase(unknown_text, p_2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce353bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Scoring base_text alone…\n",
      "   base_total = -1543.6439\n",
      "\n",
      "→ [1/22] Processing reference…\n",
      "→ [2/22] Processing paraphrase…\n",
      "→ [3/22] Processing paraphrase…\n",
      "→ [4/22] Processing paraphrase…\n",
      "→ [5/22] Processing paraphrase…\n",
      "→ [6/22] Processing paraphrase…\n",
      "→ [7/22] Processing paraphrase…\n",
      "→ [8/22] Processing paraphrase…\n",
      "→ [9/22] Processing paraphrase…\n",
      "→ [10/22] Processing paraphrase…\n",
      "→ [11/22] Processing paraphrase…\n",
      "→ [12/22] Processing paraphrase…\n",
      "→ [13/22] Processing paraphrase…\n",
      "→ [14/22] Processing paraphrase…\n",
      "→ [15/22] Processing paraphrase…\n",
      "→ [16/22] Processing paraphrase…\n",
      "→ [17/22] Processing paraphrase…\n",
      "→ [18/22] Processing paraphrase…\n",
      "→ [19/22] Processing paraphrase…\n",
      "→ [20/22] Processing paraphrase…\n",
      "→ [21/22] Processing paraphrase…\n",
      "→ [22/22] Processing paraphrase…\n",
      "→ Scoring base_text alone…\n",
      "   base_total = -1383.7818\n",
      "\n",
      "→ [1/22] Processing reference…\n",
      "→ [2/22] Processing paraphrase…\n",
      "→ [3/22] Processing paraphrase…\n",
      "→ [4/22] Processing paraphrase…\n",
      "→ [5/22] Processing paraphrase…\n",
      "→ [6/22] Processing paraphrase…\n",
      "→ [7/22] Processing paraphrase…\n",
      "→ [8/22] Processing paraphrase…\n",
      "→ [9/22] Processing paraphrase…\n",
      "→ [10/22] Processing paraphrase…\n",
      "→ [11/22] Processing paraphrase…\n",
      "→ [12/22] Processing paraphrase…\n",
      "→ [13/22] Processing paraphrase…\n",
      "→ [14/22] Processing paraphrase…\n",
      "→ [15/22] Processing paraphrase…\n",
      "→ [16/22] Processing paraphrase…\n",
      "→ [17/22] Processing paraphrase…\n",
      "→ [18/22] Processing paraphrase…\n",
      "→ [19/22] Processing paraphrase…\n",
      "→ [20/22] Processing paraphrase…\n",
      "→ [21/22] Processing paraphrase…\n",
      "→ [22/22] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "known_p2_scores = score_phrases(known_base_p2, p_2, para_2, tokenizer, model)\n",
    "unknown_p2_scores = score_phrases(unknown_base_p2, p_2, para_2, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45ef214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p2_pmf = add_pmf_column(known_p2_scores, 'phrase_log_probs')\n",
    "unknown_p2_pmf = add_pmf_column(unknown_p2_scores, 'phrase_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bfab2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ [1/22] Processing reference…\n",
      "→ [2/22] Processing paraphrase…\n",
      "→ [3/22] Processing paraphrase…\n",
      "→ [4/22] Processing paraphrase…\n",
      "→ [5/22] Processing paraphrase…\n",
      "→ [6/22] Processing paraphrase…\n",
      "→ [7/22] Processing paraphrase…\n",
      "→ [8/22] Processing paraphrase…\n",
      "→ [9/22] Processing paraphrase…\n",
      "→ [10/22] Processing paraphrase…\n",
      "→ [11/22] Processing paraphrase…\n",
      "→ [12/22] Processing paraphrase…\n",
      "→ [13/22] Processing paraphrase…\n",
      "→ [14/22] Processing paraphrase…\n",
      "→ [15/22] Processing paraphrase…\n",
      "→ [16/22] Processing paraphrase…\n",
      "→ [17/22] Processing paraphrase…\n",
      "→ [18/22] Processing paraphrase…\n",
      "→ [19/22] Processing paraphrase…\n",
      "→ [20/22] Processing paraphrase…\n",
      "→ [21/22] Processing paraphrase…\n",
      "→ [22/22] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "p2_pmf = score_phrases_no_context(p_2, para_2, tokenizer, model)\n",
    "p2_pmf = add_pmf_column(p2_pmf, 'log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f7c16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_p2_pmf.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114498eb",
   "metadata": {},
   "source": [
    "## Phrase 3 - \" i would have been\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3036ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_3 = \" i would have been\"\n",
    "\n",
    "para_3 = [\" i would've been\", \" i would’ve been\", \" i wouldve been\", \" i'd have been\", \" i’d have been\", \" i'd've been\", \" i’d’ve been\", \" i'd of been\", \" i’d of been\", \" i would of been\", \" i'da been\", \" i’da been\", \" i woulda been\", \" I would have been\", \" I would've been\", \" I would’ve been\", \" I'd have been\", \" I’d have been\", \" I'd've been\", \" I’d’ve been\", \" I'd of been\", \" I’d of been\", \" I would of been\", \" I'da been\", \" I’da been\", \" I woulda been\"]\n",
    "\n",
    "known_base_p3 = keep_before_phrase(known_text, p_3, True)\n",
    "unknown_base_p3 = keep_before_phrase(unknown_text, p_3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9297ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Scoring base_text alone…\n",
      "   base_total = -681.1740\n",
      "\n",
      "→ [1/27] Processing reference…\n",
      "→ [2/27] Processing paraphrase…\n",
      "→ [3/27] Processing paraphrase…\n",
      "→ [4/27] Processing paraphrase…\n",
      "→ [5/27] Processing paraphrase…\n",
      "→ [6/27] Processing paraphrase…\n",
      "→ [7/27] Processing paraphrase…\n",
      "→ [8/27] Processing paraphrase…\n",
      "→ [9/27] Processing paraphrase…\n",
      "→ [10/27] Processing paraphrase…\n",
      "→ [11/27] Processing paraphrase…\n",
      "→ [12/27] Processing paraphrase…\n",
      "→ [13/27] Processing paraphrase…\n",
      "→ [14/27] Processing paraphrase…\n",
      "→ [15/27] Processing paraphrase…\n",
      "→ [16/27] Processing paraphrase…\n",
      "→ [17/27] Processing paraphrase…\n",
      "→ [18/27] Processing paraphrase…\n",
      "→ [19/27] Processing paraphrase…\n",
      "→ [20/27] Processing paraphrase…\n",
      "→ [21/27] Processing paraphrase…\n",
      "→ [22/27] Processing paraphrase…\n",
      "→ [23/27] Processing paraphrase…\n",
      "→ [24/27] Processing paraphrase…\n",
      "→ [25/27] Processing paraphrase…\n",
      "→ [26/27] Processing paraphrase…\n",
      "→ [27/27] Processing paraphrase…\n",
      "→ Scoring base_text alone…\n",
      "   base_total = -1999.1501\n",
      "\n",
      "→ [1/27] Processing reference…\n",
      "→ [2/27] Processing paraphrase…\n",
      "→ [3/27] Processing paraphrase…\n",
      "→ [4/27] Processing paraphrase…\n",
      "→ [5/27] Processing paraphrase…\n",
      "→ [6/27] Processing paraphrase…\n",
      "→ [7/27] Processing paraphrase…\n",
      "→ [8/27] Processing paraphrase…\n",
      "→ [9/27] Processing paraphrase…\n",
      "→ [10/27] Processing paraphrase…\n",
      "→ [11/27] Processing paraphrase…\n",
      "→ [12/27] Processing paraphrase…\n",
      "→ [13/27] Processing paraphrase…\n",
      "→ [14/27] Processing paraphrase…\n",
      "→ [15/27] Processing paraphrase…\n",
      "→ [16/27] Processing paraphrase…\n",
      "→ [17/27] Processing paraphrase…\n",
      "→ [18/27] Processing paraphrase…\n",
      "→ [19/27] Processing paraphrase…\n",
      "→ [20/27] Processing paraphrase…\n",
      "→ [21/27] Processing paraphrase…\n",
      "→ [22/27] Processing paraphrase…\n",
      "→ [23/27] Processing paraphrase…\n",
      "→ [24/27] Processing paraphrase…\n",
      "→ [25/27] Processing paraphrase…\n",
      "→ [26/27] Processing paraphrase…\n",
      "→ [27/27] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "known_p3_scores = score_phrases(known_base_p3, p_3, para_3, tokenizer, model)\n",
    "unknown_p3_scores = score_phrases(unknown_base_p3, p_3, para_3, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a17413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p3_pmf = add_pmf_column(known_p3_scores, 'phrase_log_probs')\n",
    "unknown_p3_pmf = add_pmf_column(unknown_p3_scores, 'phrase_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1541e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ [1/27] Processing reference…\n",
      "→ [2/27] Processing paraphrase…\n",
      "→ [3/27] Processing paraphrase…\n",
      "→ [4/27] Processing paraphrase…\n",
      "→ [5/27] Processing paraphrase…\n",
      "→ [6/27] Processing paraphrase…\n",
      "→ [7/27] Processing paraphrase…\n",
      "→ [8/27] Processing paraphrase…\n",
      "→ [9/27] Processing paraphrase…\n",
      "→ [10/27] Processing paraphrase…\n",
      "→ [11/27] Processing paraphrase…\n",
      "→ [12/27] Processing paraphrase…\n",
      "→ [13/27] Processing paraphrase…\n",
      "→ [14/27] Processing paraphrase…\n",
      "→ [15/27] Processing paraphrase…\n",
      "→ [16/27] Processing paraphrase…\n",
      "→ [17/27] Processing paraphrase…\n",
      "→ [18/27] Processing paraphrase…\n",
      "→ [19/27] Processing paraphrase…\n",
      "→ [20/27] Processing paraphrase…\n",
      "→ [21/27] Processing paraphrase…\n",
      "→ [22/27] Processing paraphrase…\n",
      "→ [23/27] Processing paraphrase…\n",
      "→ [24/27] Processing paraphrase…\n",
      "→ [25/27] Processing paraphrase…\n",
      "→ [26/27] Processing paraphrase…\n",
      "→ [27/27] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "p3_pmf = score_phrases_no_context(p_3, para_3, tokenizer, model)\n",
    "p3_pmf = add_pmf_column(p3_pmf, 'log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7fad9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_p3_pmf.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
