{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32190cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e7b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../../../src'))\n",
    "\n",
    "from read_and_write_docs import read_jsonl, read_rds\n",
    "from tokenize_and_score import load_model\n",
    "from utils import apply_temp_doc_id, build_metadata_df\n",
    "from n_gram_functions import (\n",
    "    common_ngrams,\n",
    "    pretty_print_common_ngrams,\n",
    "    keep_before_phrase,\n",
    "    score_phrases,\n",
    "    add_pmf_column,\n",
    "    score_phrases_no_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097eadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model(\"/Volumes/BCross/models/Qwen 2.5/Qwen2.5-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0f4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"Wiki\"\n",
    "data_type = \"training\"\n",
    "\n",
    "known_loc = f\"/Volumes/BCross/datasets/author_verification/{data_type}/{corpus}/known_raw.jsonl\"\n",
    "known = read_jsonl(known_loc)\n",
    "known = apply_temp_doc_id(known)\n",
    "\n",
    "unknown_loc = f\"/Volumes/BCross/datasets/author_verification/{data_type}/{corpus}/unknown_raw.jsonl\"\n",
    "unknown = read_jsonl(unknown_loc)\n",
    "unknown_df = apply_temp_doc_id(unknown)\n",
    "\n",
    "metadata_loc = f\"/Volumes/BCross/datasets/author_verification/{data_type}/metadata.rds\"\n",
    "metadata = read_rds(metadata_loc)\n",
    "filtered_metadata = metadata[metadata['corpus'] == corpus]\n",
    "agg_metadata = build_metadata_df(filtered_metadata, known, unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dataset_agg = read_jsonl(\"/Users/user/Documents/test_data/n-gram_tracing/Wiki_training_agg.jsonl\")\n",
    "problem_dataset_profile = read_jsonl(\"/Users/user/Documents/test_data/n-gram_tracing/Wiki_training_profile.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fa9b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>known_doc_id</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>highest_common_count</th>\n",
       "      <th>highest_common_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Enemesis vs Equanimous1</td>\n",
       "      <td>Enemesis</td>\n",
       "      <td>Equanimous1</td>\n",
       "      <td>enemesis_text_3</td>\n",
       "      <td>equanimous1_text_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Ġthe Ġcurrent Ġstate Ġof Ġthe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Caboga vs Chanakyathegreat</td>\n",
       "      <td>Caboga</td>\n",
       "      <td>Chanakyathegreat</td>\n",
       "      <td>caboga_text_5</td>\n",
       "      <td>chanakyathegreat_text_1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ġ 2 0 0 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Dweller vs Ecelan</td>\n",
       "      <td>Dweller</td>\n",
       "      <td>Ecelan</td>\n",
       "      <td>dweller_text_3</td>\n",
       "      <td>ecelan_text_2</td>\n",
       "      <td>5</td>\n",
       "      <td>.Ċ i Ġdon 't Ġthink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Fyunck(click) vs Garda40</td>\n",
       "      <td>Fyunck(click)</td>\n",
       "      <td>Garda40</td>\n",
       "      <td>fyunck_click_text_12</td>\n",
       "      <td>garda40_text_1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ġ 2 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Fyunck(click) vs Garda40</td>\n",
       "      <td>Fyunck(click)</td>\n",
       "      <td>Garda40</td>\n",
       "      <td>fyunck_click_text_2</td>\n",
       "      <td>garda40_text_1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ġ 2 0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Gwen_Gale vs Habap</td>\n",
       "      <td>Gwen_Gale</td>\n",
       "      <td>Habap</td>\n",
       "      <td>gwen_gale_text_3</td>\n",
       "      <td>habap_text_1</td>\n",
       "      <td>5</td>\n",
       "      <td>, Ġbut Ġi Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Enemesis vs Equanimous1</td>\n",
       "      <td>Enemesis</td>\n",
       "      <td>Equanimous1</td>\n",
       "      <td>enemesis_text_2</td>\n",
       "      <td>equanimous1_text_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Ġthe Ġcurrent Ġstate Ġof Ġthe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>HeadleyDown vs Hipocrite</td>\n",
       "      <td>HeadleyDown</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>headleydown_text_2</td>\n",
       "      <td>hipocrite_text_4</td>\n",
       "      <td>5</td>\n",
       "      <td>Ġon Ġthis Ġtalk Ġpage .Ċ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Britmax vs BrotherDarksoul</td>\n",
       "      <td>Britmax</td>\n",
       "      <td>BrotherDarksoul</td>\n",
       "      <td>britmax_text_1</td>\n",
       "      <td>brotherdarksoul_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġis Ġno Ġneed Ġto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Chanakyathegreat vs Cla68</td>\n",
       "      <td>Chanakyathegreat</td>\n",
       "      <td>Cla68</td>\n",
       "      <td>chanakyathegreat_text_10</td>\n",
       "      <td>cla68_text_1</td>\n",
       "      <td>4</td>\n",
       "      <td>, Ġi Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Cla68 vs Classicjupiter2</td>\n",
       "      <td>Cla68</td>\n",
       "      <td>Classicjupiter2</td>\n",
       "      <td>cla68_text_2</td>\n",
       "      <td>classicjupiter2_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>i Ġjust Ġwanted Ġto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Ecelan vs EdJohnston</td>\n",
       "      <td>Ecelan</td>\n",
       "      <td>EdJohnston</td>\n",
       "      <td>ecelan_text_1</td>\n",
       "      <td>edjohnston_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Bigdaddy1981 vs Bjenks</td>\n",
       "      <td>Bigdaddy1981</td>\n",
       "      <td>Bjenks</td>\n",
       "      <td>bigdaddy1981_text_3</td>\n",
       "      <td>bjenks_text_2</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġ 1 9 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Cptnono vs CyberAnth</td>\n",
       "      <td>Cptnono</td>\n",
       "      <td>CyberAnth</td>\n",
       "      <td>cptnono_text_10</td>\n",
       "      <td>cyberanth_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġto Ġfix Ġit .Ċ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Danlaycock vs David_Shankbone</td>\n",
       "      <td>Danlaycock</td>\n",
       "      <td>David_Shankbone</td>\n",
       "      <td>danlaycock_text_5</td>\n",
       "      <td>david_shankbone_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Delicious_carbuncle vs Dennis_Brown</td>\n",
       "      <td>Delicious_carbuncle</td>\n",
       "      <td>Dennis_Brown</td>\n",
       "      <td>delicious_carbuncle_text_3</td>\n",
       "      <td>dennis_brown_text_11</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>DonaNobisPacem vs Dricherby</td>\n",
       "      <td>DonaNobisPacem</td>\n",
       "      <td>Dricherby</td>\n",
       "      <td>donanobispacem_text_4</td>\n",
       "      <td>dricherby_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġand Ġit Ġdoesn 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Dricherby vs Dweller</td>\n",
       "      <td>Dricherby</td>\n",
       "      <td>Dweller</td>\n",
       "      <td>dricherby_text_1</td>\n",
       "      <td>dweller_text_2</td>\n",
       "      <td>4</td>\n",
       "      <td>i Ġdon 't Ġknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Dricherby vs Dweller</td>\n",
       "      <td>Dricherby</td>\n",
       "      <td>Dweller</td>\n",
       "      <td>dricherby_text_5</td>\n",
       "      <td>dweller_text_2</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġbut Ġi Ġdidn 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Bfigura vs Bielle</td>\n",
       "      <td>Bfigura</td>\n",
       "      <td>Bielle</td>\n",
       "      <td>bfigura_text_3</td>\n",
       "      <td>bielle_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>'d Ġlike Ġto Ġsee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Cla68 vs Classicjupiter2</td>\n",
       "      <td>Cla68</td>\n",
       "      <td>Classicjupiter2</td>\n",
       "      <td>cla68_text_4</td>\n",
       "      <td>classicjupiter2_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>, Ġin Ġorder Ġto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>David_Shankbone vs Delicious_carbuncle</td>\n",
       "      <td>David_Shankbone</td>\n",
       "      <td>Delicious_carbuncle</td>\n",
       "      <td>david_shankbone_text_2</td>\n",
       "      <td>delicious_carbuncle_text_1</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i 'm Ġnot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Ecelan vs EdJohnston</td>\n",
       "      <td>Ecelan</td>\n",
       "      <td>EdJohnston</td>\n",
       "      <td>ecelan_text_5</td>\n",
       "      <td>edjohnston_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Atama vs Athenean</td>\n",
       "      <td>Atama</td>\n",
       "      <td>Athenean</td>\n",
       "      <td>atama_text_4</td>\n",
       "      <td>athenean_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ also , Ġi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Essjay vs Exploding_Boy</td>\n",
       "      <td>Essjay</td>\n",
       "      <td>Exploding_Boy</td>\n",
       "      <td>essjay_text_4</td>\n",
       "      <td>exploding_boy_text_3</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Falcon9x5 vs Fipplet</td>\n",
       "      <td>Falcon9x5</td>\n",
       "      <td>Fipplet</td>\n",
       "      <td>falcon9x5_text_3</td>\n",
       "      <td>fipplet_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Fipplet vs Fixentries</td>\n",
       "      <td>Fipplet</td>\n",
       "      <td>Fixentries</td>\n",
       "      <td>fipplet_text_2</td>\n",
       "      <td>fixentries_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdidn 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Floquenbeam vs Fragments_of_Jade</td>\n",
       "      <td>Floquenbeam</td>\n",
       "      <td>Fragments_of_Jade</td>\n",
       "      <td>floquenbeam_text_1</td>\n",
       "      <td>fragments_of_jade_text_10</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġwith Ġyou , Ġand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Floquenbeam vs Fragments_of_Jade</td>\n",
       "      <td>Floquenbeam</td>\n",
       "      <td>Fragments_of_Jade</td>\n",
       "      <td>floquenbeam_text_4</td>\n",
       "      <td>fragments_of_jade_text_10</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġasked Ġyou Ġto Ġstop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Fyunck(click) vs Garda40</td>\n",
       "      <td>Fyunck(click)</td>\n",
       "      <td>Garda40</td>\n",
       "      <td>fyunck_click_text_10</td>\n",
       "      <td>garda40_text_1</td>\n",
       "      <td>4</td>\n",
       "      <td>i 'm Ġnot Ġsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Garda40 vs George</td>\n",
       "      <td>Garda40</td>\n",
       "      <td>George</td>\n",
       "      <td>garda40_text_2</td>\n",
       "      <td>george_text_13</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġat Ġthe Ġend Ġof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Garda40 vs George</td>\n",
       "      <td>Garda40</td>\n",
       "      <td>George</td>\n",
       "      <td>garda40_text_3</td>\n",
       "      <td>george_text_13</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Garda40 vs George</td>\n",
       "      <td>Garda40</td>\n",
       "      <td>George</td>\n",
       "      <td>garda40_text_4</td>\n",
       "      <td>george_text_13</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ i Ġdon 't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Habap vs Hamiltonstone</td>\n",
       "      <td>Habap</td>\n",
       "      <td>Hamiltonstone</td>\n",
       "      <td>habap_text_2</td>\n",
       "      <td>hamiltonstone_text_3</td>\n",
       "      <td>4</td>\n",
       "      <td>, Ġbut Ġi Ġhave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Hanlon1755 vs Happyme22</td>\n",
       "      <td>Hanlon1755</td>\n",
       "      <td>Happyme22</td>\n",
       "      <td>hanlon1755_text_4</td>\n",
       "      <td>happyme22_text_2</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġi Ġdo Ġnot Ġbelieve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Happyme22 vs Hardyplants</td>\n",
       "      <td>Happyme22</td>\n",
       "      <td>Hardyplants</td>\n",
       "      <td>happyme22_text_5</td>\n",
       "      <td>hardyplants_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġseem Ġto Ġbe Ġa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>HeadleyDown vs Hipocrite</td>\n",
       "      <td>HeadleyDown</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>headleydown_text_5</td>\n",
       "      <td>hipocrite_text_4</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġis Ġthat Ġwe Ġhave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Athenean vs Avraham</td>\n",
       "      <td>Athenean</td>\n",
       "      <td>Avraham</td>\n",
       "      <td>athenean_text_4</td>\n",
       "      <td>avraham_text_1</td>\n",
       "      <td>4</td>\n",
       "      <td>, Ġit Ġis Ġvery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Hipocrite vs Hodja_Nasreddin</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>hipocrite_text_5</td>\n",
       "      <td>hodja_nasreddin_text_3</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ for Ġexample ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Alienus vs Amalthea</td>\n",
       "      <td>Alienus</td>\n",
       "      <td>Amalthea</td>\n",
       "      <td>alienus_text_11</td>\n",
       "      <td>amalthea_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ in Ġfact ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aban1313 vs Akuri</td>\n",
       "      <td>Aban1313</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>aban1313_text_5</td>\n",
       "      <td>akuri_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġthe Ġsock p uppet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Atama vs Athenean</td>\n",
       "      <td>Atama</td>\n",
       "      <td>Athenean</td>\n",
       "      <td>atama_text_1</td>\n",
       "      <td>athenean_text_5</td>\n",
       "      <td>4</td>\n",
       "      <td>.Ċ there Ġis Ġno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Alanyst vs AlasdairGreen27</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>AlasdairGreen27</td>\n",
       "      <td>alanyst_text_1</td>\n",
       "      <td>alasdairgreen27_text_11</td>\n",
       "      <td>4</td>\n",
       "      <td>Ġnothing Ġto Ġdo Ġwith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Fixentries vs Flamarande</td>\n",
       "      <td>Fixentries</td>\n",
       "      <td>Flamarande</td>\n",
       "      <td>fixentries_text_4</td>\n",
       "      <td>flamarande_text_1</td>\n",
       "      <td>3</td>\n",
       "      <td>Ġbut Ġthey Ġare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Fixentries vs Flamarande</td>\n",
       "      <td>Fixentries</td>\n",
       "      <td>Flamarande</td>\n",
       "      <td>fixentries_text_2</td>\n",
       "      <td>flamarande_text_1</td>\n",
       "      <td>3</td>\n",
       "      <td>i 'm Ġnot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Erigu vs Essjay</td>\n",
       "      <td>Erigu</td>\n",
       "      <td>Essjay</td>\n",
       "      <td>erigu_text_2</td>\n",
       "      <td>essjay_text_3</td>\n",
       "      <td>3</td>\n",
       "      <td>.Ċ when Ġit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Essjay vs Exploding_Boy</td>\n",
       "      <td>Essjay</td>\n",
       "      <td>Exploding_Boy</td>\n",
       "      <td>essjay_text_1</td>\n",
       "      <td>exploding_boy_text_3</td>\n",
       "      <td>3</td>\n",
       "      <td>, Ġas Ġi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Essjay vs Exploding_Boy</td>\n",
       "      <td>Essjay</td>\n",
       "      <td>Exploding_Boy</td>\n",
       "      <td>essjay_text_2</td>\n",
       "      <td>exploding_boy_text_3</td>\n",
       "      <td>3</td>\n",
       "      <td>, Ġi Ġthink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AlasdairGreen27 vs Alienus</td>\n",
       "      <td>AlasdairGreen27</td>\n",
       "      <td>Alienus</td>\n",
       "      <td>alasdairgreen27_text_1</td>\n",
       "      <td>alienus_text_12</td>\n",
       "      <td>3</td>\n",
       "      <td>, Ġand Ġi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Exploding_Boy vs Fakirbakir</td>\n",
       "      <td>Exploding_Boy</td>\n",
       "      <td>Fakirbakir</td>\n",
       "      <td>exploding_boy_text_1</td>\n",
       "      <td>fakirbakir_text_5</td>\n",
       "      <td>3</td>\n",
       "      <td>Ġ 1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    problem  ...           highest_common_ngram\n",
       "287                 Enemesis vs Equanimous1  ...  Ġthe Ġcurrent Ġstate Ġof Ġthe\n",
       "161              Caboga vs Chanakyathegreat  ...                      Ġ 2 0 0 8\n",
       "262                       Dweller vs Ecelan  ...            .Ċ i Ġdon 't Ġthink\n",
       "364                Fyunck(click) vs Garda40  ...                      Ġ 2 0 1 1\n",
       "365                Fyunck(click) vs Garda40  ...                      Ġ 2 0 1 2\n",
       "395                      Gwen_Gale vs Habap  ...              , Ġbut Ġi Ġdon 't\n",
       "286                 Enemesis vs Equanimous1  ...  Ġthe Ġcurrent Ġstate Ġof Ġthe\n",
       "441                HeadleyDown vs Hipocrite  ...       Ġon Ġthis Ġtalk Ġpage .Ċ\n",
       "135              Britmax vs BrotherDarksoul  ...              Ġis Ġno Ġneed Ġto\n",
       "165               Chanakyathegreat vs Cla68  ...                   , Ġi Ġdon 't\n",
       "171                Cla68 vs Classicjupiter2  ...            i Ġjust Ġwanted Ġto\n",
       "267                    Ecelan vs EdJohnston  ...                   .Ċ i Ġdon 't\n",
       "112                  Bigdaddy1981 vs Bjenks  ...                        Ġ 1 9 6\n",
       "202                    Cptnono vs CyberAnth  ...                Ġto Ġfix Ġit .Ċ\n",
       "221           Danlaycock vs David_Shankbone  ...                   .Ċ i Ġdon 't\n",
       "231     Delicious_carbuncle vs Dennis_Brown  ...                   .Ċ i Ġdon 't\n",
       "250             DonaNobisPacem vs Dricherby  ...             Ġand Ġit Ġdoesn 't\n",
       "255                    Dricherby vs Dweller  ...                i Ġdon 't Ġknow\n",
       "257                    Dricherby vs Dweller  ...               Ġbut Ġi Ġdidn 't\n",
       "100                       Bfigura vs Bielle  ...              'd Ġlike Ġto Ġsee\n",
       "173                Cla68 vs Classicjupiter2  ...               , Ġin Ġorder Ġto\n",
       "226  David_Shankbone vs Delicious_carbuncle  ...                   .Ċ i 'm Ġnot\n",
       "269                    Ecelan vs EdJohnston  ...                   .Ċ i Ġdon 't\n",
       "77                        Atama vs Athenean  ...                   .Ċ also , Ġi\n",
       "311                 Essjay vs Exploding_Boy  ...                   .Ċ i Ġdon 't\n",
       "328                    Falcon9x5 vs Fipplet  ...                   .Ċ i Ġdon 't\n",
       "334                   Fipplet vs Fixentries  ...                  .Ċ i Ġdidn 't\n",
       "351        Floquenbeam vs Fragments_of_Jade  ...              Ġwith Ġyou , Ġand\n",
       "353        Floquenbeam vs Fragments_of_Jade  ...          Ġasked Ġyou Ġto Ġstop\n",
       "363                Fyunck(click) vs Garda40  ...                i 'm Ġnot Ġsure\n",
       "369                       Garda40 vs George  ...              Ġat Ġthe Ġend Ġof\n",
       "370                       Garda40 vs George  ...                   .Ċ i Ġdon 't\n",
       "371                       Garda40 vs George  ...                   .Ċ i Ġdon 't\n",
       "399                  Habap vs Hamiltonstone  ...                , Ġbut Ġi Ġhave\n",
       "413                 Hanlon1755 vs Happyme22  ...           Ġi Ġdo Ġnot Ġbelieve\n",
       "419                Happyme22 vs Hardyplants  ...               Ġseem Ġto Ġbe Ġa\n",
       "443                HeadleyDown vs Hipocrite  ...            Ġis Ġthat Ġwe Ġhave\n",
       "83                      Athenean vs Avraham  ...                , Ġit Ġis Ġvery\n",
       "449            Hipocrite vs Hodja_Nasreddin  ...              .Ċ for Ġexample ,\n",
       "46                      Alienus vs Amalthea  ...                  .Ċ in Ġfact ,\n",
       "17                        Aban1313 vs Akuri  ...             Ġthe Ġsock p uppet\n",
       "75                        Atama vs Athenean  ...               .Ċ there Ġis Ġno\n",
       "33               Alanyst vs AlasdairGreen27  ...         Ġnothing Ġto Ġdo Ġwith\n",
       "341                Fixentries vs Flamarande  ...                Ġbut Ġthey Ġare\n",
       "340                Fixentries vs Flamarande  ...                      i 'm Ġnot\n",
       "304                         Erigu vs Essjay  ...                    .Ċ when Ġit\n",
       "309                 Essjay vs Exploding_Boy  ...                       , Ġas Ġi\n",
       "310                 Essjay vs Exploding_Boy  ...                    , Ġi Ġthink\n",
       "39               AlasdairGreen27 vs Alienus  ...                      , Ġand Ġi\n",
       "315             Exploding_Boy vs Fakirbakir  ...                          Ġ 1 1\n",
       "\n",
       "[50 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_author_problems = problem_dataset_agg[problem_dataset_agg['known_author'] != problem_dataset_agg['unknown_author']].copy()\n",
    "diff_author_problems.sort_values([\"highest_common_count\"], ascending=[False], inplace=True)\n",
    "diff_author_problems[diff_author_problems['highest_common_count'] >= 3].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb6993e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams (17): [' going to', ' has been', ' have to', ' in the', ' it.\\n', ' know that', ' on the', ' that this', ' the same', ' to stop', ' to the', ' to your', ' you have', ', i', ', then', ', you', 'i just']\n",
      "3-grams (8): [' page.\\ni', ' that you are', ' the article.\\n', ' the wikip', ' you need to', '.\\nalso,', '.\\nthank you', '.\\nwhen you']\n",
      "4-grams (3): [' on my talk page', ', in order to', '.\\nthere is no']\n"
     ]
    }
   ],
   "source": [
    "known_doc = \"cla68_text_4\"\n",
    "known_text = known[known['doc_id'] == known_doc].reset_index().loc[0, 'text']\n",
    "\n",
    "unknown_doc = \"classicjupiter2_text_5\"\n",
    "unknown_text = unknown[unknown['doc_id'] == unknown_doc].reset_index().loc[0, 'text']\n",
    "\n",
    "common = common_ngrams(known_text, unknown_text, 2, model, tokenizer)\n",
    "pretty_print_common_ngrams(common, tokenizer=tokenizer, order='len_asc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7651c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<DOC>\n",
      "WP participants and communicated with them privately is still allowed to edit Wikipedia with no restrictions and has posted here to your talk page numerous times?\n",
      "Sue, have you read the latest blog post on Wikipediocracy?\n",
      "So, in order to increase female participation in WP, you would have to go back to the beginning and fundamentally alter how WP works.\n",
      "Might need to note something about that in the best practices paragraph you draft also.\n",
      "There is nothing wrong with being a participant on the Wikipediocracy website, probably the second best website on the planet, after Wikipedia, of course.\n",
      "Also, please review the checklist that you follow when acting on situations like this and make sure that this type of contingency is included in the steps listed.\n",
      "I'm still catching insults related to when I helped blow the whistle on an abusive group of editors/admins in Wikipedia about five years ago.\n",
      "Notice that nothing has been done to stop this particular editor from continuing to hector me about it.\n",
      "There is no protection for whistleblowers in Wikipedia.\n",
      "Also, Jimbo, I think you sent me a rather critical email when I spoke to the media about yours and David Gerard's range block of that town in Utah that someone else mentioned above.\n",
      "Spartaz, please link to the policy that says that indef blocked users cannot have article-related information posted to their talk page.\n",
      "I'm not suggesting that you are wrong, I just think you need to back up your argument with a link to a policy statement.\n",
      "Dave, you know that the first step in dispute resolution is to post one's concern on the other editor's talk page.\n",
      "When you revert the editor's comment, it interferes with the dispute resolution process.\n",
      "Do you have a formal role in adjudicating dispute resolution that I'm not aware of?\n",
      "If so, why didn't you say so on my talk page after reverting my post?\n",
      "I co-sponsored an RfC with two other editors on an admin about five years ago\n",
      "I just went to respond to the GA review and saw that you went ahead and made the corrections and passed the article.\n",
      "Thank you very much for the GA review and for the improvements.\n",
      "Are you going to change TDA's sanction rationale to WP\n",
      "If so, then I think you need to extend the sanction to the arbitrators who have recently said the same thing that he did.\n",
      "</DOC>\n",
      "<NGRAM>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "<DOC>\n",
    "{known_text}\n",
    "</DOC>\n",
    "<NGRAM>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98c4cd",
   "metadata": {},
   "source": [
    "## Phrase 1 -  \" on my talk page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d334e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = \" on my talk page\"\n",
    "\n",
    "para_1 = [\" on my discussion page\", \" on my talk-page\", \" on my talkpage\", \" on my discussion-page\", \" on my discussionpage\", \" upon my talk page\", \" upon my discussion page\", \" on the talk page of mine\", \" on the discussion page of mine\", \" on my tlak page\", \" on my talk pag\", \" on my talk paeg\", \" on my talkpgae\", \" on my discusson page\", \" on my discusion page\", \" on my discussin page\", \" on my discussion pg\", \" on my talk pg\", \" upon my talk-page\", \" upon my talkpage\", \" upon my discussion-page\", \" upon my discussionpage\", \" on the talk-page of mine\", \" on the discussion-page of mine\", \" on my talkpge\", \" on my tlk page\", \" on my talk paage\"]\n",
    "\n",
    "known_base_p1 = keep_before_phrase(known_text, p_1, True)\n",
    "unknown_base_p1 = keep_before_phrase(unknown_text, p_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11a1e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Scoring base_text alone…\n",
      "   base_total = -1368.2740\n",
      "\n",
      "→ [1/28] Processing reference…\n",
      "→ [2/28] Processing paraphrase…\n",
      "→ [3/28] Processing paraphrase…\n",
      "→ [4/28] Processing paraphrase…\n",
      "→ [5/28] Processing paraphrase…\n",
      "→ [6/28] Processing paraphrase…\n",
      "→ [7/28] Processing paraphrase…\n",
      "→ [8/28] Processing paraphrase…\n",
      "→ [9/28] Processing paraphrase…\n",
      "→ [10/28] Processing paraphrase…\n",
      "→ [11/28] Processing paraphrase…\n",
      "→ [12/28] Processing paraphrase…\n",
      "→ [13/28] Processing paraphrase…\n",
      "→ [14/28] Processing paraphrase…\n",
      "→ [15/28] Processing paraphrase…\n",
      "→ [16/28] Processing paraphrase…\n",
      "→ [17/28] Processing paraphrase…\n",
      "→ [18/28] Processing paraphrase…\n",
      "→ [19/28] Processing paraphrase…\n",
      "→ [20/28] Processing paraphrase…\n",
      "→ [21/28] Processing paraphrase…\n",
      "→ [22/28] Processing paraphrase…\n",
      "→ [23/28] Processing paraphrase…\n",
      "→ [24/28] Processing paraphrase…\n",
      "→ [25/28] Processing paraphrase…\n",
      "→ [26/28] Processing paraphrase…\n",
      "→ [27/28] Processing paraphrase…\n",
      "→ [28/28] Processing paraphrase…\n",
      "→ Scoring base_text alone…\n",
      "   base_total = -1416.0420\n",
      "\n",
      "→ [1/28] Processing reference…\n",
      "→ [2/28] Processing paraphrase…\n",
      "→ [3/28] Processing paraphrase…\n",
      "→ [4/28] Processing paraphrase…\n",
      "→ [5/28] Processing paraphrase…\n",
      "→ [6/28] Processing paraphrase…\n",
      "→ [7/28] Processing paraphrase…\n",
      "→ [8/28] Processing paraphrase…\n",
      "→ [9/28] Processing paraphrase…\n",
      "→ [10/28] Processing paraphrase…\n",
      "→ [11/28] Processing paraphrase…\n",
      "→ [12/28] Processing paraphrase…\n",
      "→ [13/28] Processing paraphrase…\n",
      "→ [14/28] Processing paraphrase…\n",
      "→ [15/28] Processing paraphrase…\n",
      "→ [16/28] Processing paraphrase…\n",
      "→ [17/28] Processing paraphrase…\n",
      "→ [18/28] Processing paraphrase…\n",
      "→ [19/28] Processing paraphrase…\n",
      "→ [20/28] Processing paraphrase…\n",
      "→ [21/28] Processing paraphrase…\n",
      "→ [22/28] Processing paraphrase…\n",
      "→ [23/28] Processing paraphrase…\n",
      "→ [24/28] Processing paraphrase…\n",
      "→ [25/28] Processing paraphrase…\n",
      "→ [26/28] Processing paraphrase…\n",
      "→ [27/28] Processing paraphrase…\n",
      "→ [28/28] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "known_p1_scores = score_phrases(known_base_p1, p_1, para_1, tokenizer, model)\n",
    "unknown_p1_scores = score_phrases(unknown_base_p1, p_1, para_1, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe842fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p1_pmf = add_pmf_column(known_p1_scores, 'phrase_log_probs')\n",
    "unknown_p1_pmf = add_pmf_column(unknown_p1_scores, 'phrase_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b144cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ [1/28] Processing reference…\n",
      "→ [2/28] Processing paraphrase…\n",
      "→ [3/28] Processing paraphrase…\n",
      "→ [4/28] Processing paraphrase…\n",
      "→ [5/28] Processing paraphrase…\n",
      "→ [6/28] Processing paraphrase…\n",
      "→ [7/28] Processing paraphrase…\n",
      "→ [8/28] Processing paraphrase…\n",
      "→ [9/28] Processing paraphrase…\n",
      "→ [10/28] Processing paraphrase…\n",
      "→ [11/28] Processing paraphrase…\n",
      "→ [12/28] Processing paraphrase…\n",
      "→ [13/28] Processing paraphrase…\n",
      "→ [14/28] Processing paraphrase…\n",
      "→ [15/28] Processing paraphrase…\n",
      "→ [16/28] Processing paraphrase…\n",
      "→ [17/28] Processing paraphrase…\n",
      "→ [18/28] Processing paraphrase…\n",
      "→ [19/28] Processing paraphrase…\n",
      "→ [20/28] Processing paraphrase…\n",
      "→ [21/28] Processing paraphrase…\n",
      "→ [22/28] Processing paraphrase…\n",
      "→ [23/28] Processing paraphrase…\n",
      "→ [24/28] Processing paraphrase…\n",
      "→ [25/28] Processing paraphrase…\n",
      "→ [26/28] Processing paraphrase…\n",
      "→ [27/28] Processing paraphrase…\n",
      "→ [28/28] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "p1_pmf = score_phrases_no_context(p_1, para_1, tokenizer, model)\n",
    "p1_pmf = add_pmf_column(p1_pmf, 'log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eed19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_p1_pmf.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a7ca6",
   "metadata": {},
   "source": [
    "## Phrase 2 - \", in order to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "505c5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2 = \", in order to\"\n",
    "\n",
    "para_2 = [\", to\", \", so as to\", \", for to\", \", inorder to\"]\n",
    "\n",
    "known_base_p2 = keep_before_phrase(known_text, p_2, True)\n",
    "unknown_base_p2 = keep_before_phrase(unknown_text, p_2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06f266a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Scoring base_text alone…\n",
      "   base_total = -241.3805\n",
      "\n",
      "→ [1/5] Processing reference…\n",
      "→ [2/5] Processing paraphrase…\n",
      "→ [3/5] Processing paraphrase…\n",
      "→ [4/5] Processing paraphrase…\n",
      "→ [5/5] Processing paraphrase…\n",
      "→ Scoring base_text alone…\n",
      "   base_total = -78.6113\n",
      "\n",
      "→ [1/5] Processing reference…\n",
      "→ [2/5] Processing paraphrase…\n",
      "→ [3/5] Processing paraphrase…\n",
      "→ [4/5] Processing paraphrase…\n",
      "→ [5/5] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "known_p2_scores = score_phrases(known_base_p2, p_2, para_2, tokenizer, model)\n",
    "unknown_p2_scores = score_phrases(unknown_base_p2, p_2, para_2, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f5d2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p2_pmf = add_pmf_column(known_p2_scores, 'phrase_log_probs')\n",
    "unknown_p2_pmf = add_pmf_column(unknown_p2_scores, 'phrase_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cddc53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ [1/5] Processing reference…\n",
      "→ [2/5] Processing paraphrase…\n",
      "→ [3/5] Processing paraphrase…\n",
      "→ [4/5] Processing paraphrase…\n",
      "→ [5/5] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "p2_pmf = score_phrases_no_context(p_2, para_2, tokenizer, model)\n",
    "p2_pmf = add_pmf_column(p2_pmf, 'log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b1930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_p2_pmf.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa94d03",
   "metadata": {},
   "source": [
    "## Phrase 3 - \".\\nthere is no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98b7b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_3 = \".\\nthere is no\"\n",
    "\n",
    "para_3 = [\".\\nthere's no\", \".\\nthere’s no\", \".\\ntheres no\", \".\\nthere is not any\", \".\\nthere isn't any\"]\n",
    "\n",
    "known_base_p3 = keep_before_phrase(known_text, p_3, True)\n",
    "unknown_base_p3 = keep_before_phrase(unknown_text, p_3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c07ff4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Scoring base_text alone…\n",
      "   base_total = -401.3787\n",
      "\n",
      "→ [1/6] Processing reference…\n",
      "→ [2/6] Processing paraphrase…\n",
      "→ [3/6] Processing paraphrase…\n",
      "→ [4/6] Processing paraphrase…\n",
      "→ [5/6] Processing paraphrase…\n",
      "→ [6/6] Processing paraphrase…\n",
      "→ Scoring base_text alone…\n",
      "   base_total = -1286.7996\n",
      "\n",
      "→ [1/6] Processing reference…\n",
      "→ [2/6] Processing paraphrase…\n",
      "→ [3/6] Processing paraphrase…\n",
      "→ [4/6] Processing paraphrase…\n",
      "→ [5/6] Processing paraphrase…\n",
      "→ [6/6] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "known_p3_scores = score_phrases(known_base_p3, p_3, para_3, tokenizer, model)\n",
    "unknown_p3_scores = score_phrases(unknown_base_p3, p_3, para_3, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "185bef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p3_pmf = add_pmf_column(known_p3_scores, 'phrase_log_probs')\n",
    "unknown_p3_pmf = add_pmf_column(unknown_p3_scores, 'phrase_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4509d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ [1/6] Processing reference…\n",
      "→ [2/6] Processing paraphrase…\n",
      "→ [3/6] Processing paraphrase…\n",
      "→ [4/6] Processing paraphrase…\n",
      "→ [5/6] Processing paraphrase…\n",
      "→ [6/6] Processing paraphrase…\n"
     ]
    }
   ],
   "source": [
    "p3_pmf = score_phrases_no_context(p_3, para_3, tokenizer, model)\n",
    "p3_pmf = add_pmf_column(p3_pmf, 'log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21a2b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_p3_pmf.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
