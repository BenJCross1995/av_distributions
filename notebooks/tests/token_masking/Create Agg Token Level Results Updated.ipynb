{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573779af",
   "metadata": {},
   "source": [
    "# Create Aggregated Token Level Results\n",
    "\n",
    "In this script we combine the scores for all of the corpuses and data types in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "735c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from from_root import from_root\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from read_and_write_docs import read_excel_sheets, read_rds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd778600",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Here we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ad19d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = \"/Volumes/BCross/av_datasets_experiments/ngram_masking\"\n",
    "raw_save_loc = f\"{base_data_dir}/raw_token_level_scores.xlsx\"\n",
    "agg_save_loc = f\"{base_data_dir}/raw_agg_token_level_scores.xlsx\"\n",
    "token_level_problems_loc = f\"{base_data_dir}/raw_problem_list.xlsx\"\n",
    "\n",
    "# Metadata for the data\n",
    "data_types = [\"test\", \"training\"]\n",
    "corpuses = [\"ACL\", \"Enron\", \"Perverted Justice\", \"StackExchange\",\n",
    "            \"The Telegraph\", \"TripAdvisor\", \"Wiki\"]\n",
    "paraphrasing_models = [\"ModernBERT-base\", \"ModernBERT-large\"]\n",
    "scoring_models = [\"gpt2\"]\n",
    "\n",
    "# Load phrases and keep phrases if exists\n",
    "# phrases = pd.read_excel('/Volumes/BCross/paraphrase examples slurm/wiki-phrase-list-reviewed.xlsx')\n",
    "phrases=None\n",
    "\n",
    "if phrases:\n",
    "    phrases = phrases[phrases['keep_phrase'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c168a",
   "metadata": {},
   "source": [
    "### Load Original Data and Check Model Combos\n",
    "\n",
    "The columns to currently compare are paraphrasing_model, scoring_model, corpus, data_type, and filename. The code below gets the unique combinations of each from the raw results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e3353ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_columns = ['paraphrasing_model', 'scoring_model', 'corpus', 'data_type', 'filename']\n",
    "\n",
    "if Path(raw_save_loc).exists():\n",
    "    raw_results = pd.read_excel(raw_save_loc)\n",
    "    \n",
    "    # Get the \n",
    "    existing_combos = set(\n",
    "        raw_results[combo_columns]\n",
    "        .itertuples(index=False, name=None)\n",
    "    )\n",
    "else:\n",
    "    # file does not exist → no existing results\n",
    "    raw_results = pd.DataFrame(\n",
    "        columns=combo_columns\n",
    "    )\n",
    "    existing_combos = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b7d7f",
   "metadata": {},
   "source": [
    "### Aggregate any New Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f507dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on test data\n",
      "Working on the ACL corpus\n",
      "Working on the ModernBERT-base paraphrasing model\n",
      "Working on the gpt2 scoring model\n",
      "Num Files in data_dir 5\n",
      "Working on the ModernBERT-large paraphrasing model\n",
      "Working on the gpt2 scoring model\n",
      "Num Files in data_dir 3\n",
      "Working on the Enron corpus\n",
      "Working on the ModernBERT-base paraphrasing model\n",
      "Working on the gpt2 scoring model\n",
      "Num Files in data_dir 200\n",
      "All files already processed for test/Enron/ModernBERT-base/gpt2 — nothing new.\n",
      "Working on the ModernBERT-large paraphrasing model\n",
      "Working on the gpt2 scoring model\n",
      "Num Files in data_dir 232\n",
      "All files already processed for test/Enron/ModernBERT-large/gpt2 — nothing new.\n",
      "Working on the Perverted Justice corpus\n",
      "Working on the ModernBERT-base paraphrasing model\n",
      "Working on the gpt2 scoring model\n",
      "Num Files in data_dir 464\n",
      "All files already processed for test/Perverted Justice/ModernBERT-base/gpt2 — nothing new.\n",
      "Working on the ModernBERT-large paraphrasing model\n",
      "Working on the gpt2 scoring model\n",
      "Num Files in data_dir 395\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[170], line 54\u001b[0m\n",
      "\u001b[1;32m     46\u001b[0m llr \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m     48\u001b[0m metadata_info \u001b[38;5;241m=\u001b[39m metadata[[\n",
      "\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparaphrasing_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscoring_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknown_author\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown_author\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown_doc_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknown_doc_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;32m     52\u001b[0m ]]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;32m---> 54\u001b[0m metadata_repeated \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetadata_info\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     55\u001b[0m llr_with_metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([metadata_repeated, llr\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrases \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m phrases\u001b[38;5;241m.\u001b[39mempty:\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/av_distributions/my_venv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n",
      "\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n",
      "\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/av_distributions/my_venv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n",
      "\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n",
      "\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n",
      "\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n",
      "\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/av_distributions/my_venv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n",
      "\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n",
      "\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "all_model_data = []\n",
    "\n",
    "for dt in data_types:\n",
    "    print(f\"Working on {dt} data\")\n",
    "    for cp in corpuses:\n",
    "        print(f\"Working on the {cp} corpus\")\n",
    "        for pm in paraphrasing_models:\n",
    "            print(f\"Working on the {pm} paraphrasing model\")\n",
    "            for sm in scoring_models:\n",
    "                print(f\"Working on the {sm} scoring model\")\n",
    "\n",
    "                data_dir = f\"{base_data_dir}/{dt}/{cp}/{pm}/{sm} results/raw_inc_rank\"\n",
    "\n",
    "                # Skip cleanly if folder doesn't exist\n",
    "                if not os.path.isdir(data_dir):\n",
    "                    print(f\"Skipping (missing dir): {data_dir}\")\n",
    "                    continue\n",
    "\n",
    "                excel_files = sorted(glob(os.path.join(data_dir, \"*.xlsx\")))\n",
    "                print(f\"Num Files in data_dir {len(excel_files)}\")\n",
    "\n",
    "                # If no files, nothing to do\n",
    "                if not excel_files:\n",
    "                    continue\n",
    "\n",
    "                all_merged = []\n",
    "\n",
    "                for file in excel_files:\n",
    "                    base_name = os.path.basename(file)\n",
    "                    combo = (pm, sm, cp, dt, base_name)\n",
    "\n",
    "                    # Skip if already processed\n",
    "                    if combo in existing_combos:\n",
    "                        # optional: keep it quieter\n",
    "                        # print(f\"Skipping existing combo: {combo}\")\n",
    "                        continue\n",
    "\n",
    "                    data = read_excel_sheets(file, ['metadata', 'LLR'])\n",
    "\n",
    "                    metadata = data['metadata']\n",
    "                    metadata['data_type'] = dt\n",
    "                    metadata['paraphrasing_model'] = pm\n",
    "                    metadata['scoring_model'] = sm\n",
    "                    metadata['filename'] = base_name\n",
    "\n",
    "                    llr = data['LLR']\n",
    "\n",
    "                    metadata_info = metadata[[\n",
    "                        'paraphrasing_model', 'scoring_model', 'corpus', 'data_type',\n",
    "                        'sample_id', 'problem', 'filename', 'known_author',\n",
    "                        'unknown_author', 'unknown_doc_id', 'known_doc_id', 'target'\n",
    "                    ]].copy()\n",
    "\n",
    "                    metadata_repeated = pd.concat([metadata_info] * len(llr), ignore_index=True)\n",
    "                    llr_with_metadata = pd.concat([metadata_repeated, llr.reset_index(drop=True)], axis=1)\n",
    "\n",
    "                    if phrases is not None and not phrases.empty:\n",
    "                        llr_with_metadata = llr_with_metadata.merge(\n",
    "                            phrases,\n",
    "                            left_on='original_phrase',\n",
    "                            right_on='phrase',\n",
    "                            how='inner'\n",
    "                        )\n",
    "\n",
    "                    all_merged.append(llr_with_metadata)\n",
    "\n",
    "                # ✅ Only concat if something survived skipping\n",
    "                if not all_merged:\n",
    "                    print(f\"All files already processed for {dt}/{cp}/{pm}/{sm} — nothing new.\")\n",
    "                    continue\n",
    "\n",
    "                final_merged_table = pd.concat(all_merged, ignore_index=True)\n",
    "                all_model_data.append(final_merged_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab5afb",
   "metadata": {},
   "source": [
    "### Append any New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7045f467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw results rows (before): 33,327\n",
      "New results rows:          281\n",
      "New entries added:         281\n",
      "Raw results rows (after):  33,608\n"
     ]
    }
   ],
   "source": [
    "# rows in raw BEFORE adding anything\n",
    "raw_before = 0 if raw_results is None else len(raw_results)\n",
    "\n",
    "if all_model_data:\n",
    "    new_results = pd.concat(all_model_data, ignore_index=True)\n",
    "    new_rows = len(new_results)\n",
    "\n",
    "    raw_results = pd.concat([raw_results, new_results], ignore_index=True)\n",
    "    raw_after = len(raw_results)\n",
    "\n",
    "    added_rows = raw_after - raw_before  # should equal new_rows unless something odd happened\n",
    "\n",
    "    print(f\"Raw results rows (before): {raw_before:,}\")\n",
    "    print(f\"New results rows:          {new_rows:,}\")\n",
    "    print(f\"New entries added:         {added_rows:,}\")\n",
    "    print(f\"Raw results rows (after):  {raw_after:,}\")\n",
    "    \n",
    "    raw_results.to_excel(raw_save_loc, index=False)\n",
    "else:\n",
    "    print(\"No new model combinations to add.\")\n",
    "    print(f\"Raw results rows (unchanged): {raw_before:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c42834b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrasing_model</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>corpus</th>\n",
       "      <th>data_type</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>problem</th>\n",
       "      <th>filename</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>unknown_doc_id</th>\n",
       "      <th>...</th>\n",
       "      <th>known_vs_no_context_log_prob</th>\n",
       "      <th>unknown_vs_no_context_log_prob</th>\n",
       "      <th>pmf_no_context</th>\n",
       "      <th>pmf_known</th>\n",
       "      <th>pmf_unknown</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>unknown_ref_vs_top_rank</th>\n",
       "      <th>unknown_ref_vs_best_rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>kimberly_watson_mail_1 vs larry_campbell_mail_...</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>larry_campbell_mail_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.760929</td>\n",
       "      <td>4.005409</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>0.295786</td>\n",
       "      <td>1.870607</td>\n",
       "      <td>1.840216</td>\n",
       "      <td>0.529023</td>\n",
       "      <td>-0.728053</td>\n",
       "      <td>-0.728053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>kimberly_watson_mail_1 vs larry_campbell_mail_...</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>larry_campbell_mail_1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.093600</td>\n",
       "      <td>4.361169</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>0.127060</td>\n",
       "      <td>0.063233</td>\n",
       "      <td>1.169858</td>\n",
       "      <td>0.895991</td>\n",
       "      <td>1.199054</td>\n",
       "      <td>-2.133572</td>\n",
       "      <td>-2.133572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>kimberly_watson_mail_1 vs larry_campbell_mail_...</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>larry_campbell_mail_1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.381106</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>1.169858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.695661</td>\n",
       "      <td>-3.070706</td>\n",
       "      <td>-3.070706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>kimberly_watson_mail_1 vs larry_campbell_mail_...</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>larry_campbell_mail_1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.852410</td>\n",
       "      <td>2.336323</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.121286</td>\n",
       "      <td>0.093036</td>\n",
       "      <td>2.783573</td>\n",
       "      <td>0.916189</td>\n",
       "      <td>1.031351</td>\n",
       "      <td>-1.980500</td>\n",
       "      <td>-1.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>kimberly_watson_mail_1 vs larry_campbell_mail_...</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>larry_campbell_mail_1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091553</td>\n",
       "      <td>0.370007</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.029069</td>\n",
       "      <td>2.783573</td>\n",
       "      <td>1.971102</td>\n",
       "      <td>1.536573</td>\n",
       "      <td>-3.015689</td>\n",
       "      <td>-3.015689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paraphrasing_model scoring_model corpus data_type  sample_id                            problem  \\\n",
       "0    ModernBERT-base          gpt2  Enron      test         13  Kimberly.watson vs Larry.campbell   \n",
       "1    ModernBERT-base          gpt2  Enron      test         13  Kimberly.watson vs Larry.campbell   \n",
       "2    ModernBERT-base          gpt2  Enron      test         13  Kimberly.watson vs Larry.campbell   \n",
       "3    ModernBERT-base          gpt2  Enron      test         13  Kimberly.watson vs Larry.campbell   \n",
       "4    ModernBERT-base          gpt2  Enron      test         13  Kimberly.watson vs Larry.campbell   \n",
       "\n",
       "                                            filename     known_author  unknown_author  \\\n",
       "0  kimberly_watson_mail_1 vs larry_campbell_mail_...  Kimberly.watson  Larry.campbell   \n",
       "1  kimberly_watson_mail_1 vs larry_campbell_mail_...  Kimberly.watson  Larry.campbell   \n",
       "2  kimberly_watson_mail_1 vs larry_campbell_mail_...  Kimberly.watson  Larry.campbell   \n",
       "3  kimberly_watson_mail_1 vs larry_campbell_mail_...  Kimberly.watson  Larry.campbell   \n",
       "4  kimberly_watson_mail_1 vs larry_campbell_mail_...  Kimberly.watson  Larry.campbell   \n",
       "\n",
       "          unknown_doc_id  ... known_vs_no_context_log_prob  unknown_vs_no_context_log_prob  \\\n",
       "0  larry_campbell_mail_1  ...                     1.760929                        4.005409   \n",
       "1  larry_campbell_mail_1  ...                     5.093600                        4.361169   \n",
       "2  larry_campbell_mail_1  ...                          NaN                        2.381106   \n",
       "3  larry_campbell_mail_1  ...                     5.852410                        2.336323   \n",
       "4  larry_campbell_mail_1  ...                    -0.091553                        0.370007   \n",
       "\n",
       "  pmf_no_context  pmf_known pmf_unknown llr_no_context  llr_known  llr_unknown  unknown_ref_vs_top_rank  \\\n",
       "0       0.013471   0.014447    0.295786       1.870607   1.840216     0.529023                -0.728053   \n",
       "1       0.067630   0.127060    0.063233       1.169858   0.895991     1.199054                -2.133572   \n",
       "2       0.067630        NaN    0.020153       1.169858        NaN     1.695661                -3.070706   \n",
       "3       0.001646   0.121286    0.093036       2.783573   0.916189     1.031351                -1.980500   \n",
       "4       0.001646   0.010688    0.029069       2.783573   1.971102     1.536573                -3.015689   \n",
       "\n",
       "   unknown_ref_vs_best_rest  \n",
       "0                 -0.728053  \n",
       "1                 -2.133572  \n",
       "2                 -3.070706  \n",
       "3                 -1.980500  \n",
       "4                 -3.015689  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56052a53",
   "metadata": {},
   "source": [
    "### Get the Complete Problems\n",
    "\n",
    "Currently doing this by getting complete problems based on what we have paraphrased and scored in the raw data but the best way would be to load the known and unknown for each corpus and then get the number of documents for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1d802d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem and document level columns\n",
    "distinct_problem_cols = [\n",
    "    'paraphrasing_model', 'scoring_model', 'corpus', 'data_type', 'problem',\n",
    "    'known_doc_id', 'unknown_doc_id', 'target'\n",
    "]\n",
    "\n",
    "# The problem level columns\n",
    "distinct_grouping_cols = [\n",
    "    'paraphrasing_model', 'scoring_model', 'corpus', 'data_type', 'problem', 'target'\n",
    "]\n",
    "\n",
    "# Here we get the number of different document comparisons in each problem\n",
    "distinct_problems = (\n",
    "    raw_results[distinct_problem_cols]\n",
    "    .drop_duplicates()\n",
    "    .groupby(distinct_grouping_cols, as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={\"size\": \"n_docs\"})\n",
    "    .sort_values(\"n_docs\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Here we get the maximum for each corpus and data type\n",
    "corpus_problem_max = (\n",
    "    distinct_problems\n",
    "    .groupby(['corpus', 'data_type'], as_index=False)['n_docs']\n",
    "    .agg(n_docs='max')\n",
    ")\n",
    "\n",
    "# Get the complete problem dataframe\n",
    "complete_problems = (\n",
    "    distinct_problems\n",
    "    .merge(\n",
    "        corpus_problem_max,\n",
    "        on=['corpus', 'data_type', 'n_docs'],\n",
    "        how='inner'\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .drop(columns=['n_docs'])\n",
    ")\n",
    "\n",
    "complete_problems.to_excel(token_level_problems_loc, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44b979",
   "metadata": {},
   "source": [
    "### Aggregate First by Phrase Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f46ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before merge: 33,608\n",
      "Rows after merge:  21,783\n",
      "Rows kept:         64.81%\n",
      "Rows dropped:      11,825\n"
     ]
    }
   ],
   "source": [
    "# First we want to filter to just the problems in the problem list\n",
    "# These are the complete problems\n",
    "before_merge_rows = len(raw_results)\n",
    "\n",
    "complete_raw_results = (\n",
    "    raw_results\n",
    "    .merge(\n",
    "        complete_problems,\n",
    "        on=['paraphrasing_model', 'scoring_model', 'corpus', 'data_type', 'problem', 'target'],\n",
    "        how='inner'\n",
    "    )\n",
    ")\n",
    "\n",
    "after_merge_rows = len(complete_raw_results)\n",
    "\n",
    "print(f\"Rows before merge: {before_merge_rows:,}\")\n",
    "print(f\"Rows after merge:  {after_merge_rows:,}\")\n",
    "print(f\"Rows kept:         {after_merge_rows / before_merge_rows:.2%}\" if before_merge_rows else \"Rows kept: N/A\")\n",
    "print(f\"Rows dropped:      {before_merge_rows - after_merge_rows:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8e6826df",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    'paraphrasing_model', 'scoring_model', 'corpus', 'data_type',\n",
    "    'problem', 'known_author', 'unknown_author', 'target', 'original_phrase',\n",
    "    'num_tokens', 'phrase_occurence'\n",
    "]\n",
    "\n",
    "avg_cols = [\n",
    "    'no_context_log_prob', 'known_log_prob', 'unknown_log_prob', 'known_vs_no_context_log_prob',\n",
    "    'unknown_vs_no_context_log_prob','llr_no_context', 'llr_known', 'llr_unknown', 'unknown_ref_vs_top_rank',\n",
    "    'unknown_ref_vs_best_rest'\n",
    "]\n",
    "\n",
    "# Group and compute the mean\n",
    "grouped_results = (\n",
    "    complete_raw_results\n",
    "    .groupby(group_cols, as_index=False)[avg_cols]\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3806e790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrasing_model</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>corpus</th>\n",
       "      <th>data_type</th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>original_phrase</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>no_context_log_prob</th>\n",
       "      <th>known_log_prob</th>\n",
       "      <th>unknown_log_prob</th>\n",
       "      <th>known_vs_no_context_log_prob</th>\n",
       "      <th>unknown_vs_no_context_log_prob</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>unknown_ref_vs_top_rank</th>\n",
       "      <th>unknown_ref_vs_best_rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>False</td>\n",
       "      <td>amount of</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.663528</td>\n",
       "      <td>-7.902599</td>\n",
       "      <td>-5.658119</td>\n",
       "      <td>1.760929</td>\n",
       "      <td>4.005409</td>\n",
       "      <td>1.870607</td>\n",
       "      <td>1.840216</td>\n",
       "      <td>0.529023</td>\n",
       "      <td>-0.728053</td>\n",
       "      <td>-0.728053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>False</td>\n",
       "      <td>and i</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.443960</td>\n",
       "      <td>-6.310178</td>\n",
       "      <td>-14.665708</td>\n",
       "      <td>6.133782</td>\n",
       "      <td>-2.221747</td>\n",
       "      <td>3.873449</td>\n",
       "      <td>1.817539</td>\n",
       "      <td>3.875098</td>\n",
       "      <td>-8.505962</td>\n",
       "      <td>-8.505962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>False</td>\n",
       "      <td>and i</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.443960</td>\n",
       "      <td>-6.365383</td>\n",
       "      <td>-6.029979</td>\n",
       "      <td>6.078577</td>\n",
       "      <td>6.413981</td>\n",
       "      <td>3.873449</td>\n",
       "      <td>2.046698</td>\n",
       "      <td>1.840245</td>\n",
       "      <td>-3.946299</td>\n",
       "      <td>-3.946299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>False</td>\n",
       "      <td>and i</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.443960</td>\n",
       "      <td>-6.760739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.683221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.270580</td>\n",
       "      <td>2.187395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>False</td>\n",
       "      <td>and i</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.443960</td>\n",
       "      <td>-4.820793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.623167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.270580</td>\n",
       "      <td>1.756902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paraphrasing_model scoring_model corpus data_type                            problem     known_author  \\\n",
       "0    ModernBERT-base          gpt2  Enron      test  Kimberly.watson vs Larry.campbell  Kimberly.watson   \n",
       "1    ModernBERT-base          gpt2  Enron      test  Kimberly.watson vs Larry.campbell  Kimberly.watson   \n",
       "2    ModernBERT-base          gpt2  Enron      test  Kimberly.watson vs Larry.campbell  Kimberly.watson   \n",
       "3    ModernBERT-base          gpt2  Enron      test  Kimberly.watson vs Larry.campbell  Kimberly.watson   \n",
       "4    ModernBERT-base          gpt2  Enron      test  Kimberly.watson vs Larry.campbell  Kimberly.watson   \n",
       "\n",
       "   unknown_author  target original_phrase  num_tokens  ...  no_context_log_prob  known_log_prob  \\\n",
       "0  Larry.campbell   False       amount of          18  ...            -9.663528       -7.902599   \n",
       "1  Larry.campbell   False           and i          14  ...           -12.443960       -6.310178   \n",
       "2  Larry.campbell   False           and i          14  ...           -12.443960       -6.365383   \n",
       "3  Larry.campbell   False           and i          14  ...           -12.443960       -6.760739   \n",
       "4  Larry.campbell   False           and i          14  ...           -12.443960       -4.820793   \n",
       "\n",
       "   unknown_log_prob  known_vs_no_context_log_prob  unknown_vs_no_context_log_prob  llr_no_context  \\\n",
       "0         -5.658119                      1.760929                        4.005409        1.870607   \n",
       "1        -14.665708                      6.133782                       -2.221747        3.873449   \n",
       "2         -6.029979                      6.078577                        6.413981        3.873449   \n",
       "3               NaN                      5.683221                             NaN        4.270580   \n",
       "4               NaN                      7.623167                             NaN        4.270580   \n",
       "\n",
       "   llr_known  llr_unknown  unknown_ref_vs_top_rank  unknown_ref_vs_best_rest  \n",
       "0   1.840216     0.529023                -0.728053                 -0.728053  \n",
       "1   1.817539     3.875098                -8.505962                 -8.505962  \n",
       "2   2.046698     1.840245                -3.946299                 -3.946299  \n",
       "3   2.187395          NaN                      NaN                       NaN  \n",
       "4   1.756902          NaN                      NaN                       NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76496c",
   "metadata": {},
   "source": [
    "### Then Create Problem Level Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca75fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grouping and aggregation columns\n",
    "group_cols = [\n",
    "    'paraphrasing_model', 'scoring_model', 'corpus', 'data_type',\n",
    "    'problem', 'known_author', 'unknown_author', 'target'\n",
    "]\n",
    "\n",
    "avg_cols = [\n",
    "    'no_context_log_prob', 'known_log_prob', 'unknown_log_prob', 'known_vs_no_context_log_prob',\n",
    "    'unknown_vs_no_context_log_prob', 'llr_no_context', 'llr_known', 'llr_unknown', 'unknown_ref_vs_top_rank',\n",
    "    'unknown_ref_vs_best_rest'\n",
    "]\n",
    "\n",
    "# Get unique num_tokens thresholds (sorted ascending)\n",
    "token_thresholds = sorted(grouped_results['num_tokens'].dropna().unique())\n",
    "\n",
    "# Container for results\n",
    "all_summaries = []\n",
    "\n",
    "# Loop through each token threshold\n",
    "for min_token_size in token_thresholds:\n",
    "    # Filter rows where num_tokens >= threshold\n",
    "    filtered = grouped_results[grouped_results['num_tokens'] >= min_token_size]\n",
    "\n",
    "    # Group and sum\n",
    "    grouped = (\n",
    "        filtered\n",
    "        .groupby(group_cols, as_index=False)[avg_cols]\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "    # Add the min_token_size column\n",
    "    grouped['min_token_size'] = min_token_size\n",
    "\n",
    "    # Append to results\n",
    "    all_summaries.append(grouped)\n",
    "\n",
    "# Combine all grouped results\n",
    "problem_summary = pd.concat(all_summaries, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c63b0ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrasing_model</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>corpus</th>\n",
       "      <th>data_type</th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>no_context_log_prob</th>\n",
       "      <th>known_log_prob</th>\n",
       "      <th>unknown_log_prob</th>\n",
       "      <th>known_vs_no_context_log_prob</th>\n",
       "      <th>unknown_vs_no_context_log_prob</th>\n",
       "      <th>llr_no_context</th>\n",
       "      <th>llr_known</th>\n",
       "      <th>llr_unknown</th>\n",
       "      <th>unknown_ref_vs_top_rank</th>\n",
       "      <th>unknown_ref_vs_best_rest</th>\n",
       "      <th>min_token_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Kimberly.watson vs Larry.campbell</td>\n",
       "      <td>Kimberly.watson</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>False</td>\n",
       "      <td>-1124.176939</td>\n",
       "      <td>-476.140733</td>\n",
       "      <td>-435.045350</td>\n",
       "      <td>442.046262</td>\n",
       "      <td>379.571570</td>\n",
       "      <td>264.962419</td>\n",
       "      <td>125.190571</td>\n",
       "      <td>102.402221</td>\n",
       "      <td>-169.519448</td>\n",
       "      <td>-129.767518</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Larry.campbell vs Larry.campbell</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>True</td>\n",
       "      <td>-1069.574019</td>\n",
       "      <td>-462.281040</td>\n",
       "      <td>-473.039619</td>\n",
       "      <td>423.690896</td>\n",
       "      <td>400.981041</td>\n",
       "      <td>239.970598</td>\n",
       "      <td>116.689719</td>\n",
       "      <td>111.853246</td>\n",
       "      <td>-182.020652</td>\n",
       "      <td>-139.794260</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Larry.campbell vs Lindy.donoho</td>\n",
       "      <td>Larry.campbell</td>\n",
       "      <td>Lindy.donoho</td>\n",
       "      <td>False</td>\n",
       "      <td>-1032.656678</td>\n",
       "      <td>-418.073481</td>\n",
       "      <td>-410.445017</td>\n",
       "      <td>422.340383</td>\n",
       "      <td>433.517064</td>\n",
       "      <td>240.054272</td>\n",
       "      <td>116.580416</td>\n",
       "      <td>84.387500</td>\n",
       "      <td>-136.335129</td>\n",
       "      <td>-61.439897</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Lindy.donoho vs Lindy.donoho</td>\n",
       "      <td>Lindy.donoho</td>\n",
       "      <td>Lindy.donoho</td>\n",
       "      <td>True</td>\n",
       "      <td>-986.314673</td>\n",
       "      <td>-441.770480</td>\n",
       "      <td>-410.508914</td>\n",
       "      <td>406.427760</td>\n",
       "      <td>413.139095</td>\n",
       "      <td>221.974775</td>\n",
       "      <td>110.642685</td>\n",
       "      <td>85.310283</td>\n",
       "      <td>-130.141024</td>\n",
       "      <td>-76.749981</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>Lindy.donoho vs Liz.taylor</td>\n",
       "      <td>Lindy.donoho</td>\n",
       "      <td>Liz.taylor</td>\n",
       "      <td>False</td>\n",
       "      <td>-564.662253</td>\n",
       "      <td>-241.866188</td>\n",
       "      <td>-212.336756</td>\n",
       "      <td>214.464741</td>\n",
       "      <td>273.641570</td>\n",
       "      <td>116.686219</td>\n",
       "      <td>60.760377</td>\n",
       "      <td>41.266020</td>\n",
       "      <td>-61.975530</td>\n",
       "      <td>-4.397208</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paraphrasing_model scoring_model corpus data_type                            problem     known_author  \\\n",
       "0    ModernBERT-base          gpt2  Enron      test  Kimberly.watson vs Larry.campbell  Kimberly.watson   \n",
       "1    ModernBERT-base          gpt2  Enron      test   Larry.campbell vs Larry.campbell   Larry.campbell   \n",
       "2    ModernBERT-base          gpt2  Enron      test     Larry.campbell vs Lindy.donoho   Larry.campbell   \n",
       "3    ModernBERT-base          gpt2  Enron      test       Lindy.donoho vs Lindy.donoho     Lindy.donoho   \n",
       "4    ModernBERT-base          gpt2  Enron      test         Lindy.donoho vs Liz.taylor     Lindy.donoho   \n",
       "\n",
       "   unknown_author  target  no_context_log_prob  known_log_prob  unknown_log_prob  \\\n",
       "0  Larry.campbell   False         -1124.176939     -476.140733       -435.045350   \n",
       "1  Larry.campbell    True         -1069.574019     -462.281040       -473.039619   \n",
       "2    Lindy.donoho   False         -1032.656678     -418.073481       -410.445017   \n",
       "3    Lindy.donoho    True          -986.314673     -441.770480       -410.508914   \n",
       "4      Liz.taylor   False          -564.662253     -241.866188       -212.336756   \n",
       "\n",
       "   known_vs_no_context_log_prob  unknown_vs_no_context_log_prob  llr_no_context   llr_known  llr_unknown  \\\n",
       "0                    442.046262                      379.571570      264.962419  125.190571   102.402221   \n",
       "1                    423.690896                      400.981041      239.970598  116.689719   111.853246   \n",
       "2                    422.340383                      433.517064      240.054272  116.580416    84.387500   \n",
       "3                    406.427760                      413.139095      221.974775  110.642685    85.310283   \n",
       "4                    214.464741                      273.641570      116.686219   60.760377    41.266020   \n",
       "\n",
       "   unknown_ref_vs_top_rank  unknown_ref_vs_best_rest  min_token_size  \n",
       "0              -169.519448               -129.767518              12  \n",
       "1              -182.020652               -139.794260              12  \n",
       "2              -136.335129                -61.439897              12  \n",
       "3              -130.141024                -76.749981              12  \n",
       "4               -61.975530                 -4.397208              12  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d68dc",
   "metadata": {},
   "source": [
    "### Remove problems with not a result in each\n",
    "\n",
    "This is a check which ensures that for each corpus, data_type, paraphrasing_model, scoring_model and min_token_size combo that we have at least a single result which is a TRUE problem and also a single FALSE problem. This is to ensure that the idiolect performance results can be carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "af168323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of distinct problems for each combo\n",
    "token_level_results_info = (\n",
    "    problem_summary\n",
    "    .groupby(['corpus', 'data_type', 'paraphrasing_model', 'scoring_model', 'min_token_size', 'target'])['problem']\n",
    "    .nunique()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# remove the annoying \"target\" header (it's df.columns.name)\n",
    "token_level_results_info.columns.name = None\n",
    "\n",
    "# force a clean RangeIndex\n",
    "token_level_results_info = token_level_results_info.reset_index(drop=True)\n",
    "\n",
    "# Now filter for at least one in each and keep the combos\n",
    "valid_rows = (\n",
    "    token_level_results_info.loc[\n",
    "        (token_level_results_info[True] >= 1) &\n",
    "        (token_level_results_info[False] >= 1),\n",
    "        ['corpus', 'data_type', 'paraphrasing_model', 'scoring_model', 'min_token_size']\n",
    "    ]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "afc4b806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>data_type</th>\n",
       "      <th>paraphrasing_model</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>min_token_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enron</td>\n",
       "      <td>test</td>\n",
       "      <td>ModernBERT-base</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus data_type paraphrasing_model scoring_model  min_token_size\n",
       "0  Enron      test    ModernBERT-base          gpt2              12\n",
       "1  Enron      test    ModernBERT-base          gpt2              13\n",
       "2  Enron      test    ModernBERT-base          gpt2              14\n",
       "3  Enron      test    ModernBERT-base          gpt2              15\n",
       "4  Enron      test    ModernBERT-base          gpt2              16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0c94975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now complete the join and get all valid problems\n",
    "min_token_level_summary = (\n",
    "    problem_summary\n",
    "    .merge(\n",
    "        valid_rows,\n",
    "        on=['corpus', 'data_type', 'paraphrasing_model', 'scoring_model', 'min_token_size'],\n",
    "        how='inner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d1904",
   "metadata": {},
   "source": [
    "#### Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2b2a77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['corpus', 'data_type', 'paraphrasing_model', 'scoring_model', 'min_token_size']\n",
    "\n",
    "# total distinct problems per group\n",
    "total = (\n",
    "    min_token_level_summary\n",
    "    .groupby(group_cols)['problem']\n",
    "    .nunique()\n",
    "    .rename('total_problems')\n",
    ")\n",
    "\n",
    "# distinct problems per group split by target True/False\n",
    "by_target = (\n",
    "    min_token_level_summary\n",
    "    .groupby(group_cols + ['target'])['problem']\n",
    "    .nunique()\n",
    "    .unstack('target', fill_value=0)\n",
    "    .reindex(columns=[True, False], fill_value=0)   # ensure both columns exist\n",
    "    .rename(columns={True: 'true_problems', False: 'false_problems'})\n",
    ")\n",
    "\n",
    "# final table + sort by the same groupby cols\n",
    "model_summary = (\n",
    "    total.to_frame()\n",
    "    .join(by_target)\n",
    "    .reset_index()\n",
    "    .sort_values(group_cols)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "14eecf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ModernBERT-base', 'gpt2', 'Enron', 'test'),\n",
       " ('ModernBERT-base', 'gpt2', 'Perverted Justice', 'test'),\n",
       " ('ModernBERT-large', 'gpt2', 'Enron', 'test'),\n",
       " ('ModernBERT-large', 'gpt2', 'Perverted Justice', 'test')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_combos = set(\n",
    "    min_token_level_summary [['paraphrasing_model', 'scoring_model', 'corpus', 'data_type']]\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "summary_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "86289396",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_token_level_summary.to_excel(agg_save_loc, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
