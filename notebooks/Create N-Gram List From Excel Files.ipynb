{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7bd658",
   "metadata": {},
   "source": [
    "# Create N-Gram List from Excel Files\n",
    "\n",
    "This notebook allows the user to enter a directory containing pre-processed Excel files after passing through an LLM in order to grab the distinct list of n-grams created when doing n-gram tracing. This will be used to filter out past results but also for future iterations this idea will be used prior to sending requests to an LLM.\n",
    "\n",
    "In the future i will process all of the documents in n-gram tracing and output a file similar to this containing all possible n-grams in common. Then i will create a filtered list to remove some before processing them next time around and keep iterating on this list with each corpus.\n",
    "\n",
    "Done to save time and money if using OpenAI as i feel the main 2-grams will be featured reguoarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4434322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10def25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = '/Volumes/BCross/paraphrase examples slurm/Wiki-test-auto/'\n",
    "\n",
    "output_path = \"/Volumes/BCross/paraphrase examples slurm/wiki-phrase-list-raw.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe35576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_distinct_references(doc_loc, sheet_name='no context'):\n",
    "    \"\"\"\n",
    "    Reads a single Excel sheet, extracts distinct reference phrases, \n",
    "    parses the tokens list, and sorts the output by token count and phrase length.\n",
    "    \"\"\"\n",
    "\n",
    "    # Only read the required columns for speed and memory efficiency\n",
    "    use_cols = ['phrase_type', 'phrase', 'tokens']\n",
    "\n",
    "    try:\n",
    "        no_context = pd.read_excel(doc_loc, sheet_name=sheet_name, usecols=use_cols)\n",
    "    except Exception as e:\n",
    "        # Return empty DataFrame if the file or sheet can't be read\n",
    "        print(f\"‚ö†Ô∏è Failed to read {doc_loc}: {e}\")\n",
    "        return pd.DataFrame(columns=['phrase', 'tokens', 'num_tokens'])\n",
    "\n",
    "    # Filter only the rows where phrase_type == 'reference'\n",
    "    references = no_context[no_context['phrase_type'] == 'reference']\n",
    "\n",
    "    # Remove duplicates and reset index\n",
    "    references = references[['phrase', 'tokens']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Safely parse stringified lists (e.g., \"['a','b']\") into Python lists\n",
    "    def parse_tokens(x):\n",
    "        try:\n",
    "            return ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    references['tokens'] = references['tokens'].map(parse_tokens)\n",
    "\n",
    "    # Count number of tokens in each list\n",
    "    references['num_tokens'] = references['tokens'].map(len)\n",
    "\n",
    "    # Also compute phrase length in characters (for secondary sorting)\n",
    "    references['phrase_len'] = references['phrase'].str.len()\n",
    "\n",
    "    # Sort by number of tokens first, then phrase length\n",
    "    sorted_refs = references.sort_values(by=['num_tokens', 'phrase_len']).reset_index(drop=True)\n",
    "\n",
    "    # Remove temporary sorting column before returning\n",
    "    return sorted_refs.drop(columns='phrase_len')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0662a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_ngrams_dir(doc_dir, sheet_name='no context'):\n",
    "    \"\"\"\n",
    "    Loops through all Excel files in a directory, extracts distinct reference phrases \n",
    "    from each file in parallel, merges them, and returns a sorted, deduplicated DataFrame.\n",
    "    Progress is shown as percentages (10%, 20%, ..., 100%).\n",
    "    \"\"\"\n",
    "\n",
    "    excel_dir = Path(doc_dir)\n",
    "\n",
    "    # Collect all Excel files (skip temporary lock files)\n",
    "    excel_files = sorted([f for f in excel_dir.glob(\"*.xlsx\") if not f.name.startswith(\"~$\")])\n",
    "    total_files = len(excel_files)\n",
    "    print(f\"üü¢ Processing {total_files} Excel files in parallel...\")\n",
    "\n",
    "    # Shared state for progress tracking\n",
    "    progress_state = {'count': 0, 'next_threshold': 10}\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    def load_and_track_progress(excel_path):\n",
    "        \"\"\"Loads and processes a single Excel file, updating progress.\"\"\"\n",
    "        try:\n",
    "            return get_sorted_distinct_references(excel_path, sheet_name=sheet_name)\n",
    "        finally:\n",
    "            with lock:\n",
    "                progress_state['count'] += 1\n",
    "                pct = (progress_state['count'] / total_files) * 100\n",
    "\n",
    "                # Print at clean 10% intervals\n",
    "                if pct >= progress_state['next_threshold']:\n",
    "                    print(f\"Progress: {int(progress_state['next_threshold'])}%\")\n",
    "                    progress_state['next_threshold'] += 10\n",
    "\n",
    "    # Run file processing in parallel\n",
    "    phrases_dataframe_list = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(load_and_track_progress, f) for f in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if not result.empty:\n",
    "                phrases_dataframe_list.append(result)\n",
    "\n",
    "    print(\"‚úÖ All files processed.\")\n",
    "\n",
    "    # Combine all results into one DataFrame\n",
    "    combined = pd.concat(phrases_dataframe_list, ignore_index=True)\n",
    "\n",
    "    # Convert lists to tuples so they can be hashed (for drop_duplicates)\n",
    "    combined['tokens'] = combined['tokens'].map(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "\n",
    "    # Drop duplicates across all files\n",
    "    combined = combined[['phrase', 'tokens', 'num_tokens']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Compute phrase length for sorting\n",
    "    combined['phrase_len'] = combined['phrase'].str.len()\n",
    "\n",
    "    # Sort by number of tokens first, then phrase length\n",
    "    sorted_combined = combined.sort_values(by=['num_tokens', 'phrase_len']).reset_index(drop=True)\n",
    "\n",
    "    # Drop helper column before returning\n",
    "    return sorted_combined.drop(columns='phrase_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = \"/Volumes/BCross/av_datasets_experiments/ngram_masking\"\n",
    "\n",
    "data_types = [\"test\", \"training\"]\n",
    "corpuses = [\"ACL\", \"Enron\", \"Perverted Justice\", \"StackExchange\",\n",
    "            \"The Telegraph\", \"TripAdvisor\", \"Wiki\"]\n",
    "paraphrasing_models = [\"ModernBERT-base\", \"ModernBERT-large\"]\n",
    "scoring_models = [\"gpt2\"]\n",
    "\n",
    "full_phrase_list = []\n",
    "\n",
    "for dt in data_types:\n",
    "    print(f\"Working on {dt} data\")\n",
    "    for cp in corpuses:\n",
    "        print(f\"Working on the {cp} corpus\")\n",
    "        for pm in paraphrasing_models:\n",
    "            print(f\"Working on the {pm} paraphrasing model\")\n",
    "            for sm in scoring_models:\n",
    "                print(f\"Working on the {sm} scoring model\")\n",
    "                \n",
    "                data_dir = f\"{base_data_dir}/{dt}/{cp}/{pm}/{sm} results/raw\"\n",
    "                \n",
    "                if not os.path.isdir(data_dir):\n",
    "                    print(f\"Skipping (missing): {data_dir}\")\n",
    "                    continue\n",
    "                \n",
    "                reference_phrases = get_sorted_ngrams_dir(data_dir)\n",
    "                \n",
    "                full_phrase_list.append(reference_phrases)\n",
    "                \n",
    "reference_ngrams = pd.concat(full_phrase_list, ignore_index=True)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026d78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on test data\n",
      "  Working on the ACL corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/ACL/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.036s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/ACL/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  ACL subtotal: 0.041s\n",
      "  Working on the Enron corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "üü¢ Processing 200 Excel files in parallel...\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 70%\n",
      "Progress: 80%\n",
      "Progress: 90%\n",
      "Progress: 100%\n",
      "‚úÖ All files processed.\n",
      "      Done: read=15.939s, combo_total=15.957s\n",
      "    ModernBERT-base subtotal: 15.957s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/Enron/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.008s\n",
      "  Enron subtotal: 15.965s\n",
      "  Working on the Perverted Justice corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/Perverted Justice/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.012s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/Perverted Justice/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  Perverted Justice subtotal: 0.016s\n",
      "  Working on the StackExchange corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/StackExchange/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.004s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/StackExchange/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  StackExchange subtotal: 0.008s\n",
      "  Working on the The Telegraph corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/The Telegraph/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.095s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/The Telegraph/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.005s\n",
      "  The Telegraph subtotal: 0.100s\n",
      "  Working on the TripAdvisor corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/TripAdvisor/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.004s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/TripAdvisor/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  TripAdvisor subtotal: 0.008s\n",
      "  Working on the Wiki corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/Wiki/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.004s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/test/Wiki/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.000s\n",
      "  Wiki subtotal: 0.004s\n",
      "test subtotal: 16.146s\n",
      "\n",
      "Working on training data\n",
      "  Working on the ACL corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/ACL/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.012s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/ACL/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  ACL subtotal: 0.016s\n",
      "  Working on the Enron corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/Enron/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.004s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/Enron/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  Enron subtotal: 0.008s\n",
      "  Working on the Perverted Justice corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/Perverted Justice/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.006s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/Perverted Justice/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.005s\n",
      "  Perverted Justice subtotal: 0.011s\n",
      "  Working on the StackExchange corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/StackExchange/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.004s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/StackExchange/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  StackExchange subtotal: 0.008s\n",
      "  Working on the The Telegraph corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/The Telegraph/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.005s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/The Telegraph/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  The Telegraph subtotal: 0.009s\n",
      "  Working on the TripAdvisor corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/TripAdvisor/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.004s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/TripAdvisor/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.004s\n",
      "  TripAdvisor subtotal: 0.008s\n",
      "  Working on the Wiki corpus\n",
      "    Working on the ModernBERT-base paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/Wiki/ModernBERT-base/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-base subtotal: 0.000s\n",
      "    Working on the ModernBERT-large paraphrasing model\n",
      "      Working on the gpt2 scoring model\n",
      "      Skipping (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking/training/Wiki/ModernBERT-large/gpt2 results/filtered_inc_rank\n",
      "    ModernBERT-large subtotal: 0.000s\n",
      "  Wiki subtotal: 0.000s\n",
      "training subtotal: 0.060s\n",
      "\n",
      "=== Summary ===\n",
      "Processed: 1\n",
      "Skipped:   27\n",
      "Concat:    0.000s\n",
      "Total:     16.207s\n"
     ]
    }
   ],
   "source": [
    "base_data_dir = \"/Volumes/BCross/av_datasets_experiments/ngram_masking\"\n",
    "\n",
    "data_types = [\"test\", \"training\"]\n",
    "corpuses = [\"ACL\", \"Enron\", \"Perverted Justice\", \"StackExchange\",\n",
    "            \"The Telegraph\", \"TripAdvisor\", \"Wiki\"]\n",
    "paraphrasing_models = [\"ModernBERT-base\", \"ModernBERT-large\"]\n",
    "scoring_models = [\"gpt2\"]\n",
    "\n",
    "full_phrase_list = []\n",
    "skipped = 0\n",
    "processed = 0\n",
    "\n",
    "t0_total = time.perf_counter()\n",
    "\n",
    "for dt in data_types:\n",
    "    t0_dt = time.perf_counter()\n",
    "    print(f\"\\nWorking on {dt} data\")\n",
    "\n",
    "    for cp in corpuses:\n",
    "        t0_cp = time.perf_counter()\n",
    "        print(f\"  Working on the {cp} corpus\")\n",
    "\n",
    "        for pm in paraphrasing_models:\n",
    "            t0_pm = time.perf_counter()\n",
    "            print(f\"    Working on the {pm} paraphrasing model\")\n",
    "\n",
    "            for sm in scoring_models:\n",
    "                t0_combo = time.perf_counter()\n",
    "                print(f\"      Working on the {sm} scoring model\")\n",
    "\n",
    "                # NOTE: keeps your intended \"gpt2 results/raw\" directory naming\n",
    "                data_dir = f\"{base_data_dir}/{dt}/{cp}/{pm}/{sm} results/filtered_inc_rank\"\n",
    "\n",
    "                if not os.path.isdir(data_dir):\n",
    "                    skipped += 1\n",
    "                    print(f\"      Skipping (missing): {data_dir}\")\n",
    "                    continue\n",
    "\n",
    "                t0_read = time.perf_counter()\n",
    "                reference_phrases = get_sorted_ngrams_dir(data_dir)\n",
    "                t1_read = time.perf_counter()\n",
    "\n",
    "                full_phrase_list.append(reference_phrases)\n",
    "                processed += 1\n",
    "\n",
    "                t1_combo = time.perf_counter()\n",
    "                print(\n",
    "                    f\"      Done: read={t1_read - t0_read:.3f}s, \"\n",
    "                    f\"combo_total={t1_combo - t0_combo:.3f}s\"\n",
    "                )\n",
    "\n",
    "            t1_pm = time.perf_counter()\n",
    "            print(f\"    {pm} subtotal: {t1_pm - t0_pm:.3f}s\")\n",
    "\n",
    "        t1_cp = time.perf_counter()\n",
    "        print(f\"  {cp} subtotal: {t1_cp - t0_cp:.3f}s\")\n",
    "\n",
    "    t1_dt = time.perf_counter()\n",
    "    print(f\"{dt} subtotal: {t1_dt - t0_dt:.3f}s\")\n",
    "\n",
    "t0_concat = time.perf_counter()\n",
    "reference_ngrams = (\n",
    "    pd.concat(full_phrase_list, ignore_index=True)\n",
    "    if full_phrase_list\n",
    "    else pd.DataFrame()\n",
    ")\n",
    "t1_concat = time.perf_counter()\n",
    "\n",
    "t1_total = time.perf_counter()\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Processed: {processed}\")\n",
    "print(f\"Skipped:   {skipped}\")\n",
    "print(f\"Concat:    {t1_concat - t0_concat:.3f}s\")\n",
    "print(f\"Total:     {t1_total - t0_total:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd158178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as a</td>\n",
       "      <td>(ƒ†as, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>on a</td>\n",
       "      <td>(ƒ†on, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to a</td>\n",
       "      <td>(ƒ†to, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be a</td>\n",
       "      <td>(ƒ†be, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in a</td>\n",
       "      <td>(ƒ†in, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>in the future</td>\n",
       "      <td>(ƒ†in, ƒ†the, ƒ†future)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>because of the</td>\n",
       "      <td>(ƒ†because, ƒ†of, ƒ†the)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>, i don't</td>\n",
       "      <td>(,, ƒ†i, ƒ†don, 't)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>i'm not sure</td>\n",
       "      <td>(ƒ†i, 'm, ƒ†not, ƒ†sure)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>so that we can</td>\n",
       "      <td>(ƒ†so, ƒ†that, ƒ†we, ƒ†can)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              phrase                   tokens  num_tokens\n",
       "0               as a                (ƒ†as, ƒ†a)           2\n",
       "1               on a                (ƒ†on, ƒ†a)           2\n",
       "2               to a                (ƒ†to, ƒ†a)           2\n",
       "3               be a                (ƒ†be, ƒ†a)           2\n",
       "4               in a                (ƒ†in, ƒ†a)           2\n",
       "..               ...                      ...         ...\n",
       "504    in the future     (ƒ†in, ƒ†the, ƒ†future)           3\n",
       "505   because of the    (ƒ†because, ƒ†of, ƒ†the)           3\n",
       "506        , i don't        (,, ƒ†i, ƒ†don, 't)           4\n",
       "507     i'm not sure    (ƒ†i, 'm, ƒ†not, ƒ†sure)           4\n",
       "508   so that we can  (ƒ†so, ƒ†that, ƒ†we, ƒ†can)           4\n",
       "\n",
       "[509 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6015f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Processing 661 Excel files in parallel...\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 70%\n",
      "Progress: 80%\n",
      "Progress: 90%\n",
      "Progress: 100%\n",
      "‚úÖ All files processed.\n"
     ]
    }
   ],
   "source": [
    "reference_phrases = get_sorted_ngrams_dir(doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c44ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 is</td>\n",
       "      <td>(7, ƒ†is)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s of</td>\n",
       "      <td>(s, ƒ†of)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s a</td>\n",
       "      <td>('s, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am</td>\n",
       "      <td>(i, ƒ†am)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'t a</td>\n",
       "      <td>('t, ƒ†a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>in the interest of not starting a flame war or...</td>\n",
       "      <td>(in, ƒ†the, ƒ†interest, ƒ†of, ƒ†not, ƒ†starting, ƒ†a...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>my advice to mr asquith is to stay away from w...</td>\n",
       "      <td>(my, ƒ†advice, ƒ†to, ƒ†mr, ƒ†as, qu, ith, ƒ†is, ƒ†to...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>.\\ni was unaware of wikipedia, as i do not ref...</td>\n",
       "      <td>(.ƒä, i, ƒ†was, ƒ†unaware, ƒ†of, ƒ†wikipedia, ,, ƒ†a...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>indeed, this is pure logic just think about th...</td>\n",
       "      <td>(inde, ed, ,, ƒ†this, ƒ†is, ƒ†pure, ƒ†logic, ƒ†just...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>while this does not involve sequencing the ent...</td>\n",
       "      <td>(while, ƒ†this, ƒ†does, ƒ†not, ƒ†involve, ƒ†sequenc...</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3026 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase  \\\n",
       "0                                                  7 is   \n",
       "1                                                  s of   \n",
       "2                                                  's a   \n",
       "3                                                  i am   \n",
       "4                                                  't a   \n",
       "...                                                 ...   \n",
       "3021  in the interest of not starting a flame war or...   \n",
       "3022  my advice to mr asquith is to stay away from w...   \n",
       "3023  .\\ni was unaware of wikipedia, as i do not ref...   \n",
       "3024  indeed, this is pure logic just think about th...   \n",
       "3025  while this does not involve sequencing the ent...   \n",
       "\n",
       "                                                 tokens  num_tokens  \n",
       "0                                              (7, ƒ†is)           2  \n",
       "1                                              (s, ƒ†of)           2  \n",
       "2                                              ('s, ƒ†a)           2  \n",
       "3                                              (i, ƒ†am)           2  \n",
       "4                                              ('t, ƒ†a)           2  \n",
       "...                                                 ...         ...  \n",
       "3021  (in, ƒ†the, ƒ†interest, ƒ†of, ƒ†not, ƒ†starting, ƒ†a...          72  \n",
       "3022  (my, ƒ†advice, ƒ†to, ƒ†mr, ƒ†as, qu, ith, ƒ†is, ƒ†to...          88  \n",
       "3023  (.ƒä, i, ƒ†was, ƒ†unaware, ƒ†of, ƒ†wikipedia, ,, ƒ†a...         154  \n",
       "3024  (inde, ed, ,, ƒ†this, ƒ†is, ƒ†pure, ƒ†logic, ƒ†just...         300  \n",
       "3025  (while, ƒ†this, ƒ†does, ƒ†not, ƒ†involve, ƒ†sequenc...         320  \n",
       "\n",
       "[3026 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae289f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_phrases.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "652d9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phrase_or_tokens_in_dir(doc_dir, sheet_name='no context', target=None):\n",
    "    \"\"\"\n",
    "    Searches through all Excel files in a directory (in parallel) \n",
    "    to find which ones contain a specific phrase or a specific list/tuple of tokens.\n",
    "    Progress is shown as percentages (10%, 20%, ..., 100%).\n",
    "    \"\"\"\n",
    "\n",
    "    if target is None:\n",
    "        raise ValueError(\"You must provide a target phrase or tuple of tokens.\")\n",
    "\n",
    "    # Determine if this is a token or phrase search\n",
    "    is_token_search = isinstance(target, (list, tuple))\n",
    "    target_list = list(target) if is_token_search else str(target)\n",
    "\n",
    "    excel_dir = Path(doc_dir)\n",
    "    excel_files = sorted([f for f in excel_dir.glob(\"*.xlsx\") if not f.name.startswith(\"~$\")])\n",
    "    total_files = len(excel_files)\n",
    "\n",
    "    print(f\"üîç Searching {total_files} files for {'tokens' if is_token_search else 'phrase'}: {target_list}\")\n",
    "\n",
    "    # Shared progress tracker\n",
    "    progress_state = {'count': 0, 'next_threshold': 10}\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    def check_file(excel_path):\n",
    "        \"\"\"Worker function for one file.\"\"\"\n",
    "        try:\n",
    "            df = get_sorted_distinct_references(excel_path, sheet_name=sheet_name)\n",
    "            if df.empty:\n",
    "                return None\n",
    "\n",
    "            # Token-based or phrase-based matching\n",
    "            if is_token_search:\n",
    "                token_tuples = set(df['tokens'].map(tuple))\n",
    "                if tuple(target_list) in token_tuples:\n",
    "                    return excel_path.name\n",
    "            else:\n",
    "                phrases_set = set(df['phrase'])\n",
    "                if target_list in phrases_set:\n",
    "                    return excel_path.name\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to process {excel_path.name}: {e}\")\n",
    "        finally:\n",
    "            with lock:\n",
    "                progress_state['count'] += 1\n",
    "                pct = (progress_state['count'] / total_files) * 100\n",
    "\n",
    "                # Print at clean 10% increments\n",
    "                if pct >= progress_state['next_threshold']:\n",
    "                    print(f\"Progress: {int(progress_state['next_threshold'])}%\")\n",
    "                    progress_state['next_threshold'] += 10\n",
    "\n",
    "        return None\n",
    "\n",
    "    matched_files = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(check_file, f) for f in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                matched_files.append(result)\n",
    "\n",
    "    print(\"‚úÖ Search complete.\")\n",
    "    return matched_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b44f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching 661 files for tokens: [',', 'ƒ†i', \"'d\"]\n",
      "Progress: 10%\n",
      "Progress: 20%\n",
      "Progress: 30%\n",
      "Progress: 40%\n",
      "Progress: 50%\n",
      "Progress: 60%\n",
      "Progress: 70%\n",
      "Progress: 80%\n",
      "Progress: 90%\n",
      "Progress: 100%\n",
      "‚úÖ Search complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jasper_deng_text_2 vs jasper_deng_text_4.xlsx',\n",
       " 'pinkampersand_text_2 vs pinkampersand_text_4.xlsx',\n",
       " 'pinkampersand_text_3 vs pinkampersand_text_4.xlsx',\n",
       " 'pinkampersand_text_3 vs pro_lick_text_1.xlsx',\n",
       " 'pro_lick_text_3 vs pro_lick_text_1.xlsx',\n",
       " 'stephenbuxton_text_1 vs stillstanding_247_text_5.xlsx']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_phrase_doc_list = find_phrase_or_tokens_in_dir(\n",
    "    doc_dir,\n",
    "    sheet_name='no context',\n",
    "    target=(',', 'ƒ†i', \"'d\")\n",
    "\n",
    ")\n",
    "common_phrase_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1ed68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
