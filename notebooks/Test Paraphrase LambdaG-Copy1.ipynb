{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a02b8e-cbcf-46e8-9842-95c3be0f741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/GitHub/av_distributions/my_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e714e642-89f9-46d1-85fe-e7ddbe5c17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from read_and_write_docs import read_jsonl, write_jsonl, read_rds\n",
    "from utils import apply_temp_doc_id, build_metadata_df\n",
    "from lambdaG import extract_ngrams, lambdaG_paraphrase, lambdaG, lambdaG_v2, lambdaG_max_similarity\n",
    "from performance import performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99c8908-f658-4752-9952-97de9ff1a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = \"/Volumes/BCross/datasets/author_verification\"\n",
    "\n",
    "data_type = \"training\"\n",
    "corpus = \"Enron\"\n",
    "\n",
    "model = \"Qwen2.5-1.5B-Instruct\"\n",
    "model_name = model.lower().replace(\"-\", \"_\")\n",
    "token_type = model\n",
    "\n",
    "known_loc = f\"{base_loc}/sentence_log_probs_datasets/{data_type}/{corpus}/known_sentence_logprobs_{model_name}.jsonl\"\n",
    "# known_loc = \"/Users/user/Documents/test_data/known_sentence_logprobs_qwen2.5_1.5b_instruct.jsonl\"\n",
    "known = read_jsonl(known_loc)\n",
    "known.rename(columns={'sentence': 'text'}, inplace=True)\n",
    "known = apply_temp_doc_id(known)\n",
    "known = known[known['num_tokens'] > 0]\n",
    "# known['perplexity'] = known['log_probs'].apply(compute_perplexity)\n",
    "\n",
    "unknown_loc = f\"{base_loc}/sentence_log_probs_datasets/{data_type}/{corpus}/unknown_sentence_logprobs_{model_name}.jsonl\"\n",
    "# unknown_loc = '/Users/user/Documents/test_data/unknown_sentence_logprobs_qwen2.5_1.5b_instruct.jsonl'\n",
    "unknown = read_jsonl(unknown_loc)\n",
    "unknown.rename(columns={'sentence': 'text'}, inplace=True)\n",
    "unknown = apply_temp_doc_id(unknown)\n",
    "unknown = unknown[unknown['num_tokens'] > 0]\n",
    "# unknown['perplexity'] = unknown['log_probs'].apply(compute_perplexity)\n",
    "\n",
    "metadata_loc = f\"{base_loc}/{data_type}/metadata.rds\"\n",
    "metadata_loc = \"/Users/user/Documents/test_data/metadata.rds\"\n",
    "metadata = read_rds(metadata_loc)\n",
    "filtered_metadata = metadata[metadata['corpus'] == corpus]\n",
    "agg_metadata = build_metadata_df(filtered_metadata, known, unknown)\n",
    "\n",
    "# Set an impostor location\n",
    "impostor_loc = \"/Volumes/BCross/datasets/author_verification/training/Wiki/Qwen_2.5_1.5B/gen_t_1.5_tp_0.9/top_impostors_tokenized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805a8438-8a22-413c-a0bb-4e9850aacdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>orig_doc_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>med_log_prob</th>\n",
       "      <th>differences</th>\n",
       "      <th>abs_differences</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>sum_log_prob</th>\n",
       "      <th>avg_log_prob</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andy_zipper_mail_1</td>\n",
       "      <td>known [Andy.zipper - Mail_1].txt</td>\n",
       "      <td>Enron</td>\n",
       "      <td>1</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>known</td>\n",
       "      <td>And I guess we simply weren't prepared for thi...</td>\n",
       "      <td>[And, I, guess, we, simply, weren, 't, prepare...</td>\n",
       "      <td>[-12.659452438354492, -4.494169235229492, -4.5...</td>\n",
       "      <td>[-18.545480728149414, -18.545480728149414, -18...</td>\n",
       "      <td>[5.886028289794922, 14.051311492919922, 14.428...</td>\n",
       "      <td>[5.886028289794922, 14.051311492919922, 14.428...</td>\n",
       "      <td>16</td>\n",
       "      <td>-72.019607</td>\n",
       "      <td>-4.501225</td>\n",
       "      <td>15.877056</td>\n",
       "      <td>15.877056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andy_zipper_mail_1</td>\n",
       "      <td>known [Andy.zipper - Mail_1].txt</td>\n",
       "      <td>Enron</td>\n",
       "      <td>2</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>known</td>\n",
       "      <td>Before military police restored order, thousan...</td>\n",
       "      <td>[Before, military, police, restored, order, ,,...</td>\n",
       "      <td>[-14.579527854919434, -11.595590591430664, -4....</td>\n",
       "      <td>[-19.1412410736084, -19.1412410736084, -22.459...</td>\n",
       "      <td>[4.561713218688965, 7.545650482177734, 18.0961...</td>\n",
       "      <td>[4.561713218688965, 7.545650482177734, 18.0961...</td>\n",
       "      <td>28</td>\n",
       "      <td>-125.616024</td>\n",
       "      <td>-4.486287</td>\n",
       "      <td>17.655718</td>\n",
       "      <td>17.655718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc_id                       orig_doc_id corpus  chunk_id  \\\n",
       "0  andy_zipper_mail_1  known [Andy.zipper - Mail_1].txt  Enron         1   \n",
       "1  andy_zipper_mail_1  known [Andy.zipper - Mail_1].txt  Enron         2   \n",
       "\n",
       "        author texttype                                               text  \\\n",
       "0  Andy.zipper    known  And I guess we simply weren't prepared for thi...   \n",
       "1  Andy.zipper    known  Before military police restored order, thousan...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [And, I, guess, we, simply, weren, 't, prepare...   \n",
       "1  [Before, military, police, restored, order, ,,...   \n",
       "\n",
       "                                           log_probs  \\\n",
       "0  [-12.659452438354492, -4.494169235229492, -4.5...   \n",
       "1  [-14.579527854919434, -11.595590591430664, -4....   \n",
       "\n",
       "                                        med_log_prob  \\\n",
       "0  [-18.545480728149414, -18.545480728149414, -18...   \n",
       "1  [-19.1412410736084, -19.1412410736084, -22.459...   \n",
       "\n",
       "                                         differences  \\\n",
       "0  [5.886028289794922, 14.051311492919922, 14.428...   \n",
       "1  [4.561713218688965, 7.545650482177734, 18.0961...   \n",
       "\n",
       "                                     abs_differences  num_tokens  \\\n",
       "0  [5.886028289794922, 14.051311492919922, 14.428...          16   \n",
       "1  [4.561713218688965, 7.545650482177734, 18.0961...          28   \n",
       "\n",
       "   sum_log_prob  avg_log_prob  mean_diff  mean_abs_diff  \n",
       "0    -72.019607     -4.501225  15.877056      15.877056  \n",
       "1   -125.616024     -4.486287  17.655718      17.655718  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb9e7e0-fde8-4059-967b-32c40c91d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_filtered = known[known['author'].isin(['Akuri', '142.196.88.228'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c61b07-542b-4f23-86de-72f6d2269763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_column(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str = 'text',\n",
    "    embedding_column: str = 'embedding',\n",
    "    model_name: str = 'all-MiniLM-L6-v2',\n",
    "    batch_size: int = 32,\n",
    "    show_progress_bar: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Embed a text column of a DataFrame using a Hugging Face embedding model.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing the text column.\n",
    "        text_column (str): Name of the text column to embed.\n",
    "        embedding_column (str): Name of the new column to store embeddings.\n",
    "        model_name (str): Hugging Face model name (e.g., 'all-MiniLM-L6-v2').\n",
    "        batch_size (int): Batch size for embedding.\n",
    "        show_progress_bar (bool): Whether to show a progress bar during embedding.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with an added column of embeddings.\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Text column '{text_column}' not found in DataFrame.\")\n",
    "\n",
    "    # Work on a copy to avoid SettingWithCopyWarning\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Initialize the embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Convert text values to string and collect for batching\n",
    "    texts = df_copy[text_column].astype(str).tolist()\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=show_progress_bar\n",
    "    )\n",
    "\n",
    "    # Assign embeddings as list of floats to avoid numpy 2D assignment issues\n",
    "    df_copy[embedding_column] = embeddings.tolist()\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090ed1a1-630b-4978-8d23-30b68cd7e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████| 142/142 [00:04<00:00, 33.62it/s]\n",
      "Batches: 100%|██████████████████████████████████| 46/46 [00:02<00:00, 22.57it/s]\n"
     ]
    }
   ],
   "source": [
    "known_embedded = embed_text_column(known)\n",
    "# known_filtered_embedded = embed_text_column(known_filtered)\n",
    "unknown_embedded = embed_text_column(unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6de1bc-3d8e-441d-a8b9-588fa706b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    There are 2 known author(s) and 4 problem(s) in the dataset.\n",
      "        Working on problem 1 of 4: 142.196.88.228 vs 142.196.88.228\n",
      "        Working on problem 2 of 4: 142.196.88.228 vs Aban1313\n",
      "        Working on problem 3 of 4: Akuri vs Akuri\n",
      "        Working on problem 4 of 4: Akuri vs AlanBarnet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142.196.88.228 vs 142.196.88.228</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>True</td>\n",
       "      <td>23662.776835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.196.88.228 vs Aban1313</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>Aban1313</td>\n",
       "      <td>False</td>\n",
       "      <td>-8618.878281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akuri vs Akuri</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>True</td>\n",
       "      <td>17237.168861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akuri vs AlanBarnet</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>AlanBarnet</td>\n",
       "      <td>False</td>\n",
       "      <td>-3905.769088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            problem    known_author  unknown_author  target  \\\n",
       "0  142.196.88.228 vs 142.196.88.228  142.196.88.228  142.196.88.228    True   \n",
       "1        142.196.88.228 vs Aban1313  142.196.88.228        Aban1313   False   \n",
       "2                    Akuri vs Akuri           Akuri           Akuri    True   \n",
       "3               Akuri vs AlanBarnet           Akuri      AlanBarnet   False   \n",
       "\n",
       "          score  \n",
       "0  23662.776835  \n",
       "1  -8618.878281  \n",
       "2  17237.168861  \n",
       "3  -3905.769088  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambdaG(unknown, known_filtered, known, metadata=agg_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708fc33b-0181-48c6-b696-494f5bd8a783",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'known_filtered_embedded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_res = lambdaG_max_similarity(unknown_embedded, \u001b[43mknown_filtered_embedded\u001b[49m, known_embedded, metadata=agg_metadata)\n",
      "\u001b[31mNameError\u001b[39m: name 'known_filtered_embedded' is not defined"
     ]
    }
   ],
   "source": [
    "test_res = lambdaG_max_similarity(unknown_embedded, known_filtered_embedded, known_embedded, metadata=agg_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd5701-7737-41be-8b84-f0646fe9a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambdaG_v2(unknown, known_filtered, known, metadata=agg_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6fa3c-82b5-41e7-931e-a7f54b5f144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_res = lambdaG_paraphrase(unknown, known_filtered, metadata=agg_metadata, impostor_loc=impostor_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d466dca8-9964-4ab2-8136-eb9de48c2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142.196.88.228 vs 142.196.88.228</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>True</td>\n",
       "      <td>22672.086886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.196.88.228 vs Aban1313</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>Aban1313</td>\n",
       "      <td>False</td>\n",
       "      <td>-6832.770557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akuri vs Akuri</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>True</td>\n",
       "      <td>14516.544497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akuri vs AlanBarnet</td>\n",
       "      <td>Akuri</td>\n",
       "      <td>AlanBarnet</td>\n",
       "      <td>False</td>\n",
       "      <td>-4207.973023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            problem    known_author  unknown_author  target  \\\n",
       "0  142.196.88.228 vs 142.196.88.228  142.196.88.228  142.196.88.228    True   \n",
       "1        142.196.88.228 vs Aban1313  142.196.88.228        Aban1313   False   \n",
       "2                    Akuri vs Akuri           Akuri           Akuri    True   \n",
       "3               Akuri vs AlanBarnet           Akuri      AlanBarnet   False   \n",
       "\n",
       "          score  \n",
       "0  22672.086886  \n",
       "1  -6832.770557  \n",
       "2  14516.544497  \n",
       "3  -4207.973023  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d94bf3fc-3401-4601-a66d-ca30c6694c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1\n",
      "    There are 32 known author(s) and 64 problem(s) in the dataset.\n",
      "        Working on problem 1 of 64: Andy.zipper vs Andy.zipper\n",
      "        Working on problem 2 of 64: Andy.zipper vs Barry.tycholiz\n",
      "        Working on problem 3 of 64: Barry.tycholiz vs Barry.tycholiz\n",
      "        Working on problem 4 of 64: Barry.tycholiz vs Benjamin.rogers\n",
      "        Working on problem 5 of 64: Benjamin.rogers vs Benjamin.rogers\n",
      "        Working on problem 6 of 64: Benjamin.rogers vs Bill.williams\n",
      "        Working on problem 7 of 64: Bill.williams vs Bill.williams\n",
      "        Working on problem 8 of 64: Bill.williams vs Cara.semperger\n",
      "        Working on problem 9 of 64: Cara.semperger vs Cara.semperger\n",
      "        Working on problem 10 of 64: Cara.semperger vs Carol.clair\n",
      "        Working on problem 11 of 64: Carol.clair vs Carol.clair\n",
      "        Working on problem 12 of 64: Carol.clair vs Chris.dorland\n",
      "        Working on problem 13 of 64: Chris.dorland vs Chris.dorland\n",
      "        Working on problem 14 of 64: Chris.dorland vs Cooper.richey\n",
      "        Working on problem 15 of 64: Cooper.richey vs Cooper.richey\n",
      "        Working on problem 16 of 64: Cooper.richey vs D.steffes\n",
      "        Working on problem 17 of 64: D.steffes vs D.steffes\n",
      "        Working on problem 18 of 64: D.steffes vs D.thomas\n",
      "        Working on problem 19 of 64: D.thomas vs D.thomas\n",
      "        Working on problem 20 of 64: D.thomas vs Dan.hyvl\n",
      "        Working on problem 21 of 64: Dan.hyvl vs Dan.hyvl\n",
      "        Working on problem 22 of 64: Dan.hyvl vs Dana.davis\n",
      "        Working on problem 23 of 64: Dana.davis vs Dana.davis\n",
      "        Working on problem 24 of 64: Dana.davis vs Daren.farmer\n",
      "        Working on problem 25 of 64: Daren.farmer vs Daren.farmer\n",
      "        Working on problem 26 of 64: Daren.farmer vs Darrell.schoolcraft\n",
      "        Working on problem 27 of 64: Darrell.schoolcraft vs Darrell.schoolcraft\n",
      "        Working on problem 28 of 64: Darrell.schoolcraft vs Darron.giron\n",
      "        Working on problem 29 of 64: Darron.giron vs Darron.giron\n",
      "        Working on problem 30 of 64: Darron.giron vs David.delainey\n",
      "        Working on problem 31 of 64: David.delainey vs David.delainey\n",
      "        Working on problem 32 of 64: David.delainey vs Debra.perlingiere\n",
      "        Working on problem 33 of 64: Debra.perlingiere vs Debra.perlingiere\n",
      "        Working on problem 34 of 64: Debra.perlingiere vs Drew.fossum\n",
      "        Working on problem 35 of 64: Drew.fossum vs Drew.fossum\n",
      "        Working on problem 36 of 64: Drew.fossum vs Elizabeth.sager\n",
      "        Working on problem 37 of 64: Elizabeth.sager vs Elizabeth.sager\n",
      "        Working on problem 38 of 64: Elizabeth.sager vs Errol.mclaughlin\n",
      "        Working on problem 39 of 64: Errol.mclaughlin vs Errol.mclaughlin\n",
      "        Working on problem 40 of 64: Errol.mclaughlin vs Gerald.nemec\n",
      "        Working on problem 41 of 64: Gerald.nemec vs Gerald.nemec\n",
      "        Working on problem 42 of 64: Gerald.nemec vs James.derrick\n",
      "        Working on problem 43 of 64: James.derrick vs James.derrick\n",
      "        Working on problem 44 of 64: James.derrick vs Jane.tholt\n",
      "        Working on problem 45 of 64: Jane.tholt vs Jane.tholt\n",
      "        Working on problem 46 of 64: Jane.tholt vs Janette.elbertson\n",
      "        Working on problem 47 of 64: Janette.elbertson vs Janette.elbertson\n",
      "        Working on problem 48 of 64: Janette.elbertson vs Jeff.dasovich\n",
      "        Working on problem 49 of 64: Jeff.dasovich vs Jeff.dasovich\n",
      "        Working on problem 50 of 64: Jeff.dasovich vs Jeff.skilling\n",
      "        Working on problem 51 of 64: Jeff.skilling vs Jeff.skilling\n",
      "        Working on problem 52 of 64: Jeff.skilling vs Jeffrey.shankman\n",
      "        Working on problem 53 of 64: Jeffrey.shankman vs Jeffrey.shankman\n",
      "        Working on problem 54 of 64: Jeffrey.shankman vs Joannie.williamson\n",
      "        Working on problem 55 of 64: Joannie.williamson vs Joannie.williamson\n",
      "        Working on problem 56 of 64: Joannie.williamson vs John.arnold\n",
      "        Working on problem 57 of 64: John.arnold vs John.arnold\n",
      "        Working on problem 58 of 64: John.arnold vs K.allen\n",
      "        Working on problem 59 of 64: K.allen vs K.allen\n",
      "        Working on problem 60 of 64: K.allen vs Kam.keiser\n",
      "        Working on problem 61 of 64: Kam.keiser vs Kam.keiser\n",
      "        Working on problem 62 of 64: Kam.keiser vs Kate.symes\n",
      "        Working on problem 63 of 64: Kate.symes vs Andy.zipper\n",
      "        Working on problem 64 of 64: Kate.symes vs Kate.symes\n",
      "Repetition 2\n",
      "    There are 32 known author(s) and 64 problem(s) in the dataset.\n",
      "        Working on problem 1 of 64: Andy.zipper vs Andy.zipper\n",
      "        Working on problem 2 of 64: Andy.zipper vs Barry.tycholiz\n",
      "        Working on problem 3 of 64: Barry.tycholiz vs Barry.tycholiz\n",
      "        Working on problem 4 of 64: Barry.tycholiz vs Benjamin.rogers\n",
      "        Working on problem 5 of 64: Benjamin.rogers vs Benjamin.rogers\n",
      "        Working on problem 6 of 64: Benjamin.rogers vs Bill.williams\n",
      "        Working on problem 7 of 64: Bill.williams vs Bill.williams\n",
      "        Working on problem 8 of 64: Bill.williams vs Cara.semperger\n",
      "        Working on problem 9 of 64: Cara.semperger vs Cara.semperger\n",
      "        Working on problem 10 of 64: Cara.semperger vs Carol.clair\n",
      "        Working on problem 11 of 64: Carol.clair vs Carol.clair\n",
      "        Working on problem 12 of 64: Carol.clair vs Chris.dorland\n",
      "        Working on problem 13 of 64: Chris.dorland vs Chris.dorland\n",
      "        Working on problem 14 of 64: Chris.dorland vs Cooper.richey\n",
      "        Working on problem 15 of 64: Cooper.richey vs Cooper.richey\n",
      "        Working on problem 16 of 64: Cooper.richey vs D.steffes\n",
      "        Working on problem 17 of 64: D.steffes vs D.steffes\n",
      "        Working on problem 18 of 64: D.steffes vs D.thomas\n",
      "        Working on problem 19 of 64: D.thomas vs D.thomas\n",
      "        Working on problem 20 of 64: D.thomas vs Dan.hyvl\n",
      "        Working on problem 21 of 64: Dan.hyvl vs Dan.hyvl\n",
      "        Working on problem 22 of 64: Dan.hyvl vs Dana.davis\n",
      "        Working on problem 23 of 64: Dana.davis vs Dana.davis\n",
      "        Working on problem 24 of 64: Dana.davis vs Daren.farmer\n",
      "        Working on problem 25 of 64: Daren.farmer vs Daren.farmer\n",
      "        Working on problem 26 of 64: Daren.farmer vs Darrell.schoolcraft\n",
      "        Working on problem 27 of 64: Darrell.schoolcraft vs Darrell.schoolcraft\n",
      "        Working on problem 28 of 64: Darrell.schoolcraft vs Darron.giron\n",
      "        Working on problem 29 of 64: Darron.giron vs Darron.giron\n",
      "        Working on problem 30 of 64: Darron.giron vs David.delainey\n",
      "        Working on problem 31 of 64: David.delainey vs David.delainey\n",
      "        Working on problem 32 of 64: David.delainey vs Debra.perlingiere\n",
      "        Working on problem 33 of 64: Debra.perlingiere vs Debra.perlingiere\n",
      "        Working on problem 34 of 64: Debra.perlingiere vs Drew.fossum\n",
      "        Working on problem 35 of 64: Drew.fossum vs Drew.fossum\n",
      "        Working on problem 36 of 64: Drew.fossum vs Elizabeth.sager\n",
      "        Working on problem 37 of 64: Elizabeth.sager vs Elizabeth.sager\n",
      "        Working on problem 38 of 64: Elizabeth.sager vs Errol.mclaughlin\n",
      "        Working on problem 39 of 64: Errol.mclaughlin vs Errol.mclaughlin\n",
      "        Working on problem 40 of 64: Errol.mclaughlin vs Gerald.nemec\n",
      "        Working on problem 41 of 64: Gerald.nemec vs Gerald.nemec\n",
      "        Working on problem 42 of 64: Gerald.nemec vs James.derrick\n",
      "        Working on problem 43 of 64: James.derrick vs James.derrick\n",
      "        Working on problem 44 of 64: James.derrick vs Jane.tholt\n",
      "        Working on problem 45 of 64: Jane.tholt vs Jane.tholt\n",
      "        Working on problem 46 of 64: Jane.tholt vs Janette.elbertson\n",
      "        Working on problem 47 of 64: Janette.elbertson vs Janette.elbertson\n",
      "        Working on problem 48 of 64: Janette.elbertson vs Jeff.dasovich\n",
      "        Working on problem 49 of 64: Jeff.dasovich vs Jeff.dasovich\n",
      "        Working on problem 50 of 64: Jeff.dasovich vs Jeff.skilling\n",
      "        Working on problem 51 of 64: Jeff.skilling vs Jeff.skilling\n",
      "        Working on problem 52 of 64: Jeff.skilling vs Jeffrey.shankman\n",
      "        Working on problem 53 of 64: Jeffrey.shankman vs Jeffrey.shankman\n",
      "        Working on problem 54 of 64: Jeffrey.shankman vs Joannie.williamson\n",
      "        Working on problem 55 of 64: Joannie.williamson vs Joannie.williamson\n",
      "        Working on problem 56 of 64: Joannie.williamson vs John.arnold\n",
      "        Working on problem 57 of 64: John.arnold vs John.arnold\n",
      "        Working on problem 58 of 64: John.arnold vs K.allen\n",
      "        Working on problem 59 of 64: K.allen vs K.allen\n",
      "        Working on problem 60 of 64: K.allen vs Kam.keiser\n",
      "        Working on problem 61 of 64: Kam.keiser vs Kam.keiser\n",
      "        Working on problem 62 of 64: Kam.keiser vs Kate.symes\n",
      "        Working on problem 63 of 64: Kate.symes vs Andy.zipper\n",
      "        Working on problem 64 of 64: Kate.symes vs Kate.symes\n",
      "Repetition 3\n",
      "    There are 32 known author(s) and 64 problem(s) in the dataset.\n",
      "        Working on problem 1 of 64: Andy.zipper vs Andy.zipper\n",
      "        Working on problem 2 of 64: Andy.zipper vs Barry.tycholiz\n",
      "        Working on problem 3 of 64: Barry.tycholiz vs Barry.tycholiz\n",
      "        Working on problem 4 of 64: Barry.tycholiz vs Benjamin.rogers\n",
      "        Working on problem 5 of 64: Benjamin.rogers vs Benjamin.rogers\n",
      "        Working on problem 6 of 64: Benjamin.rogers vs Bill.williams\n",
      "        Working on problem 7 of 64: Bill.williams vs Bill.williams\n",
      "        Working on problem 8 of 64: Bill.williams vs Cara.semperger\n",
      "        Working on problem 9 of 64: Cara.semperger vs Cara.semperger\n",
      "        Working on problem 10 of 64: Cara.semperger vs Carol.clair\n",
      "        Working on problem 11 of 64: Carol.clair vs Carol.clair\n",
      "        Working on problem 12 of 64: Carol.clair vs Chris.dorland\n",
      "        Working on problem 13 of 64: Chris.dorland vs Chris.dorland\n",
      "        Working on problem 14 of 64: Chris.dorland vs Cooper.richey\n",
      "        Working on problem 15 of 64: Cooper.richey vs Cooper.richey\n",
      "        Working on problem 16 of 64: Cooper.richey vs D.steffes\n",
      "        Working on problem 17 of 64: D.steffes vs D.steffes\n",
      "        Working on problem 18 of 64: D.steffes vs D.thomas\n",
      "        Working on problem 19 of 64: D.thomas vs D.thomas\n",
      "        Working on problem 20 of 64: D.thomas vs Dan.hyvl\n",
      "        Working on problem 21 of 64: Dan.hyvl vs Dan.hyvl\n",
      "        Working on problem 22 of 64: Dan.hyvl vs Dana.davis\n",
      "        Working on problem 23 of 64: Dana.davis vs Dana.davis\n",
      "        Working on problem 24 of 64: Dana.davis vs Daren.farmer\n",
      "        Working on problem 25 of 64: Daren.farmer vs Daren.farmer\n",
      "        Working on problem 26 of 64: Daren.farmer vs Darrell.schoolcraft\n",
      "        Working on problem 27 of 64: Darrell.schoolcraft vs Darrell.schoolcraft\n",
      "        Working on problem 28 of 64: Darrell.schoolcraft vs Darron.giron\n",
      "        Working on problem 29 of 64: Darron.giron vs Darron.giron\n",
      "        Working on problem 30 of 64: Darron.giron vs David.delainey\n",
      "        Working on problem 31 of 64: David.delainey vs David.delainey\n",
      "        Working on problem 32 of 64: David.delainey vs Debra.perlingiere\n",
      "        Working on problem 33 of 64: Debra.perlingiere vs Debra.perlingiere\n",
      "        Working on problem 34 of 64: Debra.perlingiere vs Drew.fossum\n",
      "        Working on problem 35 of 64: Drew.fossum vs Drew.fossum\n",
      "        Working on problem 36 of 64: Drew.fossum vs Elizabeth.sager\n",
      "        Working on problem 37 of 64: Elizabeth.sager vs Elizabeth.sager\n",
      "        Working on problem 38 of 64: Elizabeth.sager vs Errol.mclaughlin\n",
      "        Working on problem 39 of 64: Errol.mclaughlin vs Errol.mclaughlin\n",
      "        Working on problem 40 of 64: Errol.mclaughlin vs Gerald.nemec\n",
      "        Working on problem 41 of 64: Gerald.nemec vs Gerald.nemec\n",
      "        Working on problem 42 of 64: Gerald.nemec vs James.derrick\n",
      "        Working on problem 43 of 64: James.derrick vs James.derrick\n",
      "        Working on problem 44 of 64: James.derrick vs Jane.tholt\n",
      "        Working on problem 45 of 64: Jane.tholt vs Jane.tholt\n",
      "        Working on problem 46 of 64: Jane.tholt vs Janette.elbertson\n",
      "        Working on problem 47 of 64: Janette.elbertson vs Janette.elbertson\n",
      "        Working on problem 48 of 64: Janette.elbertson vs Jeff.dasovich\n",
      "        Working on problem 49 of 64: Jeff.dasovich vs Jeff.dasovich\n",
      "        Working on problem 50 of 64: Jeff.dasovich vs Jeff.skilling\n",
      "        Working on problem 51 of 64: Jeff.skilling vs Jeff.skilling\n",
      "        Working on problem 52 of 64: Jeff.skilling vs Jeffrey.shankman\n",
      "        Working on problem 53 of 64: Jeffrey.shankman vs Jeffrey.shankman\n",
      "        Working on problem 54 of 64: Jeffrey.shankman vs Joannie.williamson\n",
      "        Working on problem 55 of 64: Joannie.williamson vs Joannie.williamson\n",
      "        Working on problem 56 of 64: Joannie.williamson vs John.arnold\n",
      "        Working on problem 57 of 64: John.arnold vs John.arnold\n",
      "        Working on problem 58 of 64: John.arnold vs K.allen\n",
      "        Working on problem 59 of 64: K.allen vs K.allen\n",
      "        Working on problem 60 of 64: K.allen vs Kam.keiser\n",
      "        Working on problem 61 of 64: Kam.keiser vs Kam.keiser\n",
      "        Working on problem 62 of 64: Kam.keiser vs Kate.symes\n",
      "        Working on problem 63 of 64: Kate.symes vs Andy.zipper\n",
      "        Working on problem 64 of 64: Kate.symes vs Kate.symes\n",
      "Repetition 4\n",
      "    There are 32 known author(s) and 64 problem(s) in the dataset.\n",
      "        Working on problem 1 of 64: Andy.zipper vs Andy.zipper\n",
      "        Working on problem 2 of 64: Andy.zipper vs Barry.tycholiz\n",
      "        Working on problem 3 of 64: Barry.tycholiz vs Barry.tycholiz\n",
      "        Working on problem 4 of 64: Barry.tycholiz vs Benjamin.rogers\n",
      "        Working on problem 5 of 64: Benjamin.rogers vs Benjamin.rogers\n",
      "        Working on problem 6 of 64: Benjamin.rogers vs Bill.williams\n",
      "        Working on problem 7 of 64: Bill.williams vs Bill.williams\n",
      "        Working on problem 8 of 64: Bill.williams vs Cara.semperger\n",
      "        Working on problem 9 of 64: Cara.semperger vs Cara.semperger\n",
      "        Working on problem 10 of 64: Cara.semperger vs Carol.clair\n",
      "        Working on problem 11 of 64: Carol.clair vs Carol.clair\n",
      "        Working on problem 12 of 64: Carol.clair vs Chris.dorland\n",
      "        Working on problem 13 of 64: Chris.dorland vs Chris.dorland\n",
      "        Working on problem 14 of 64: Chris.dorland vs Cooper.richey\n",
      "        Working on problem 15 of 64: Cooper.richey vs Cooper.richey\n",
      "        Working on problem 16 of 64: Cooper.richey vs D.steffes\n",
      "        Working on problem 17 of 64: D.steffes vs D.steffes\n",
      "        Working on problem 18 of 64: D.steffes vs D.thomas\n",
      "        Working on problem 19 of 64: D.thomas vs D.thomas\n",
      "        Working on problem 20 of 64: D.thomas vs Dan.hyvl\n",
      "        Working on problem 21 of 64: Dan.hyvl vs Dan.hyvl\n",
      "        Working on problem 22 of 64: Dan.hyvl vs Dana.davis\n",
      "        Working on problem 23 of 64: Dana.davis vs Dana.davis\n",
      "        Working on problem 24 of 64: Dana.davis vs Daren.farmer\n",
      "        Working on problem 25 of 64: Daren.farmer vs Daren.farmer\n",
      "        Working on problem 26 of 64: Daren.farmer vs Darrell.schoolcraft\n",
      "        Working on problem 27 of 64: Darrell.schoolcraft vs Darrell.schoolcraft\n",
      "        Working on problem 28 of 64: Darrell.schoolcraft vs Darron.giron\n",
      "        Working on problem 29 of 64: Darron.giron vs Darron.giron\n",
      "        Working on problem 30 of 64: Darron.giron vs David.delainey\n",
      "        Working on problem 31 of 64: David.delainey vs David.delainey\n",
      "        Working on problem 32 of 64: David.delainey vs Debra.perlingiere\n",
      "        Working on problem 33 of 64: Debra.perlingiere vs Debra.perlingiere\n",
      "        Working on problem 34 of 64: Debra.perlingiere vs Drew.fossum\n",
      "        Working on problem 35 of 64: Drew.fossum vs Drew.fossum\n",
      "        Working on problem 36 of 64: Drew.fossum vs Elizabeth.sager\n",
      "        Working on problem 37 of 64: Elizabeth.sager vs Elizabeth.sager\n",
      "        Working on problem 38 of 64: Elizabeth.sager vs Errol.mclaughlin\n",
      "        Working on problem 39 of 64: Errol.mclaughlin vs Errol.mclaughlin\n",
      "        Working on problem 40 of 64: Errol.mclaughlin vs Gerald.nemec\n",
      "        Working on problem 41 of 64: Gerald.nemec vs Gerald.nemec\n",
      "        Working on problem 42 of 64: Gerald.nemec vs James.derrick\n",
      "        Working on problem 43 of 64: James.derrick vs James.derrick\n",
      "        Working on problem 44 of 64: James.derrick vs Jane.tholt\n",
      "        Working on problem 45 of 64: Jane.tholt vs Jane.tholt\n",
      "        Working on problem 46 of 64: Jane.tholt vs Janette.elbertson\n",
      "        Working on problem 47 of 64: Janette.elbertson vs Janette.elbertson\n",
      "        Working on problem 48 of 64: Janette.elbertson vs Jeff.dasovich\n",
      "        Working on problem 49 of 64: Jeff.dasovich vs Jeff.dasovich\n",
      "        Working on problem 50 of 64: Jeff.dasovich vs Jeff.skilling\n",
      "        Working on problem 51 of 64: Jeff.skilling vs Jeff.skilling\n",
      "        Working on problem 52 of 64: Jeff.skilling vs Jeffrey.shankman\n",
      "        Working on problem 53 of 64: Jeffrey.shankman vs Jeffrey.shankman\n",
      "        Working on problem 54 of 64: Jeffrey.shankman vs Joannie.williamson\n",
      "        Working on problem 55 of 64: Joannie.williamson vs Joannie.williamson\n",
      "        Working on problem 56 of 64: Joannie.williamson vs John.arnold\n",
      "        Working on problem 57 of 64: John.arnold vs John.arnold\n",
      "        Working on problem 58 of 64: John.arnold vs K.allen\n",
      "        Working on problem 59 of 64: K.allen vs K.allen\n",
      "        Working on problem 60 of 64: K.allen vs Kam.keiser\n",
      "        Working on problem 61 of 64: Kam.keiser vs Kam.keiser\n",
      "        Working on problem 62 of 64: Kam.keiser vs Kate.symes\n",
      "        Working on problem 63 of 64: Kate.symes vs Andy.zipper\n",
      "        Working on problem 64 of 64: Kate.symes vs Kate.symes\n",
      "Repetition 5\n",
      "    There are 32 known author(s) and 64 problem(s) in the dataset.\n",
      "        Working on problem 1 of 64: Andy.zipper vs Andy.zipper\n",
      "        Working on problem 2 of 64: Andy.zipper vs Barry.tycholiz\n",
      "        Working on problem 3 of 64: Barry.tycholiz vs Barry.tycholiz\n",
      "        Working on problem 4 of 64: Barry.tycholiz vs Benjamin.rogers\n",
      "        Working on problem 5 of 64: Benjamin.rogers vs Benjamin.rogers\n",
      "        Working on problem 6 of 64: Benjamin.rogers vs Bill.williams\n",
      "        Working on problem 7 of 64: Bill.williams vs Bill.williams\n",
      "        Working on problem 8 of 64: Bill.williams vs Cara.semperger\n",
      "        Working on problem 9 of 64: Cara.semperger vs Cara.semperger\n",
      "        Working on problem 10 of 64: Cara.semperger vs Carol.clair\n",
      "        Working on problem 11 of 64: Carol.clair vs Carol.clair\n",
      "        Working on problem 12 of 64: Carol.clair vs Chris.dorland\n",
      "        Working on problem 13 of 64: Chris.dorland vs Chris.dorland\n",
      "        Working on problem 14 of 64: Chris.dorland vs Cooper.richey\n",
      "        Working on problem 15 of 64: Cooper.richey vs Cooper.richey\n",
      "        Working on problem 16 of 64: Cooper.richey vs D.steffes\n",
      "        Working on problem 17 of 64: D.steffes vs D.steffes\n",
      "        Working on problem 18 of 64: D.steffes vs D.thomas\n",
      "        Working on problem 19 of 64: D.thomas vs D.thomas\n",
      "        Working on problem 20 of 64: D.thomas vs Dan.hyvl\n",
      "        Working on problem 21 of 64: Dan.hyvl vs Dan.hyvl\n",
      "        Working on problem 22 of 64: Dan.hyvl vs Dana.davis\n",
      "        Working on problem 23 of 64: Dana.davis vs Dana.davis\n",
      "        Working on problem 24 of 64: Dana.davis vs Daren.farmer\n",
      "        Working on problem 25 of 64: Daren.farmer vs Daren.farmer\n",
      "        Working on problem 26 of 64: Daren.farmer vs Darrell.schoolcraft\n",
      "        Working on problem 27 of 64: Darrell.schoolcraft vs Darrell.schoolcraft\n",
      "        Working on problem 28 of 64: Darrell.schoolcraft vs Darron.giron\n",
      "        Working on problem 29 of 64: Darron.giron vs Darron.giron\n",
      "        Working on problem 30 of 64: Darron.giron vs David.delainey\n",
      "        Working on problem 31 of 64: David.delainey vs David.delainey\n",
      "        Working on problem 32 of 64: David.delainey vs Debra.perlingiere\n",
      "        Working on problem 33 of 64: Debra.perlingiere vs Debra.perlingiere\n",
      "        Working on problem 34 of 64: Debra.perlingiere vs Drew.fossum\n",
      "        Working on problem 35 of 64: Drew.fossum vs Drew.fossum\n",
      "        Working on problem 36 of 64: Drew.fossum vs Elizabeth.sager\n",
      "        Working on problem 37 of 64: Elizabeth.sager vs Elizabeth.sager\n",
      "        Working on problem 38 of 64: Elizabeth.sager vs Errol.mclaughlin\n",
      "        Working on problem 39 of 64: Errol.mclaughlin vs Errol.mclaughlin\n",
      "        Working on problem 40 of 64: Errol.mclaughlin vs Gerald.nemec\n",
      "        Working on problem 41 of 64: Gerald.nemec vs Gerald.nemec\n",
      "        Working on problem 42 of 64: Gerald.nemec vs James.derrick\n",
      "        Working on problem 43 of 64: James.derrick vs James.derrick\n",
      "        Working on problem 44 of 64: James.derrick vs Jane.tholt\n",
      "        Working on problem 45 of 64: Jane.tholt vs Jane.tholt\n",
      "        Working on problem 46 of 64: Jane.tholt vs Janette.elbertson\n",
      "        Working on problem 47 of 64: Janette.elbertson vs Janette.elbertson\n",
      "        Working on problem 48 of 64: Janette.elbertson vs Jeff.dasovich\n",
      "        Working on problem 49 of 64: Jeff.dasovich vs Jeff.dasovich\n",
      "        Working on problem 50 of 64: Jeff.dasovich vs Jeff.skilling\n",
      "        Working on problem 51 of 64: Jeff.skilling vs Jeff.skilling\n",
      "        Working on problem 52 of 64: Jeff.skilling vs Jeffrey.shankman\n",
      "        Working on problem 53 of 64: Jeffrey.shankman vs Jeffrey.shankman\n",
      "        Working on problem 54 of 64: Jeffrey.shankman vs Joannie.williamson\n",
      "        Working on problem 55 of 64: Joannie.williamson vs Joannie.williamson\n",
      "        Working on problem 56 of 64: Joannie.williamson vs John.arnold\n",
      "        Working on problem 57 of 64: John.arnold vs John.arnold\n",
      "        Working on problem 58 of 64: John.arnold vs K.allen\n",
      "        Working on problem 59 of 64: K.allen vs K.allen\n",
      "        Working on problem 60 of 64: K.allen vs Kam.keiser\n",
      "        Working on problem 61 of 64: Kam.keiser vs Kam.keiser\n",
      "        Working on problem 62 of 64: Kam.keiser vs Kate.symes\n",
      "        Working on problem 63 of 64: Kate.symes vs Andy.zipper\n",
      "        Working on problem 64 of 64: Kate.symes vs Kate.symes\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for rep in range(1, 6): \n",
    "    print(f\"Repetition {rep}\")\n",
    "    df = lambdaG_max_similarity(\n",
    "        unknown_embedded,\n",
    "        known_embedded,\n",
    "        known_embedded,\n",
    "        metadata=agg_metadata\n",
    "    )\n",
    "\n",
    "    # Add the repetition column at the start:\n",
    "    df.insert(0, 'repetition', rep)\n",
    "    df.insert(1, 'corpus', corpus)      # move corpus next\n",
    "    df.insert(2, 'data_type', data_type)\n",
    "    df.insert(2, 'token_type', token_type) \n",
    "    all_results.append(df)\n",
    "\n",
    "# Combine all repetitions into one DataFrame\n",
    "test_res_long = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb9b380-283a-43c4-aa4a-93d1479bd2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repetition</th>\n",
       "      <th>corpus</th>\n",
       "      <th>token_type</th>\n",
       "      <th>data_type</th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Andy.zipper vs Andy.zipper</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>True</td>\n",
       "      <td>5664.602018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Andy.zipper vs Barry.tycholiz</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>False</td>\n",
       "      <td>-5027.842891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Barry.tycholiz vs Barry.tycholiz</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>True</td>\n",
       "      <td>13795.558616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Barry.tycholiz vs Benjamin.rogers</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>Benjamin.rogers</td>\n",
       "      <td>False</td>\n",
       "      <td>6107.237502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Benjamin.rogers vs Benjamin.rogers</td>\n",
       "      <td>Benjamin.rogers</td>\n",
       "      <td>Benjamin.rogers</td>\n",
       "      <td>True</td>\n",
       "      <td>12278.282148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>K.allen vs Kam.keiser</td>\n",
       "      <td>K.allen</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>False</td>\n",
       "      <td>-13073.234427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kam.keiser vs Kam.keiser</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>True</td>\n",
       "      <td>10851.247357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kam.keiser vs Kate.symes</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>False</td>\n",
       "      <td>-10868.279335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kate.symes vs Andy.zipper</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>False</td>\n",
       "      <td>-7869.612466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kate.symes vs Kate.symes</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>True</td>\n",
       "      <td>2094.879476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     repetition corpus             token_type data_type  \\\n",
       "0             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "1             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "2             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "3             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "4             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "..          ...    ...                    ...       ...   \n",
       "315           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "316           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "317           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "318           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "319           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "\n",
       "                                problem     known_author   unknown_author  \\\n",
       "0            Andy.zipper vs Andy.zipper      Andy.zipper      Andy.zipper   \n",
       "1         Andy.zipper vs Barry.tycholiz      Andy.zipper   Barry.tycholiz   \n",
       "2      Barry.tycholiz vs Barry.tycholiz   Barry.tycholiz   Barry.tycholiz   \n",
       "3     Barry.tycholiz vs Benjamin.rogers   Barry.tycholiz  Benjamin.rogers   \n",
       "4    Benjamin.rogers vs Benjamin.rogers  Benjamin.rogers  Benjamin.rogers   \n",
       "..                                  ...              ...              ...   \n",
       "315               K.allen vs Kam.keiser          K.allen       Kam.keiser   \n",
       "316            Kam.keiser vs Kam.keiser       Kam.keiser       Kam.keiser   \n",
       "317            Kam.keiser vs Kate.symes       Kam.keiser       Kate.symes   \n",
       "318           Kate.symes vs Andy.zipper       Kate.symes      Andy.zipper   \n",
       "319            Kate.symes vs Kate.symes       Kate.symes       Kate.symes   \n",
       "\n",
       "     target         score  \n",
       "0      True   5664.602018  \n",
       "1     False  -5027.842891  \n",
       "2      True  13795.558616  \n",
       "3     False   6107.237502  \n",
       "4      True  12278.282148  \n",
       "..      ...           ...  \n",
       "315   False -13073.234427  \n",
       "316    True  10851.247357  \n",
       "317   False -10868.279335  \n",
       "318   False  -7869.612466  \n",
       "319    True   2094.879476  \n",
       "\n",
       "[320 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42be150d-90d8-424c-94d2-a476bbfb69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(test_res_long, '/Volumes/BCross/datasets/author_verification/lambda_g_results/Enron_training_qwen2.5_1.5b_instruct_max_sim.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4cb2fa-c9b5-4b45-95f6-1a2a9e4a3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repetition</th>\n",
       "      <th>corpus</th>\n",
       "      <th>token_type</th>\n",
       "      <th>data_type</th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>142.196.88.228 vs 142.196.88.228</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>True</td>\n",
       "      <td>21670.058283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>142.196.88.228 vs Aban1313</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>Aban1313</td>\n",
       "      <td>False</td>\n",
       "      <td>-6293.803291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>A_Man_In_Black vs A_Man_In_Black</td>\n",
       "      <td>A_Man_In_Black</td>\n",
       "      <td>A_Man_In_Black</td>\n",
       "      <td>True</td>\n",
       "      <td>5056.981924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>A_Man_In_Black vs Bankhallbretherton</td>\n",
       "      <td>A_Man_In_Black</td>\n",
       "      <td>Bankhallbretherton</td>\n",
       "      <td>False</td>\n",
       "      <td>-8213.153313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Aban1313 vs Aban1313</td>\n",
       "      <td>Aban1313</td>\n",
       "      <td>Aban1313</td>\n",
       "      <td>True</td>\n",
       "      <td>3772.600359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Haymaker vs HeadleyDown</td>\n",
       "      <td>Haymaker</td>\n",
       "      <td>HeadleyDown</td>\n",
       "      <td>False</td>\n",
       "      <td>-3269.552887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>HeadleyDown vs HeadleyDown</td>\n",
       "      <td>HeadleyDown</td>\n",
       "      <td>HeadleyDown</td>\n",
       "      <td>True</td>\n",
       "      <td>3895.946070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>HeadleyDown vs Hipocrite</td>\n",
       "      <td>HeadleyDown</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>False</td>\n",
       "      <td>-9169.141508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Hipocrite vs Hipocrite</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>True</td>\n",
       "      <td>-143.055478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>5</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Hipocrite vs Hodja_Nasreddin</td>\n",
       "      <td>Hipocrite</td>\n",
       "      <td>Hodja_Nasreddin</td>\n",
       "      <td>False</td>\n",
       "      <td>-6504.262630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     repetition corpus             token_type data_type  \\\n",
       "0             1   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "1             1   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "2             1   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "3             1   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "4             1   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "..          ...    ...                    ...       ...   \n",
       "745           5   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "746           5   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "747           5   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "748           5   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "749           5   Wiki  Qwen2.5-1.5B-Instruct  training   \n",
       "\n",
       "                                  problem    known_author      unknown_author  \\\n",
       "0        142.196.88.228 vs 142.196.88.228  142.196.88.228      142.196.88.228   \n",
       "1              142.196.88.228 vs Aban1313  142.196.88.228            Aban1313   \n",
       "2        A_Man_In_Black vs A_Man_In_Black  A_Man_In_Black      A_Man_In_Black   \n",
       "3    A_Man_In_Black vs Bankhallbretherton  A_Man_In_Black  Bankhallbretherton   \n",
       "4                    Aban1313 vs Aban1313        Aban1313            Aban1313   \n",
       "..                                    ...             ...                 ...   \n",
       "745               Haymaker vs HeadleyDown        Haymaker         HeadleyDown   \n",
       "746            HeadleyDown vs HeadleyDown     HeadleyDown         HeadleyDown   \n",
       "747              HeadleyDown vs Hipocrite     HeadleyDown           Hipocrite   \n",
       "748                Hipocrite vs Hipocrite       Hipocrite           Hipocrite   \n",
       "749          Hipocrite vs Hodja_Nasreddin       Hipocrite     Hodja_Nasreddin   \n",
       "\n",
       "     target         score  \n",
       "0      True  21670.058283  \n",
       "1     False  -6293.803291  \n",
       "2      True   5056.981924  \n",
       "3     False  -8213.153313  \n",
       "4      True   3772.600359  \n",
       "..      ...           ...  \n",
       "745   False  -3269.552887  \n",
       "746    True   3895.946070  \n",
       "747   False  -9169.141508  \n",
       "748    True   -143.055478  \n",
       "749   False  -6504.262630  \n",
       "\n",
       "[750 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_jsonl('/Volumes/BCross/datasets/author_verification/lambda_g_results/Wiki_training_qwen2.5_1.5b_instruct_max_sim.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6361ccd3-dd58-46d1-9ebc-567e9cad8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = read_jsonl('/Volumes/BCross/datasets/author_verification/lambda_g_results/Enron_training_qwen2.5_1.5b_instruct_max_sim.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53dc2f9b-bf90-4a7c-a323-0e0bb601906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repetition</th>\n",
       "      <th>corpus</th>\n",
       "      <th>token_type</th>\n",
       "      <th>data_type</th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Andy.zipper vs Andy.zipper</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>True</td>\n",
       "      <td>5664.602018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Andy.zipper vs Barry.tycholiz</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>False</td>\n",
       "      <td>-5027.842891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Barry.tycholiz vs Barry.tycholiz</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>True</td>\n",
       "      <td>13795.558616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Barry.tycholiz vs Benjamin.rogers</td>\n",
       "      <td>Barry.tycholiz</td>\n",
       "      <td>Benjamin.rogers</td>\n",
       "      <td>False</td>\n",
       "      <td>6107.237502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Benjamin.rogers vs Benjamin.rogers</td>\n",
       "      <td>Benjamin.rogers</td>\n",
       "      <td>Benjamin.rogers</td>\n",
       "      <td>True</td>\n",
       "      <td>12278.282148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>K.allen vs Kam.keiser</td>\n",
       "      <td>K.allen</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>False</td>\n",
       "      <td>-13073.234427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kam.keiser vs Kam.keiser</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>True</td>\n",
       "      <td>10851.247357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kam.keiser vs Kate.symes</td>\n",
       "      <td>Kam.keiser</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>False</td>\n",
       "      <td>-10868.279335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kate.symes vs Andy.zipper</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>Andy.zipper</td>\n",
       "      <td>False</td>\n",
       "      <td>-7869.612466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>5</td>\n",
       "      <td>Enron</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>training</td>\n",
       "      <td>Kate.symes vs Kate.symes</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>Kate.symes</td>\n",
       "      <td>True</td>\n",
       "      <td>2094.879476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     repetition corpus             token_type data_type  \\\n",
       "0             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "1             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "2             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "3             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "4             1  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "..          ...    ...                    ...       ...   \n",
       "315           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "316           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "317           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "318           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "319           5  Enron  Qwen2.5-1.5B-Instruct  training   \n",
       "\n",
       "                                problem     known_author   unknown_author  \\\n",
       "0            Andy.zipper vs Andy.zipper      Andy.zipper      Andy.zipper   \n",
       "1         Andy.zipper vs Barry.tycholiz      Andy.zipper   Barry.tycholiz   \n",
       "2      Barry.tycholiz vs Barry.tycholiz   Barry.tycholiz   Barry.tycholiz   \n",
       "3     Barry.tycholiz vs Benjamin.rogers   Barry.tycholiz  Benjamin.rogers   \n",
       "4    Benjamin.rogers vs Benjamin.rogers  Benjamin.rogers  Benjamin.rogers   \n",
       "..                                  ...              ...              ...   \n",
       "315               K.allen vs Kam.keiser          K.allen       Kam.keiser   \n",
       "316            Kam.keiser vs Kam.keiser       Kam.keiser       Kam.keiser   \n",
       "317            Kam.keiser vs Kate.symes       Kam.keiser       Kate.symes   \n",
       "318           Kate.symes vs Andy.zipper       Kate.symes      Andy.zipper   \n",
       "319            Kate.symes vs Kate.symes       Kate.symes       Kate.symes   \n",
       "\n",
       "     target         score  \n",
       "0      True   5664.602018  \n",
       "1     False  -5027.842891  \n",
       "2      True  13795.558616  \n",
       "3     False   6107.237502  \n",
       "4      True  12278.282148  \n",
       "..      ...           ...  \n",
       "315   False -13073.234427  \n",
       "316    True  10851.247357  \n",
       "317   False -10868.279335  \n",
       "318   False  -7869.612466  \n",
       "319    True   2094.879476  \n",
       "\n",
       "[320 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b585e8-e9a7-49c2-a78f-a414cd517095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron</td>\n",
       "      <td>0.527494</td>\n",
       "      <td>0.527494</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1.404785</td>\n",
       "      <td>-0.789995</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus      Cllr  Cllr_min      EER       AUC  Balanced_Accuracy  Precision  \\\n",
       "0  Enron  0.527494  0.527494  0.09375  0.914062              0.875   0.928571   \n",
       "\n",
       "   Recall        F1  TP  FP  FN  TN  Mean_TRUE_LLR  Mean_FALSE_LLR  \\\n",
       "0  0.8125  0.866667  26   2   6  30       1.404785       -0.789995   \n",
       "\n",
       "   TRUE_trials  FALSE_trials  \n",
       "0           32            32  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_agg = (\n",
    "    test_df\n",
    "    .groupby(['problem', 'target'], as_index=False)\n",
    "    ['score']\n",
    "    .mean()\n",
    ")\n",
    "score_col = 'score'\n",
    "target_col = 'target'\n",
    "performance(results_agg,\n",
    "            score_col,\n",
    "            target_col,\n",
    "            additional_metadata={\n",
    "                'corpus': corpus\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2223ba7-2af2-4d82-ae69-a9f36355c755",
   "metadata": {},
   "source": [
    "## Test Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487e2ab-7712-4210-a9e7-eb09138d6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def embed_text_column(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str = 'text',\n",
    "    embedding_column: str = 'embedding',\n",
    "    model_name: str = 'all-MiniLM-L6-v2',\n",
    "    batch_size: int = 32,\n",
    "    show_progress_bar: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Embed a text column of a DataFrame using a Hugging Face embedding model.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing the text column.\n",
    "        text_column (str): Name of the text column to embed.\n",
    "        embedding_column (str): Name of the new column to store embeddings.\n",
    "        model_name (str): Hugging Face model name (e.g., 'all-MiniLM-L6-v2').\n",
    "        batch_size (int): Batch size for embedding.\n",
    "        show_progress_bar (bool): Whether to show a progress bar during embedding.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with an added column of embeddings.\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Text column '{text_column}' not found in DataFrame.\")\n",
    "\n",
    "    # Work on a copy to avoid SettingWithCopyWarning\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Initialize the embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Convert text values to string and collect for batching\n",
    "    texts = df_copy[text_column].astype(str).tolist()\n",
    "\n",
    "    # Compute embeddings\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=show_progress_bar\n",
    "    )\n",
    "\n",
    "    # Assign embeddings as list of floats to avoid numpy 2D assignment issues\n",
    "    df_copy[embedding_column] = embeddings.tolist()\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede55bf-93de-483e-9c57-7d3a7cf740e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_embedded = embed_text_column(known)\n",
    "known_filtered_embedded = embed_text_column(known_filtered)\n",
    "unknown_embedded = embed_text_column(unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1ed6-04df-47a0-9fdf-917286a62f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_filtered_embedded.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d8b53-6e76-4830-9d2d-185095e83e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(\n",
    "    vec1: np.ndarray,\n",
    "    vec2: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vec1 (np.ndarray): First vector.\n",
    "        vec2 (np.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity score between -1 and 1.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    v1 = np.array(vec1, dtype=float)\n",
    "    v2 = np.array(vec2, dtype=float)\n",
    "\n",
    "    # Compute dot product and norms\n",
    "    dot_prod = np.dot(v1, v2)\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(v2)\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        raise ValueError(\"One or both vectors have zero magnitude, cosine similarity is undefined.\")\n",
    "\n",
    "    return dot_prod / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a6e5d-65e4-44ab-8d7b-e99eb2fa9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(known_filtered_embedded.iloc[0, 17], known_filtered_embedded.iloc[1, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99359cb-9e65-4f5f-a296-56122d4a829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_closest(\n",
    "    df: pd.DataFrame,\n",
    "    query_vec: np.ndarray,\n",
    "    embedding_column: str = 'embedding',\n",
    "    top_n: int = 5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve the top N rows from a DataFrame whose embeddings are closest to a query vector.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing an embedding column.\n",
    "        query_vec (np.ndarray or list): The query embedding vector.\n",
    "        embedding_column (str): Name of the column with embeddings.\n",
    "        top_n (int): Number of top similar rows to return.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Subset of the original DataFrame sorted by descending similarity,\n",
    "                      with an additional 'similarity' column.\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    if embedding_column not in df.columns:\n",
    "        raise ValueError(f\"Embedding column '{embedding_column}' not found in DataFrame.\")\n",
    "\n",
    "    # Convert query vector to numpy array\n",
    "    qv = np.array(query_vec, dtype=float)\n",
    "    if np.linalg.norm(qv) == 0:\n",
    "        raise ValueError(\"Query vector has zero magnitude, cosine similarity is undefined.\")\n",
    "\n",
    "    # Compute similarities\n",
    "    sims = []\n",
    "    for emb in df[embedding_column]:\n",
    "        sims.append(cosine_similarity(qv, np.array(emb, dtype=float)))\n",
    "\n",
    "    # Create a copy with similarity scores\n",
    "    df_with_sim = df.copy()\n",
    "    df_with_sim['similarity'] = sims\n",
    "\n",
    "    # Sort and select top N\n",
    "    top_df = df_with_sim.sort_values(by='similarity', ascending=False).head(top_n)\n",
    "\n",
    "    return top_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3f998-0c01-4c34-8e00-ed821c74d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_embedded_filtered = known_embedded[known_embedded['doc_id'] != '142_196_88_228_text_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1814c8-c755-4608-90dc-16f30fdfb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_n_closest(known_embedded_filtered, known_filtered_embedded.iloc[0,17], top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602a99d-b331-4885-a56a-1aa917e22880",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import random\n",
    "\n",
    "    known_tokens = [\"Sentence A.\", \"Sentence B.\", \"Sentence C.\"]\n",
    "    known_embeddings = [\n",
    "        np.random.rand(5) for _ in known_tokens  # replace with real embeddings\n",
    "    ]\n",
    "\n",
    "    # Reference DataFrame with tokens and precomputed embeddings\n",
    "    ref_tokens = [f\"Ref sentence {i}\" for i in range(1, 11)]\n",
    "    ref_embeddings = [\n",
    "        np.random.rand(5) for _ in ref_tokens  # replace with real embeddings\n",
    "    ]\n",
    "    refs_df = pd.DataFrame({\n",
    "        'tokens': ref_tokens,\n",
    "        'embedding': ref_embeddings\n",
    "    })\n",
    "\n",
    "    # Parameters\n",
    "    r = 4  # number of nearest neighbors and samples\n",
    "\n",
    "    # Step 1: Build neighbor lists for each known sentence\n",
    "    neighbor_lists = []\n",
    "    for emb in known_embeddings:\n",
    "        top_df = get_top_n_closest(refs_df, emb, embedding_column='embedding', top_n=r)\n",
    "        neighbor_lists.append(top_df['tokens'].tolist())\n",
    "    print(\"Neighbor lists per known sentence:\")\n",
    "    for i, nbrs in enumerate(neighbor_lists, 1):\n",
    "        print(f\" Known sentence {i}: {nbrs}\")\n",
    "\n",
    "    # Step 2: Generate r samples ensuring no duplicates within each sample\n",
    "    max_attempts = 100\n",
    "    sample_sets = None\n",
    "    for attempt in range(max_attempts):\n",
    "        # Shuffle each neighbor list independently\n",
    "        shuffled = [random.sample(nbrs, len(nbrs)) for nbrs in neighbor_lists]\n",
    "        # Transpose to get samples[j][i]\n",
    "        samples = list(zip(*shuffled))[:r]\n",
    "        # Check for duplicates within each sample\n",
    "        if all(len(set(sample)) == len(sample) for sample in samples):\n",
    "            sample_sets = [list(sample) for sample in samples]\n",
    "            break\n",
    "\n",
    "    if sample_sets is None:\n",
    "        print(\"Error: Could not create non-overlapping samples\")\n",
    "    else:\n",
    "        print(\"Generated sample sets:\")\n",
    "        for idx, s in enumerate(sample_sets, 1):\n",
    "            print(f\" Sample {idx}: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e2e29-80e0-4d1a-8b6d-e0e3bf195672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av_dists",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
