{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db8ae60-5a34-4c1d-b29b-83df93e6bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406ed005-dc23-4fca-b965-dd0da11ddf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from read_and_write_docs import read_jsonl, write_jsonl, read_rds\n",
    "from utils import apply_temp_doc_id, build_metadata_df\n",
    "from lambdaG import lambdaG, lambdaG_perplexity\n",
    "from performance import performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a94cfc-c850-4067-aee8-603f674b5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(logprobs):\n",
    "    \"\"\"\n",
    "    Compute sentence-level perplexity from token log-probabilities.\n",
    "    Assumes log-probs are natural logs (base e), as provided by Qwenâ€‘2.5.\n",
    "    \"\"\"\n",
    "    return np.exp(-np.mean(logprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b709205f-ba50-487b-af8d-4721a6400524",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = \"/Volumes/BCross/datasets/author_verification\"\n",
    "\n",
    "data_type = \"test\"\n",
    "corpus = \"Enron\"\n",
    "\n",
    "model = \"Qwen2.5-1.5B-Instruct\"\n",
    "model_name = model.lower().replace(\"-\", \"_\")\n",
    "token_type = model\n",
    "\n",
    "known_loc = f\"{base_loc}/sentence_log_probs_datasets/{data_type}/{corpus}/known_sentence_logprobs_{model_name}.jsonl\"\n",
    "known = read_jsonl(known_loc)\n",
    "known.rename(columns={'sentence': 'text'}, inplace=True)\n",
    "known = apply_temp_doc_id(known)\n",
    "known = known[known['num_tokens'] > 0]\n",
    "known['perplexity'] = known['log_probs'].apply(compute_perplexity)\n",
    "\n",
    "unknown_loc = f\"{base_loc}/sentence_log_probs_datasets/{data_type}/{corpus}/unknown_sentence_logprobs_{model_name}.jsonl\"\n",
    "unknown = read_jsonl(unknown_loc)\n",
    "unknown.rename(columns={'sentence': 'text'}, inplace=True)\n",
    "unknown = apply_temp_doc_id(unknown)\n",
    "unknown = unknown[unknown['num_tokens'] > 0]\n",
    "unknown['perplexity'] = unknown['log_probs'].apply(compute_perplexity)\n",
    "\n",
    "metadata_loc = f\"{base_loc}/{data_type}/metadata.rds\"\n",
    "metadata = read_rds(metadata_loc)\n",
    "filtered_metadata = metadata[metadata['corpus'] == corpus]\n",
    "agg_metadata = build_metadata_df(filtered_metadata, known, unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c384fa06-bf5d-4a36-9386-92c8a7ae7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_filtered = known[known['author'].isin(['Hodja_Nasreddin', 'ZjarriRrethues'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84528095-4e29-46b7-b9e7-20647c3c9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = lambdaG_perplexity(unknown, known, known, agg_metadata)\n",
    "# results_agg = (\n",
    "#     results\n",
    "#     .groupby(['problem', 'target'], as_index=False)\n",
    "#     ['score']\n",
    "#     .mean()\n",
    "# )\n",
    "# score_col = 'score'\n",
    "# target_col = 'target'\n",
    "# performance(results_agg,\n",
    "#             score_col,\n",
    "#             target_col,\n",
    "#             additional_metadata={\n",
    "#                 'corpus': corpus\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb973e13-da1a-4093-9a48-4b65e6bcfa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1\n",
      "    There are 48 known author(s) and 96 problem(s) in the dataset.\n",
      "        Working on problem 1 of 96: Kevin.hyatt vs Kevin.hyatt\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for rep in range(1, 6): \n",
    "    print(f\"Repetition {rep}\")\n",
    "    df = lambdaG(unknown, known, known, agg_metadata)\n",
    "    # Add the repetition column at the start:\n",
    "    df.insert(0, 'repetition', rep)\n",
    "    df.insert(1, 'corpus', corpus)      # move corpus next\n",
    "    df.insert(2, 'data_type', data_type)\n",
    "    df.insert(2, 'token_type', token_type) \n",
    "    all_results.append(df)\n",
    "\n",
    "# Combine all repetitions into one DataFrame\n",
    "results = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7916d-70c0-4096-85b5-b5b3e9fc8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = f\"{base_loc}/lambda_g_results/{corpus}_{data_type}_{model_name}_raw.jsonl\"\n",
    "write_jsonl(results, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1add2-35b9-4745-8f78-8d5d924eb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loc = f\"{base_loc}/lambda_g_results/{corpus}_training_{model_name}_raw.jsonl\"\n",
    "training = read_jsonl(training_loc)\n",
    "\n",
    "test_loc = f\"{base_loc}/lambda_g_results/{corpus}_test_{model_name}_raw.jsonl\"\n",
    "test = read_jsonl(test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4087c02-06ca-44bd-aa94-593dfaa6d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results_agg = (\n",
    "    training\n",
    "    .groupby(['problem', 'target'], as_index=False)\n",
    "    ['score']\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "test_results_agg = (\n",
    "    test\n",
    "    .groupby(['problem', 'target'], as_index=False)\n",
    "    ['score']\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90000ede-3536-4c63-a0d9-34d35d288d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_col = 'score'\n",
    "target_col = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f52fa9-8f55-4947-aba8-5a81711603d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = performance(training_results_agg,\n",
    "                             score_col,\n",
    "                             target_col,\n",
    "                             df_test=test_results_agg,\n",
    "                             additional_metadata={\n",
    "                                 'corpus': corpus\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b02b7f-524e-4d47-9a81-83861d8595a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av_dists",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
