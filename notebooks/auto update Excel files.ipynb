{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7dd857cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.workbook.properties import CalcProperties  # openpyxl ≥ 3.1\n",
    "\n",
    "\n",
    "def add_include_phrase_lookup_column(\n",
    "    target_df: pd.DataFrame,\n",
    "    ws_target,                     # openpyxl worksheet to modify\n",
    "    no_context: pd.DataFrame,\n",
    "    nc_sheet_name: str = \"No Context\",\n",
    "    use_xlookup: bool = False,     # True -> XLOOKUP, False -> INDEX/MATCH\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Append an 'include_phrase' formula column to ws_target that pulls from the\n",
    "    No Context sheet's include_phrase by matching phrase_num.\n",
    "    \"\"\"\n",
    "    # Validations\n",
    "    if \"phrase_num\" not in target_df.columns:\n",
    "        raise ValueError(\"target_df is missing required column 'phrase_num'.\")\n",
    "    if \"phrase_num\" not in no_context.columns:\n",
    "        raise ValueError(\"no_context is missing required column 'phrase_num'.\")\n",
    "    if \"include_phrase\" not in no_context.columns:\n",
    "        raise ValueError(\"no_context is missing required column 'include_phrase'.\")\n",
    "\n",
    "    t_rows = len(target_df)\n",
    "    t_start, t_end = 2, 1 + t_rows  # headers row=1\n",
    "\n",
    "    # Place the new column at the end\n",
    "    new_col_idx = target_df.shape[1] + 1\n",
    "    new_col_letter = get_column_letter(new_col_idx)\n",
    "    ws_target[f\"{new_col_letter}1\"] = \"include_phrase\"\n",
    "\n",
    "    if t_rows == 0:\n",
    "        return\n",
    "\n",
    "    # Column letters\n",
    "    t_phrase_idx = target_df.columns.get_loc(\"phrase_num\") + 1\n",
    "    t_phrase_col = get_column_letter(t_phrase_idx)\n",
    "\n",
    "    nc_rows = len(no_context)\n",
    "    nc_start, nc_end = 2, 1 + nc_rows\n",
    "    if nc_rows == 0:\n",
    "        for r in range(t_start, t_end + 1):\n",
    "            ws_target[f\"{new_col_letter}{r}\"] = \"\"\n",
    "        return\n",
    "\n",
    "    nc_phrase_idx = no_context.columns.get_loc(\"phrase_num\") + 1\n",
    "    nc_incl_idx   = no_context.columns.get_loc(\"include_phrase\") + 1\n",
    "    nc_phrase_col = get_column_letter(nc_phrase_idx)\n",
    "    nc_incl_col   = get_column_letter(nc_incl_idx)\n",
    "\n",
    "    ncq = f\"'{nc_sheet_name}'\"  # quote for spaces/special chars\n",
    "    nc_phrase_rng = f\"{ncq}!${nc_phrase_col}${nc_start}:${nc_phrase_col}${nc_end}\"\n",
    "    nc_incl_rng   = f\"{ncq}!${nc_incl_col}${nc_start}:${nc_incl_col}${nc_end}\"\n",
    "\n",
    "    # Row formulas\n",
    "    for r in range(t_start, t_end + 1):\n",
    "        target_phrase_cell = f\"{t_phrase_col}{r}\"\n",
    "        formula = (\n",
    "            f'=IFERROR(XLOOKUP({target_phrase_cell}, {nc_phrase_rng}, {nc_incl_rng}), \"\")'\n",
    "            if use_xlookup else\n",
    "            f'=IFERROR(INDEX({nc_incl_rng}, MATCH({target_phrase_cell}, {nc_phrase_rng}, 0)), \"\")'\n",
    "        )\n",
    "        ws_target[f\"{new_col_letter}{r}\"] = formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9f50b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_llr_metrics(\n",
    "    ws_llr, *,\n",
    "    llr_sheet_name: str,\n",
    "    nc_sheet_name: str,\n",
    "    known_sheet_name: str,\n",
    "    unknown_sheet_name: str,\n",
    ") -> None:\n",
    "    LLR = f\"'{llr_sheet_name}'\"\n",
    "    NC  = f\"'{nc_sheet_name}'\"\n",
    "    KN  = f\"'{known_sheet_name}'\"\n",
    "    UN  = f\"'{unknown_sheet_name}'\"\n",
    "\n",
    "    # headers\n",
    "    ws_llr[\"D1\"] = \"num_phrases\"\n",
    "    ws_llr[\"E1\"] = \"phrases_kept\"\n",
    "    ws_llr[\"F1\"] = \"pmf_no_context\"\n",
    "    ws_llr[\"G1\"] = \"pmf_known\"\n",
    "    ws_llr[\"H1\"] = \"pmf_unknown\"\n",
    "    ws_llr[\"I1\"] = \"llr_no_context\"\n",
    "    ws_llr[\"J1\"] = \"llr_known\"\n",
    "    ws_llr[\"K1\"] = \"llr_unknown\"\n",
    "\n",
    "    last_row = ws_llr.max_row\n",
    "    if last_row < 2:\n",
    "        return\n",
    "\n",
    "    for r in range(2, last_row + 1):\n",
    "        a = f\"A{r}\"  # phrase_num\n",
    "        b = f\"B{r}\"  # phrase_occurence\n",
    "\n",
    "        # D: num_phrases\n",
    "        ws_llr[f\"D{r}\"] = f\"=COUNTIFS({NC}!$A:$A,{LLR}!${a})\"\n",
    "\n",
    "        # E: phrases_kept (include_phrase in NC col J)\n",
    "        ws_llr[f\"E{r}\"] = f\"=COUNTIFS({NC}!$A:$A,{LLR}!${a},{NC}!$J:$J,TRUE)\"\n",
    "\n",
    "        # F: pmf_no_context  (add NC J:J TRUE to both parts)\n",
    "        ws_llr[f\"F{r}\"] = (\n",
    "            f\"=IFERROR(\"\n",
    "            f\"SUMIFS({NC}!$H:$H,\"\n",
    "            f\"{NC}!$A:$A,{LLR}!${a},\"\n",
    "            f\"{NC}!$C:$C,\\\"reference\\\",\"\n",
    "            f\"{NC}!$J:$J,TRUE)\"\n",
    "            f\"/\"\n",
    "            f\"SUMIFS({NC}!$H:$H,\"\n",
    "            f\"{NC}!$A:$A,{LLR}!${a},\"\n",
    "            f\"{NC}!$J:$J,TRUE)\"\n",
    "            f\",0)\"\n",
    "        )\n",
    "\n",
    "        # G: pmf_known  (add KN N:N TRUE to both parts)  — also filters C='reference' in D:D per your spec\n",
    "        ws_llr[f\"G{r}\"] = (\n",
    "            f\"=IFERROR(\"\n",
    "            f\"SUMIFS({KN}!$K:$K,\"\n",
    "            f\"{KN}!$A:$A,{LLR}!${a},\"\n",
    "            f\"{KN}!$B:$B,{LLR}!${b},\"\n",
    "            f\"{KN}!$D:$D,\\\"reference\\\",\"\n",
    "            f\"{KN}!$N:$N,TRUE)\"\n",
    "            f\"/\"\n",
    "            f\"SUMIFS({KN}!$K:$K,\"\n",
    "            f\"{KN}!$A:$A,{LLR}!${a},\"\n",
    "            f\"{KN}!$B:$B,{LLR}!${b},\"\n",
    "            f\"{KN}!$N:$N,TRUE)\"\n",
    "            f\",0)\"\n",
    "        )\n",
    "\n",
    "        # H: pmf_unknown  (add UN N:N TRUE to both parts)\n",
    "        ws_llr[f\"H{r}\"] = (\n",
    "            f\"=IFERROR(\"\n",
    "            f\"SUMIFS({UN}!$K:$K,\"\n",
    "            f\"{UN}!$A:$A,{LLR}!${a},\"\n",
    "            f\"{UN}!$B:$B,{LLR}!${b},\"\n",
    "            f\"{UN}!$D:$D,\\\"reference\\\",\"\n",
    "            f\"{UN}!$N:$N,TRUE)\"\n",
    "            f\"/\"\n",
    "            f\"SUMIFS({UN}!$K:$K,\"\n",
    "            f\"{UN}!$A:$A,{LLR}!${a},\"\n",
    "            f\"{UN}!$B:$B,{LLR}!${b},\"\n",
    "            f\"{UN}!$N:$N,TRUE)\"\n",
    "            f\",0)\"\n",
    "        )\n",
    "\n",
    "        # I/J/K: base-10 logs of 1/pmf*\n",
    "        ws_llr[f\"I{r}\"] = f\"=IFERROR(LOG(1/F{r},10),0)\"\n",
    "        ws_llr[f\"J{r}\"] = f\"=IFERROR(LOG(1/G{r},10),0)\"\n",
    "        ws_llr[f\"K{r}\"] = f\"=IFERROR(LOG(1/H{r},10),0)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bb11a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_metrics(ws_meta, *, llr_sheet_name: str, ws_llr) -> None:\n",
    "    \"\"\"\n",
    "    metadata!J: num_phrases        = distinct count of nonblank LLR!C\n",
    "    metadata!K: phrases_kept       = distinct count of LLR!C where LLR!E > 0\n",
    "    metadata!L: llr_no_context     = SUMIFS(LLR!I:I, LLR!B:B, 1)\n",
    "    metadata!M: llr_known          = SUM(LLR!J:J)\n",
    "    metadata!N: llr_unknown        = SUM(LLR!K:K)\n",
    "    metadata!O: normalised_llr_no_context = L2 / K2 (IFERROR -> 0)\n",
    "    metadata!P: normalised_llr_known      = M2 / K2 (IFERROR -> 0)\n",
    "    metadata!Q: normalised_llr_unknown    = N2 / K2 (IFERROR -> 0)\n",
    "    \"\"\"\n",
    "    LLR = f\"'{llr_sheet_name}'\"\n",
    "    last_r = max(ws_llr.max_row, 2)\n",
    "\n",
    "    c_rng = f\"{LLR}!$C$2:$C${last_r}\"\n",
    "    e_rng = f\"{LLR}!$E$2:$E${last_r}\"\n",
    "\n",
    "    # J: all distinct phrases (nonblank) — legacy SUMPRODUCT/COUNTIF pattern\n",
    "    ws_meta[\"J1\"] = \"num_phrases\"\n",
    "    ws_meta[\"J2\"] = f\"=SUMPRODUCT(({c_rng}<>\\\"\\\")/COUNTIF({c_rng},{c_rng}))\"\n",
    "\n",
    "    # K: distinct phrases where any row for that phrase has E>0\n",
    "    ws_meta[\"K1\"] = \"phrases_kept\"\n",
    "    ws_meta[\"K2\"] = (\n",
    "        f\"=SUMPRODUCT(\"\n",
    "        f\"({c_rng}<>\\\"\\\")*\"\n",
    "        f\"(COUNTIFS({c_rng},{c_rng},{e_rng},\\\">0\\\")>0)\"\n",
    "        f\"/COUNTIF({c_rng},{c_rng})\"\n",
    "        f\")\"\n",
    "    )\n",
    "\n",
    "    # L/M/N: sums of LLR columns with stated conditions\n",
    "    ws_meta[\"L1\"] = \"llr_no_context\"\n",
    "    ws_meta[\"L2\"] = f\"=SUMIFS({LLR}!$I:$I,{LLR}!$B:$B,1)\"   # only rows with occurrence = 1\n",
    "\n",
    "    ws_meta[\"M1\"] = \"llr_known\"\n",
    "    ws_meta[\"M2\"] = f\"=SUM({LLR}!$J:$J)\"\n",
    "\n",
    "    ws_meta[\"N1\"] = \"llr_unknown\"\n",
    "    ws_meta[\"N2\"] = f\"=SUM({LLR}!$K:$K)\"\n",
    "\n",
    "    # O/P/Q: normalized by phrases_kept (metadata!K2)\n",
    "    ws_meta[\"O1\"] = \"normalised_llr_no_context\"\n",
    "    ws_meta[\"O2\"] = \"=IFERROR(L2/K2,0)\"\n",
    "\n",
    "    ws_meta[\"P1\"] = \"normalised_llr_known\"\n",
    "    ws_meta[\"P2\"] = \"=IFERROR(M2/K2,0)\"\n",
    "\n",
    "    ws_meta[\"Q1\"] = \"normalised_llr_unknown\"\n",
    "    ws_meta[\"Q2\"] = \"=IFERROR(N2/K2,0)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d1a15b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment, NamedStyle\n",
    "\n",
    "def style_entire_workbook(wb, *, header_font=\"Calibri\", header_size=11,\n",
    "                          header_grey=\"F2F2F2\", freeze_headers=True):\n",
    "    \"\"\"\n",
    "    Apply uniform header style + thin borders to all cells across all sheets.\n",
    "    - Header row assumed at row 1.\n",
    "    - Borders applied to the entire used range (1..max_row, 1..max_column).\n",
    "    \"\"\"\n",
    "    # Build reusable styles (docs: Font/Fill/Border/Alignment/NamedStyle)\n",
    "    # https://openpyxl.readthedocs.io/en/3.1/styles.html\n",
    "    thin = Side(style=\"thin\", color=\"000000\")\n",
    "    all_borders = Border(left=thin, right=thin, top=thin, bottom=thin)\n",
    "\n",
    "    header_style = NamedStyle(name=\"__hdr__auto\")\n",
    "    header_style.font = Font(name=header_font, size=header_size, bold=True)\n",
    "    header_style.fill = PatternFill(\"solid\", fgColor=header_grey)\n",
    "    header_style.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    header_style.border = all_borders\n",
    "\n",
    "    # Register style once (ignore if it already exists)\n",
    "    if \"__hdr__auto\" not in wb.named_styles:\n",
    "        wb.add_named_style(header_style)\n",
    "\n",
    "    for ws in wb.worksheets:\n",
    "        max_r, max_c = ws.max_row or 1, ws.max_column or 1\n",
    "\n",
    "        # 1) Header row styling (row 1)\n",
    "        for c in range(1, max_c + 1):\n",
    "            cell = ws.cell(row=1, column=c)\n",
    "            # If a cell existed, apply the named style; if it's empty, this is still fine\n",
    "            cell.style = \"__hdr__auto\"\n",
    "\n",
    "        # 2) Borders for all cells in used range (headers + data)\n",
    "        # Pattern: iterate rows and apply Border to each cell\n",
    "        # https://stackoverflow.com/a/18844061  (range borders with openpyxl)\n",
    "        for r in range(1, max_r + 1):\n",
    "            for c in range(1, max_c + 1):\n",
    "                ws.cell(row=r, column=c).border = all_borders\n",
    "\n",
    "        # 3) Optional: freeze header row\n",
    "        # set the pane to first cell BELOW headers, i.e. A2\n",
    "        # https://automatetheboringstuff.com/2e/chapter13/\n",
    "        if freeze_headers:\n",
    "            ws.freeze_panes = \"A2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ac398339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_sheets(wb, desired_order: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Reorder workbook sheets to match desired_order (by title).\n",
    "    Any sheets not listed are appended at the end, preserving their relative order.\n",
    "    \"\"\"\n",
    "    # Keep only existing sheet objects in the requested order\n",
    "    ordered = [wb[name] for name in desired_order if name in wb.sheetnames]\n",
    "    # Append any other sheets not specified\n",
    "    ordered += [ws for ws in wb.worksheets if ws.title not in desired_order]\n",
    "    # Assign back (openpyxl supports reassigning the private _sheets list)\n",
    "    wb._sheets = ordered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a241c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import Alignment\n",
    "\n",
    "def wrap_text_in_docs(ws_docs, cols=(\"A\", \"B\")) -> None:\n",
    "    \"\"\"\n",
    "    Turn on text wrapping for the given columns (default: A & B) on the docs sheet.\n",
    "    \"\"\"\n",
    "    wrap = Alignment(wrapText=True, horizontal=\"left\", vertical=\"top\")\n",
    "    max_r = ws_docs.max_row or 1\n",
    "    for col in cols:\n",
    "        for r in range(1, max_r + 1):\n",
    "            cell = ws_docs[f\"{col}{r}\"]\n",
    "            # Rebind alignment (styles are immutable)\n",
    "            cell.alignment = wrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3c9c9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from decimal import Decimal\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.utils import get_column_letter, column_index_from_string\n",
    "\n",
    "def _header_map(ws):\n",
    "    m = {}\n",
    "    for i, cell in enumerate(ws[1], start=1):\n",
    "        if cell.value is not None:\n",
    "            k = str(cell.value).strip().lower()\n",
    "            if k and k not in m:\n",
    "                m[k] = i\n",
    "    return m\n",
    "\n",
    "def _normalize_cols(ws, cols):\n",
    "    if cols is None:\n",
    "        return list(range(1, ws.max_column + 1))\n",
    "    lookup = _header_map(ws)\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if isinstance(c, int):\n",
    "            out.append(c)\n",
    "        else:\n",
    "            s = str(c).strip()\n",
    "            if s.lower() in lookup:\n",
    "                out.append(lookup[s.lower()])\n",
    "            else:\n",
    "                out.append(column_index_from_string(s))  # may raise if bad\n",
    "    return out\n",
    "\n",
    "def _is_number(v):\n",
    "    return isinstance(v, (int, float, Decimal)) and not isinstance(v, bool)\n",
    "\n",
    "def _is_date(v):\n",
    "    return isinstance(v, (date, datetime))\n",
    "\n",
    "def autofit_columns(\n",
    "    ws,\n",
    "    cols=None,                  # None = all; or header names / letters / indexes\n",
    "    min_width=8,\n",
    "    max_width=60,               # hard cap for general/text columns\n",
    "    numeric_max_width=14,       # tighter cap for numeric columns\n",
    "    date_max_width=12,          # tighter cap for dates\n",
    "    bool_max_width=6,           # tiny for TRUE/FALSE\n",
    "    padding=2.0,\n",
    "    wrap=True,\n",
    "    shrink=False,\n",
    "    ignore_outlier_pct=0.98,    # ignore top 2% lengths\n",
    "    sample_rows=500,            # sample up to N rows to detect type & lengths\n",
    "):\n",
    "    col_indexes = _normalize_cols(ws, cols)\n",
    "    for col_idx in col_indexes:\n",
    "        letter = get_column_letter(col_idx)\n",
    "\n",
    "        # --- sample cells to detect type and measure lengths\n",
    "        lengths = []\n",
    "        n_numeric = n_date = n_bool = n_total = 0\n",
    "\n",
    "        # iterate with values_only for speed; sample up to sample_rows\n",
    "        max_r = ws.max_row\n",
    "        end_r = min(max_r, sample_rows)\n",
    "        for row in ws.iter_rows(min_row=2, max_row=end_r,  # skip header for typing\n",
    "                                min_col=col_idx, max_col=col_idx, values_only=True):\n",
    "            v = row[0]\n",
    "            if v is None:\n",
    "                continue\n",
    "            n_total += 1\n",
    "            if _is_number(v):\n",
    "                n_numeric += 1\n",
    "                # estimate displayed length: digits + commas + decimal part\n",
    "                s = f\"{v:,}\" if float(v).is_integer() else f\"{v:,.2f}\"\n",
    "            elif _is_date(v):\n",
    "                n_date += 1\n",
    "                s = v.strftime(\"%Y-%m-%d %H:%M\") if isinstance(v, datetime) else v.strftime(\"%Y-%m-%d\")\n",
    "            elif isinstance(v, bool):\n",
    "                n_bool += 1\n",
    "                s = \"TRUE\" if v else \"FALSE\"\n",
    "            else:\n",
    "                s = str(v)\n",
    "\n",
    "            # longest visual line if there are line breaks\n",
    "            parts = s.splitlines() if \"\\n\" in s else [s]\n",
    "            for part in parts:\n",
    "                # crude width heuristic; non-ASCII a bit wider\n",
    "                L = sum(1.2 if ord(ch) > 255 else 1.0 for ch in part)\n",
    "                lengths.append(L)\n",
    "\n",
    "        # include header\n",
    "        header_val = ws.cell(row=1, column=col_idx).value\n",
    "        if header_val:\n",
    "            lengths.append(len(str(header_val)) * 1.05)\n",
    "\n",
    "        # decide the dominant type in this column\n",
    "        dominant = None\n",
    "        if n_total:\n",
    "            ratios = [(n_numeric, \"num\"), (n_date, \"date\"), (n_bool, \"bool\")]\n",
    "            dominant = max(ratios, key=lambda t: t[0])[1] if max(ratios)[0] / n_total >= 0.6 else None\n",
    "\n",
    "        # pick a base length with percentile cap\n",
    "        if lengths:\n",
    "            lengths.sort()\n",
    "            k = int(len(lengths) * ignore_outlier_pct) - 1\n",
    "            k = max(0, min(k, len(lengths) - 1))\n",
    "            base = lengths[k]\n",
    "        else:\n",
    "            base = min_width\n",
    "\n",
    "        # choose cap by type\n",
    "        cap = {\n",
    "            \"num\": numeric_max_width,\n",
    "            \"date\": date_max_width,\n",
    "            \"bool\": bool_max_width,\n",
    "            None: max_width,\n",
    "        }[dominant]\n",
    "\n",
    "        width = min(cap, max(min_width, base + padding))\n",
    "        ws.column_dimensions[letter].width = width\n",
    "\n",
    "        # apply wrap / shrink (rebind style)\n",
    "        if wrap or shrink:\n",
    "            aln = Alignment(\n",
    "                wrapText=wrap if wrap else None,\n",
    "                shrinkToFit=shrink if shrink else None,\n",
    "                vertical=\"top\"\n",
    "            )\n",
    "            for r in range(1, ws.max_row + 1):\n",
    "                ws.cell(row=r, column=col_idx).alignment = aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d46921a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openpyxl.cell.rich_text import CellRichText, TextBlock\n",
    "from openpyxl.cell.text import InlineFont  # openpyxl ≥ 3.1\n",
    "\n",
    "def highlight_overlaps_in_docs(\n",
    "    wb,\n",
    "    docs_sheet=\"docs\",\n",
    "    llr_sheet=\"LLR\",\n",
    "    phrase_col_letter=\"C\",\n",
    "    text_cells=(\"A5\", \"B5\"),\n",
    "    color_single=\"C00000\",      # red for single matches\n",
    "    color_overlap=\"FF8C00\",     # orange for overlaps\n",
    "    make_bold=True,\n",
    "    case_insensitive=True,\n",
    "    whole_words=False,          # set True to require word boundaries\n",
    "):\n",
    "    ws_docs = wb[docs_sheet]\n",
    "    ws_llr  = wb[llr_sheet]\n",
    "\n",
    "    # 1) distinct nonblank phrases from LLR!C (row 2+)\n",
    "    col_idx = ord(phrase_col_letter.upper()) - 64\n",
    "    phrases = []\n",
    "    for (v,) in ws_llr.iter_rows(min_row=2, min_col=col_idx, max_col=col_idx, values_only=True):\n",
    "        if v is None:\n",
    "            continue\n",
    "        s = str(v).strip()\n",
    "        if s:\n",
    "            phrases.append(s)\n",
    "    phrases = sorted(set(phrases), key=lambda s: (-len(s), s))  # longest-first\n",
    "    if not phrases:\n",
    "        return\n",
    "\n",
    "    # 2) big alternation; use lookahead to get overlapping matches\n",
    "    #    (?=(...)) finds zero-width positions; group(1) is the actual phrase\n",
    "    inner = \"|\".join(re.escape(p) for p in phrases)\n",
    "    if whole_words:\n",
    "        inner = r\"\\b(?:\" + inner + r\")\\b\"\n",
    "    pattern = r\"(?=(\" + inner + r\"))\"\n",
    "    flags = re.IGNORECASE if case_insensitive else 0\n",
    "    rx = re.compile(pattern, flags)\n",
    "\n",
    "    def make_runs(text: str) -> CellRichText:\n",
    "        if not text:\n",
    "            return CellRichText([\"\"])\n",
    "\n",
    "        # collect all (start, end) spans using the lookahead\n",
    "        spans = []\n",
    "        for m in rx.finditer(text):\n",
    "            start = m.start()\n",
    "            end = start + len(m.group(1))\n",
    "            spans.append((start, end))\n",
    "        if not spans:\n",
    "            return CellRichText([text])\n",
    "\n",
    "        # coverage map: how many phrases cover each character\n",
    "        cov = [0] * len(text)\n",
    "        for a, b in spans:\n",
    "            for i in range(a, b):\n",
    "                cov[i] += 1\n",
    "\n",
    "        # split into runs by coverage transitions\n",
    "        runs, i = [], 0\n",
    "        while i < len(text):\n",
    "            start = i\n",
    "            level = cov[i] if i < len(cov) else 0\n",
    "            i += 1\n",
    "            while i < len(text) and (cov[i] if i < len(cov) else 0) == level:\n",
    "                i += 1\n",
    "            seg = text[start:i]\n",
    "            if level == 0:\n",
    "                runs.append(seg)  # plain\n",
    "            elif level == 1:\n",
    "                runs.append(TextBlock(InlineFont(color=color_single, b=make_bold), seg))\n",
    "            else:\n",
    "                runs.append(TextBlock(InlineFont(color=color_overlap, b=make_bold), seg))\n",
    "        return CellRichText(runs)\n",
    "\n",
    "    # 3) apply to the requested docs cells\n",
    "    for addr in text_cells:\n",
    "        raw = \"\" if ws_docs[addr].value is None else str(ws_docs[addr].value)\n",
    "        ws_docs[addr].value = make_runs(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4a9fc8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel_template(\n",
    "    known: pd.DataFrame,\n",
    "    unknown: pd.DataFrame,\n",
    "    no_context: pd.DataFrame,\n",
    "    metadata: pd.DataFrame,\n",
    "    docs: pd.DataFrame,\n",
    "    path: str | Path = \"template.xlsx\",\n",
    "    known_sheet: str = \"known\",\n",
    "    unknown_sheet: str = \"unknown\",\n",
    "    nc_sheet: str = \"no context\",\n",
    "    metadata_sheet: str = \"metadata\",\n",
    "    docs_sheet: str = \"docs\",\n",
    "    llr_sheet: str = \"LLR\",\n",
    "    use_xlookup: bool = False,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Writes all sheets, builds a distinct phrases 'LLR' table, adds include_phrase lookups\n",
    "    to Known & Unknown, and then adds your LLR formulas (D..H).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "\n",
    "    # Preconditions\n",
    "    for name, df in [(\"known\", known), (\"unknown\", unknown), (\"no_context\", no_context)]:\n",
    "        if \"phrase_num\" not in df.columns:\n",
    "            raise ValueError(f\"{name} is missing required column 'phrase_num'.\")\n",
    "\n",
    "    # Ensure include flags on no_context\n",
    "    no_context = no_context.copy()\n",
    "    no_context[\"include_phrase\"] = True\n",
    "\n",
    "    # Create LLR table (distinct phrases)\n",
    "    llr_cols = ['phrase_num', 'phrase_occurence', 'original_phrase']\n",
    "    distinct_phrases = (\n",
    "        pd.concat([unknown[llr_cols], known[llr_cols]], ignore_index=True)\n",
    "        .drop_duplicates()\n",
    "        .sort_values(['phrase_num', 'phrase_occurence'], kind='mergesort')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Choose writer mode safely\n",
    "    writer_mode = \"a\" if path.exists() else \"w\"\n",
    "    writer_kwargs = {\"engine\": \"openpyxl\", \"mode\": writer_mode}\n",
    "    if writer_mode == \"a\":\n",
    "        writer_kwargs[\"if_sheet_exists\"] = \"replace\"  # only valid in append mode\n",
    "        \n",
    "\n",
    "    with pd.ExcelWriter(path, **writer_kwargs) as writer:\n",
    "        # Write sheets\n",
    "        docs.to_excel(writer, index=False, sheet_name=docs_sheet)\n",
    "        known.to_excel(writer, index=False, sheet_name=known_sheet)\n",
    "        unknown.to_excel(writer, index=False, sheet_name=unknown_sheet)\n",
    "        no_context.to_excel(writer, index=False, sheet_name=nc_sheet)\n",
    "        distinct_phrases.to_excel(writer, index=False, sheet_name=llr_sheet)\n",
    "        metadata.to_excel(writer, index=False, sheet_name=metadata_sheet)\n",
    "\n",
    "        # Add formulas to Known/Unknown\n",
    "        wb = writer.book\n",
    "        ws_meta = wb[metadata_sheet]\n",
    "        _ = wb[nc_sheet]  # assert exists\n",
    "        ws_known   = wb[known_sheet]\n",
    "        ws_unknown = wb[unknown_sheet]\n",
    "        ws_llr     = wb[llr_sheet]\n",
    "        ws_docs = wb[docs_sheet]\n",
    "\n",
    "        highlight_overlaps_in_docs(\n",
    "            wb,\n",
    "            docs_sheet=docs_sheet,   # whatever you named it\n",
    "            llr_sheet=llr_sheet,     # whatever you named it\n",
    "            color_single=\"C00000\",\n",
    "            color_overlap=\"FF8C00\",\n",
    "            make_bold=True,\n",
    "            case_insensitive=True,\n",
    "        )\n",
    "        \n",
    "        add_include_phrase_lookup_column(known, ws_known, no_context, nc_sheet, use_xlookup)\n",
    "        add_include_phrase_lookup_column(unknown, ws_unknown, no_context, nc_sheet, use_xlookup)\n",
    "\n",
    "        # Add LLR metrics (your D..H columns)\n",
    "        add_llr_metrics(\n",
    "            ws_llr,\n",
    "            llr_sheet_name=llr_sheet,\n",
    "            nc_sheet_name=nc_sheet,\n",
    "            known_sheet_name=known_sheet,\n",
    "            unknown_sheet_name=unknown_sheet,\n",
    "        )\n",
    "\n",
    "        # Add the metadata metrics\n",
    "        add_metadata_metrics(ws_meta, llr_sheet_name=llr_sheet, ws_llr=ws_llr)\n",
    "        \n",
    "        # Style every sheet\n",
    "        style_entire_workbook(wb)\n",
    "\n",
    "        wrap_text_in_docs(ws_docs, cols=(\"A\",\"B\"))\n",
    "        autofit_columns(ws_docs)\n",
    "        \n",
    "        # Reorder sheets exactly as requested\n",
    "        reorder_sheets(\n",
    "            wb,\n",
    "            desired_order=[docs_sheet, metadata_sheet, nc_sheet, known_sheet, unknown_sheet, llr_sheet]\n",
    "        )\n",
    "\n",
    "        # Force Excel to do a full calc on open (newer openpyxl API)\n",
    "        wb.calculation = CalcProperties(fullCalcOnLoad=True)\n",
    "\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "24355260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping (exists): hootmag_text_1 vs hootmag_text_13.xlsx\n",
      "Skipping (exists): hootmag_text_10 vs hootmag_text_13.xlsx\n",
      "Skipping (exists): hootmag_text_12 vs hootmag_text_13.xlsx\n",
      "Skipping (exists): icarus3_text_1 vs icarus3_text_4.xlsx\n",
      "Skipping (exists): icarus3_text_2 vs icarus3_text_4.xlsx\n",
      "Skipping (exists): icarus3_text_3 vs icarus3_text_4.xlsx\n",
      "Skipping (exists): ivoshandor_text_2 vs jasper_deng_text_4.xlsx\n",
      "Skipping (exists): ivoshandor_text_4 vs jasper_deng_text_4.xlsx\n",
      "Skipping (exists): ivoshandor_text_5 vs jasper_deng_text_4.xlsx\n",
      "Skipping (exists): lear_21_text_1 vs lear_21_text_3.xlsx\n",
      "Skipping (exists): lear_21_text_2 vs lear_21_text_3.xlsx\n",
      "Skipping (exists): lear_21_text_5 vs lear_21_text_3.xlsx\n",
      "Skipping (exists): mathsci_text_2 vs maunus_text_1.xlsx\n",
      "Skipping (exists): mathsci_text_3 vs maunus_text_1.xlsx\n",
      "Skipping (exists): rjecina_text_1 vs rjecina_text_11.xlsx\n",
      "Skipping (exists): rjecina_text_10 vs rjecina_text_11.xlsx\n",
      "Skipping (exists): rjecina_text_13 vs rjecina_text_11.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "save_loc = Path('/Volumes/BCross/paraphrase examples/Wiki-test-gpt-4-1')\n",
    "completed_loc = Path('/Volumes/BCross/paraphrase examples/Wiki-test-gpt-4-1-completed')\n",
    "completed_loc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def pick(d, wanted):\n",
    "    wn = wanted.strip().lower().replace(\" \", \"_\")\n",
    "    for k, v in d.items():\n",
    "        if k.strip().lower().replace(\" \", \"_\") == wn:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "for path in sorted(save_loc.glob(\"*.xlsx\")):\n",
    "    if path.name.startswith(\"~$\"):\n",
    "        continue  # skip Excel temp/lock files\n",
    "\n",
    "    out_path = completed_loc / path.name\n",
    "    if out_path.exists():        # <-- skip if already processed\n",
    "        print(f\"Skipping (exists): {out_path.name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {path.name}\")\n",
    "\n",
    "    # Load all sheets\n",
    "    all_sheets = pd.read_excel(path, sheet_name=None, engine=\"openpyxl\")\n",
    "    docs_df    = pick(all_sheets, \"docs\")\n",
    "    known      = pick(all_sheets, \"known\")\n",
    "    unknown    = pick(all_sheets, \"unknown\")\n",
    "    metadata   = pick(all_sheets, \"metadata\")\n",
    "    no_context = pick(all_sheets, \"no_context\")\n",
    "\n",
    "    # Require the key sheets\n",
    "    required = {\"docs\": docs_df, \"known\": known, \"unknown\": unknown,\n",
    "                \"metadata\": metadata, \"no_context\": no_context}\n",
    "    missing = [k for k, v in required.items() if v is None]\n",
    "    if missing:\n",
    "        print(f\"  Skipping (missing sheets: {', '.join(missing)})\")\n",
    "        continue\n",
    "\n",
    "    # Build the completed workbook\n",
    "    create_excel_template(\n",
    "        known=known,\n",
    "        unknown=unknown,\n",
    "        no_context=no_context,\n",
    "        metadata=metadata,\n",
    "        docs=docs_df,              # ensure your function uses this param name\n",
    "        path=str(out_path),\n",
    "        known_sheet=\"known\",\n",
    "        unknown_sheet=\"unknown\",\n",
    "        nc_sheet=\"no context\",\n",
    "        metadata_sheet=\"metadata\",\n",
    "        docs_sheet=\"docs\",\n",
    "        llr_sheet=\"LLR\",\n",
    "        use_xlookup=False,\n",
    "    )\n",
    "    print(f\"  ✓ Wrote: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
