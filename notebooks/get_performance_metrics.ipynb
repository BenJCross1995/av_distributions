{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a34fd72-aec9-4469-aab3-15cf3b3cad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d89247-cd94-4630-8ae6-128044470cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a05f55-0c66-4d43-ac94-ef6e3b089154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from performance import performance\n",
    "from read_and_write_docs import read_jsonl, write_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1acf0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_loc = \"/Volumes/BCross/datasets/author_verification/log_probs_results\"\n",
    "\n",
    "abs_differences_loc = f\"{base_results_loc}/abs_differences\"\n",
    "log_probs_loc = f\"{base_results_loc}/log_probs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfac03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_abs_train = read_jsonl(f\"{abs_differences_loc}/training_enron_qwen2.5_1.5b_instruct.jsonl\")\n",
    "wiki_abs_test = read_jsonl(f\"{abs_differences_loc}/training_enron_qwen2.5_1.5b_instruct.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce6201f-ea03-4168-9137-df53dc6d7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_abs_train_agg = (\n",
    "    wiki_abs_train\n",
    "    .groupby(['corpus', 'problem', 'data_type', 'comparison', 'label'], as_index=False)\n",
    "    ['aggregated_score']\n",
    "    .mean()\n",
    "    .rename(columns={'aggregated_score': 'score'})\n",
    ")\n",
    "\n",
    "wiki_abs_test_agg = (\n",
    "    wiki_abs_test\n",
    "    .groupby(['corpus', 'problem', 'data_type', 'comparison', 'label'], as_index=False)\n",
    "    ['aggregated_score']\n",
    "    .mean()\n",
    "    .rename(columns={'aggregated_score': 'score'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbb8536-2531-4a90-8626-f39a9dda3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_col = 'score'\n",
    "target_col = 'label'\n",
    "result_name = 'Experiment_1'\n",
    "result_description = 'Initial experiment with basic model'\n",
    "corpus = 'Sample_Corpus'\n",
    "data_type = 'test'\n",
    "model = 'Logistic_Regression'\n",
    "keep_cols = ['corpus', 'data_type', 'comparison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592eb58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = performance(wiki_abs_train_agg,\n",
    "                             score_col,\n",
    "                             target_col,\n",
    "                            df_test=wiki_abs_test_agg,\n",
    "                            keep_cols = keep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e769141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comparison</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron</td>\n",
       "      <td>training</td>\n",
       "      <td>abs_differences</td>\n",
       "      <td>0.998234</td>\n",
       "      <td>0.998234</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.59668</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.00862</td>\n",
       "      <td>-0.001897</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus data_type       comparison      Cllr  Cllr_min      EER      AUC  \\\n",
       "0  Enron  training  abs_differences  0.998234  0.998234  0.46875  0.59668   \n",
       "\n",
       "   Balanced_Accuracy  Precision   Recall        F1  TP  FP  FN  TN  \\\n",
       "0           0.515625    0.52381  0.34375  0.415094  11  10  21  22   \n",
       "\n",
       "   Mean_TRUE_LLR  Mean_FALSE_LLR  TRUE_trials  FALSE_trials  \n",
       "0       -0.00862       -0.001897           32            32  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48595c65-46fb-4651-95ef-5be6815a45be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_agg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_metrics \u001b[38;5;241m=\u001b[39m performance(\u001b[43mdf_agg\u001b[49m,\n\u001b[1;32m      2\u001b[0m                              score_col,\n\u001b[1;32m      3\u001b[0m                              target_col,\n\u001b[1;32m      4\u001b[0m                              additional_metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      5\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: result_name,\n\u001b[1;32m      6\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult_description\u001b[39m\u001b[38;5;124m\"\u001b[39m: result_description,\n\u001b[1;32m      7\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: corpus,\n\u001b[1;32m      8\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_type,\n\u001b[1;32m      9\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\n\u001b[1;32m     10\u001b[0m                              }\n\u001b[1;32m     11\u001b[0m                             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_agg' is not defined"
     ]
    }
   ],
   "source": [
    "result_metrics = performance(df_agg,\n",
    "                             score_col,\n",
    "                             target_col,\n",
    "                             additional_metadata={\n",
    "                                 \"result_name\": result_name,\n",
    "                                 \"result_description\": result_description,\n",
    "                                 \"corpus\": corpus,\n",
    "                                 \"data_type\": data_type,\n",
    "                                 \"model\": model\n",
    "                             }\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723311a3-3fcc-47ad-b7a4-1fa529e29fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b01a0-f9da-4da1-b116-6cdfea9a4696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase_llm",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
