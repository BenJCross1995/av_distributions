{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db8ae60-5a34-4c1d-b29b-83df93e6bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406ed005-dc23-4fca-b965-dd0da11ddf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from read_and_write_docs import read_jsonl, write_jsonl, read_rds\n",
    "from utils import apply_temp_doc_id, build_metadata_df\n",
    "from lambdaG import lambdaG, lambdaG_paraphrase\n",
    "from performance import performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a94cfc-c850-4067-aee8-603f674b5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(logprobs):\n",
    "    \"\"\"\n",
    "    Compute sentence-level perplexity from token log-probabilities.\n",
    "    Assumes log-probs are natural logs (base e), as provided by Qwenâ€‘2.5.\n",
    "    \"\"\"\n",
    "    return np.exp(-np.mean(logprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b709205f-ba50-487b-af8d-4721a6400524",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = \"/Volumes/BCross/datasets/author_verification\"\n",
    "\n",
    "data_type = \"training\"\n",
    "corpus = \"Wiki\"\n",
    "\n",
    "model = \"Qwen2.5-1.5B-Instruct\"\n",
    "model_name = model.lower().replace(\"-\", \"_\")\n",
    "token_type = model\n",
    "\n",
    "known_loc = f\"{base_loc}/sentence_log_probs_datasets/{data_type}/{corpus}/known_sentence_logprobs_{model_name}.jsonl\"\n",
    "known_loc = \"/Users/user/Documents/test_data/known_sentence_logprobs_qwen2.5_1.5b_instruct.jsonl\"\n",
    "known = read_jsonl(known_loc)\n",
    "known.rename(columns={'sentence': 'text'}, inplace=True)\n",
    "known = apply_temp_doc_id(known)\n",
    "known = known[known['num_tokens'] > 0]\n",
    "known['perplexity'] = known['log_probs'].apply(compute_perplexity)\n",
    "\n",
    "unknown_loc = f\"{base_loc}/sentence_log_probs_datasets/{data_type}/{corpus}/unknown_sentence_logprobs_{model_name}.jsonl\"\n",
    "unknown_loc = \"/Users/user/Documents/test_data/unknown_sentence_logprobs_qwen2.5_1.5b_instruct.jsonl\"\n",
    "unknown = read_jsonl(unknown_loc)\n",
    "unknown.rename(columns={'sentence': 'text'}, inplace=True)\n",
    "unknown = apply_temp_doc_id(unknown)\n",
    "unknown = unknown[unknown['num_tokens'] > 0]\n",
    "unknown['perplexity'] = unknown['log_probs'].apply(compute_perplexity)\n",
    "\n",
    "metadata_loc = f\"{base_loc}/{data_type}/metadata.rds\"\n",
    "metadata_loc = \"/Users/user/Documents/test_data/metadata.rds\"\n",
    "metadata = read_rds(metadata_loc)\n",
    "filtered_metadata = metadata[metadata['corpus'] == corpus]\n",
    "agg_metadata = build_metadata_df(filtered_metadata, known, unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c5f99db-95e0-42ca-9227-bbd0689bab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>impostor_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>med_log_prob</th>\n",
       "      <th>differences</th>\n",
       "      <th>abs_differences</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>sum_log_prob</th>\n",
       "      <th>avg_log_prob</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>alanyst_text_13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>known</td>\n",
       "      <td>It is a caricature, and you have not clearly s...</td>\n",
       "      <td>[It, is, a, caricature,, and, you, have, not, ...</td>\n",
       "      <td>[-15.906315803527832, -0.5864660143852234, -2....</td>\n",
       "      <td>[-21.922271728515625, -21.922271728515625, -20...</td>\n",
       "      <td>[6.015955924987793, 21.3358057141304, 18.59740...</td>\n",
       "      <td>[6.015955924987793, 21.3358057141304, 18.59740...</td>\n",
       "      <td>26</td>\n",
       "      <td>-138.721345</td>\n",
       "      <td>-5.335436</td>\n",
       "      <td>15.508690</td>\n",
       "      <td>15.508690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>alanyst_text_13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>known</td>\n",
       "      <td>I hasten to add that I do not believe you are ...</td>\n",
       "      <td>[I, hasten, to, add, that, I, do, not, believe...</td>\n",
       "      <td>[-13.71926498413086, -15.373607635498047, -0.0...</td>\n",
       "      <td>[-20.256166458129883, -20.256166458129883, -24...</td>\n",
       "      <td>[6.536901473999023, 4.882558822631836, 23.9908...</td>\n",
       "      <td>[6.536901473999023, 4.882558822631836, 23.9908...</td>\n",
       "      <td>17</td>\n",
       "      <td>-53.507081</td>\n",
       "      <td>-3.147475</td>\n",
       "      <td>18.359526</td>\n",
       "      <td>18.359526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus           doc_id  impostor_id  chunk_id   author texttype  \\\n",
       "0   Wiki  alanyst_text_13            1         1  Alanyst    known   \n",
       "1   Wiki  alanyst_text_13            1         2  Alanyst    known   \n",
       "\n",
       "                                                text  \\\n",
       "0  It is a caricature, and you have not clearly s...   \n",
       "1  I hasten to add that I do not believe you are ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [It, is, a, caricature,, and, you, have, not, ...   \n",
       "1  [I, hasten, to, add, that, I, do, not, believe...   \n",
       "\n",
       "                                           log_probs  \\\n",
       "0  [-15.906315803527832, -0.5864660143852234, -2....   \n",
       "1  [-13.71926498413086, -15.373607635498047, -0.0...   \n",
       "\n",
       "                                        med_log_prob  \\\n",
       "0  [-21.922271728515625, -21.922271728515625, -20...   \n",
       "1  [-20.256166458129883, -20.256166458129883, -24...   \n",
       "\n",
       "                                         differences  \\\n",
       "0  [6.015955924987793, 21.3358057141304, 18.59740...   \n",
       "1  [6.536901473999023, 4.882558822631836, 23.9908...   \n",
       "\n",
       "                                     abs_differences  num_tokens  \\\n",
       "0  [6.015955924987793, 21.3358057141304, 18.59740...          26   \n",
       "1  [6.536901473999023, 4.882558822631836, 23.9908...          17   \n",
       "\n",
       "   sum_log_prob  avg_log_prob  mean_diff  mean_abs_diff  \n",
       "0   -138.721345     -5.335436  15.508690      15.508690  \n",
       "1    -53.507081     -3.147475  18.359526      18.359526  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impostor_loc = \"/Users/user/Documents/test_data/top_impostors_tokenized\"\n",
    "test_impostors = read_jsonl(f\"{impostor_loc}/alanyst_text_13.jsonl\")\n",
    "\n",
    "test_impostors.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a00374-8794-4004-bc73-c08a015aeea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>orig_doc_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>med_log_prob</th>\n",
       "      <th>differences</th>\n",
       "      <th>abs_differences</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>sum_log_prob</th>\n",
       "      <th>avg_log_prob</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_abs_diff</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>alanyst_text_1</td>\n",
       "      <td>known [Alanyst - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>1</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>known</td>\n",
       "      <td>Strictly speaking, we don't know whether the N...</td>\n",
       "      <td>[Strict, ly, speaking, ,, we, don, 't, know, w...</td>\n",
       "      <td>[-12.616437911987305, -3.1433467864990234, -1....</td>\n",
       "      <td>[-18.865985870361328, -18.865985870361328, -18...</td>\n",
       "      <td>[6.249547958374023, 15.722639083862305, 16.654...</td>\n",
       "      <td>[6.249547958374023, 15.722639083862305, 16.654...</td>\n",
       "      <td>45</td>\n",
       "      <td>-169.019963</td>\n",
       "      <td>-3.755999</td>\n",
       "      <td>17.431134</td>\n",
       "      <td>17.431134</td>\n",
       "      <td>42.776940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>alanyst_text_1</td>\n",
       "      <td>known [Alanyst - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>2</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>known</td>\n",
       "      <td>Because there is at least one reliable source ...</td>\n",
       "      <td>[Because, there, is, at, least, one, reliable,...</td>\n",
       "      <td>[-19.322343826293945, -6.060644149780273, -1.1...</td>\n",
       "      <td>[-19.10921859741211, -19.10921859741211, -20.8...</td>\n",
       "      <td>[-0.21312522888183594, 13.048574447631836, 19....</td>\n",
       "      <td>[0.21312522888183594, 13.048574447631836, 19.6...</td>\n",
       "      <td>27</td>\n",
       "      <td>-115.161958</td>\n",
       "      <td>-4.265258</td>\n",
       "      <td>16.349560</td>\n",
       "      <td>16.365347</td>\n",
       "      <td>71.183262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             doc_id                   orig_doc_id corpus  chunk_id   author  \\\n",
       "301  alanyst_text_1  known [Alanyst - Text-1].txt   Wiki         1  Alanyst   \n",
       "302  alanyst_text_1  known [Alanyst - Text-1].txt   Wiki         2  Alanyst   \n",
       "\n",
       "    texttype                                               text  \\\n",
       "301    known  Strictly speaking, we don't know whether the N...   \n",
       "302    known  Because there is at least one reliable source ...   \n",
       "\n",
       "                                                tokens  \\\n",
       "301  [Strict, ly, speaking, ,, we, don, 't, know, w...   \n",
       "302  [Because, there, is, at, least, one, reliable,...   \n",
       "\n",
       "                                             log_probs  \\\n",
       "301  [-12.616437911987305, -3.1433467864990234, -1....   \n",
       "302  [-19.322343826293945, -6.060644149780273, -1.1...   \n",
       "\n",
       "                                          med_log_prob  \\\n",
       "301  [-18.865985870361328, -18.865985870361328, -18...   \n",
       "302  [-19.10921859741211, -19.10921859741211, -20.8...   \n",
       "\n",
       "                                           differences  \\\n",
       "301  [6.249547958374023, 15.722639083862305, 16.654...   \n",
       "302  [-0.21312522888183594, 13.048574447631836, 19....   \n",
       "\n",
       "                                       abs_differences  num_tokens  \\\n",
       "301  [6.249547958374023, 15.722639083862305, 16.654...          45   \n",
       "302  [0.21312522888183594, 13.048574447631836, 19.6...          27   \n",
       "\n",
       "     sum_log_prob  avg_log_prob  mean_diff  mean_abs_diff  perplexity  \n",
       "301   -169.019963     -3.755999  17.431134      17.431134   42.776940  \n",
       "302   -115.161958     -4.265258  16.349560      16.365347   71.183262  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_filtered = known[known['doc_id'].isin(['athenean_text_1', 'alanyst_text_13'])]\n",
    "known_filtered = known[known['author'].isin(['Alanyst', 'Athenean'])]\n",
    "known_filtered.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b09a95-7191-44c3-bfed-c9ee31a06ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    There are 2 known author(s) and 4 problem(s) in the dataset.\n",
      "        Working on problem 1 of 4: Alanyst vs Alanyst\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/alanyst_text_1.jsonl\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/alanyst_text_12.jsonl\n",
      "2 known_docs are missing from refs_filtered and will be skipped: ['alanyst_text_1', 'alanyst_text_12']\n",
      "        Working on problem 2 of 4: Alanyst vs AlasdairGreen27\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/alanyst_text_1.jsonl\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/alanyst_text_12.jsonl\n",
      "2 known_docs are missing from refs_filtered and will be skipped: ['alanyst_text_1', 'alanyst_text_12']\n",
      "        Working on problem 3 of 4: Athenean vs Athenean\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/athenean_text_3.jsonl\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/athenean_text_4.jsonl\n",
      "2 known_docs are missing from refs_filtered and will be skipped: ['athenean_text_3', 'athenean_text_4']\n",
      "        Working on problem 4 of 4: Athenean vs Avraham\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/athenean_text_3.jsonl\n",
      "File not found, skipping: /Users/user/Documents/test_data/top_impostors_tokenized/athenean_text_4.jsonl\n",
      "2 known_docs are missing from refs_filtered and will be skipped: ['athenean_text_3', 'athenean_text_4']\n"
     ]
    }
   ],
   "source": [
    "results = lambdaG_paraphrase(unknown, known_filtered,\n",
    "                             metadata=agg_metadata, impostor_loc=impostor_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9253f86c-2242-4d4f-a30f-e6f5c8d66035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>known_author</th>\n",
       "      <th>unknown_author</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alanyst vs Alanyst</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>True</td>\n",
       "      <td>25776.300540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alanyst vs AlasdairGreen27</td>\n",
       "      <td>Alanyst</td>\n",
       "      <td>AlasdairGreen27</td>\n",
       "      <td>False</td>\n",
       "      <td>37328.820697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      problem known_author   unknown_author  target  \\\n",
       "0          Alanyst vs Alanyst      Alanyst          Alanyst    True   \n",
       "1  Alanyst vs AlasdairGreen27      Alanyst  AlasdairGreen27   False   \n",
       "\n",
       "          score  \n",
       "0  25776.300540  \n",
       "1  37328.820697  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84528095-4e29-46b7-b9e7-20647c3c9929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>Cllr</th>\n",
       "      <th>Cllr_min</th>\n",
       "      <th>EER</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Mean_TRUE_LLR</th>\n",
       "      <th>Mean_FALSE_LLR</th>\n",
       "      <th>TRUE_trials</th>\n",
       "      <th>FALSE_trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>13.206207</td>\n",
       "      <td>13.136721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.827564</td>\n",
       "      <td>2.714702</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus       Cllr   Cllr_min  EER   AUC  Balanced_Accuracy  Precision  \\\n",
       "0   Wiki  13.206207  13.136721  0.5  0.25                0.5        0.5   \n",
       "\n",
       "   Recall   F1  TP  FP  FN  TN  Mean_TRUE_LLR  Mean_FALSE_LLR  TRUE_trials  \\\n",
       "0     0.5  0.5   1   1   1   1      -3.827564        2.714702            2   \n",
       "\n",
       "   FALSE_trials  \n",
       "0             2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_agg = (\n",
    "    results\n",
    "    .groupby(['problem', 'target'], as_index=False)\n",
    "    ['score']\n",
    "    .mean()\n",
    ")\n",
    "score_col = 'score'\n",
    "target_col = 'target'\n",
    "performance(results_agg,\n",
    "            score_col,\n",
    "            target_col,\n",
    "            additional_metadata={\n",
    "                'corpus': corpus\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb973e13-da1a-4093-9a48-4b65e6bcfa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results = []\n",
    "\n",
    "# for rep in range(1, 6): \n",
    "#     print(f\"Repetition {rep}\")\n",
    "#     df = lambdaG_paraphrase(unknown, known_filtered,\n",
    "#                             metadata=agg_metadata, impostor_loc=impostor_loc)\n",
    "#     # Add the repetition column at the start:\n",
    "#     df.insert(0, 'repetition', rep)\n",
    "#     df.insert(1, 'corpus', corpus)      # move corpus next\n",
    "#     df.insert(2, 'data_type', data_type)\n",
    "#     df.insert(2, 'token_type', token_type) \n",
    "#     all_results.append(df)\n",
    "\n",
    "# # Combine all repetitions into one DataFrame\n",
    "# results = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23361d2-7213-4a30-b811-be82fe2e232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_agg = (\n",
    "#     results\n",
    "#     .groupby(['problem', 'target'], as_index=False)\n",
    "#     ['score']\n",
    "#     .mean()\n",
    "# )\n",
    "# score_col = 'score'\n",
    "# target_col = 'target'\n",
    "# performance(results_agg,\n",
    "#             score_col,\n",
    "#             target_col,\n",
    "#             additional_metadata={\n",
    "#                 'corpus': corpus\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7916d-70c0-4096-85b5-b5b3e9fc8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_loc = f\"{base_loc}/lambda_g_results/{corpus}_{data_type}_{model_name}_raw.jsonl\"\n",
    "# write_jsonl(results, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1add2-35b9-4745-8f78-8d5d924eb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_loc = f\"{base_loc}/lambda_g_results/{corpus}_training_{model_name}_raw.jsonl\"\n",
    "# training = read_jsonl(training_loc)\n",
    "\n",
    "# test_loc = f\"{base_loc}/lambda_g_results/{corpus}_test_{model_name}_raw.jsonl\"\n",
    "# test = read_jsonl(test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4087c02-06ca-44bd-aa94-593dfaa6d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_results_agg = (\n",
    "#     training\n",
    "#     .groupby(['problem', 'target'], as_index=False)\n",
    "#     ['score']\n",
    "#     .mean()\n",
    "# )\n",
    "\n",
    "# test_results_agg = (\n",
    "#     test\n",
    "#     .groupby(['problem', 'target'], as_index=False)\n",
    "#     ['score']\n",
    "#     .mean()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90000ede-3536-4c63-a0d9-34d35d288d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_col = 'score'\n",
    "# target_col = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f52fa9-8f55-4947-aba8-5a81711603d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_metrics = performance(training_results_agg,\n",
    "#                              score_col,\n",
    "#                              target_col,\n",
    "#                              df_test=test_results_agg,\n",
    "#                              additional_metadata={\n",
    "#                                  'corpus': corpus\n",
    "#                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b02b7f-524e-4d47-9a81-83861d8595a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av_dists",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
